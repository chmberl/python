

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Release notes &mdash; Scrapy 0.24.4 文档</title>
  

  
  

  

  
  
    

  

  
  

  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />
  

  
    <link rel="top" title="Scrapy 0.24.4 文档" href="index.html"/>
        <link rel="next" title="Contributing to Scrapy" href="contributing.html"/>
        <link rel="prev" title="Item Exporters" href="topics/exporters.html"/>
 
<!-- RTD Extra Head -->



<!-- 
Read the Docs is acting as the canonical URL for your project. 
If you want to change it, more info is available in our docs:
  http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://scrapy-chs.readthedocs.org/zh_CN/latest/news.html" />

<script type="text/javascript">
  // This is included here because other places don't have access to the pagename variable.
  var READTHEDOCS_DATA = {
    project: "scrapy-chs",
    version: "0.24",
    language: "zh_CN",
    page: "news",
    builder: "sphinx",
    theme: "sphinx_rtd_theme",
    docroot: "/",
    source_suffix: ".rst",
    api_host: "https://readthedocs.org",
    commit: "ee32ff555971e7503903093bd2cbc7565cb7669e"
  }
  // Old variables
  var doc_version = "0.24";
  var doc_slug = "scrapy-chs";
  var page_name = "news";
  var html_theme = "sphinx_rtd_theme";
</script>
<!-- RTD Analytics Code -->
<!-- Included in the header because you don't have a footer block. -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-17997319-1']);
  _gaq.push(['_trackPageview']);


  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<!-- end RTD Analytics Code -->
<!-- end RTD <extrahead> -->


  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        

        
          <a href="index.html" class="icon icon-home"> Scrapy
        

        
        </a>

        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

        
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul>
<li class="toctree-l1"><a class="reference internal" href="intro/overview.html">初窥Scrapy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#id1">选择一个网站</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#intro-overview-item">定义您想抓取的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#spider">编写提取数据的Spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#id3">执行spider，获取数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#id4">查看提取到的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#topics-whatelse">还有什么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/overview.html#id6">接下来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="intro/install.html">安装指南</a><ul>
<li class="toctree-l2"><a class="reference internal" href="intro/install.html#scrapy">安装Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/install.html#intro-install-platform-notes">平台安装指南</a><ul>
<li class="toctree-l3"><a class="reference internal" href="intro/install.html#windows">Windows</a><ul>
<li class="toctree-l4"><a class="reference internal" href="intro/install.html#ubuntu-9-10">Ubuntu 9.10及以上版本</a></li>
<li class="toctree-l4"><a class="reference internal" href="intro/install.html#archlinux">Archlinux</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="intro/tutorial.html">Scrapy入门教程</a><ul>
<li class="toctree-l2"><a class="reference internal" href="intro/tutorial.html#id2">创建项目</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/tutorial.html#item">定义Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/tutorial.html#spider">编写第一个爬虫(Spider)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="intro/tutorial.html#id3">爬取</a><ul>
<li class="toctree-l4"><a class="reference internal" href="intro/tutorial.html#id4">刚才发生了什么？</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="intro/tutorial.html#id5">提取Item</a><ul>
<li class="toctree-l4"><a class="reference internal" href="intro/tutorial.html#selectors">Selectors选择器简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="intro/tutorial.html#shellselector">在Shell中尝试Selector选择器</a></li>
<li class="toctree-l4"><a class="reference internal" href="intro/tutorial.html#id7">提取数据</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="intro/tutorial.html#id8">使用item</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="intro/tutorial.html#id9">保存爬取到的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro/tutorial.html#id10">下一步</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="intro/examples.html">例子</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/commands.html">命令行工具(Command line tools)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/commands.html#scrapy">默认的Scrapy项目结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/commands.html#id1">使用 <code class="docutils literal"><span class="pre">scrapy</span></code> 工具</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#id2">创建项目</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#id3">控制项目</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/commands.html#tool-commands">可用的工具命令(tool commands)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#startproject">startproject</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#genspider">genspider</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#crawl">crawl</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#check">check</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#list">list</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#edit">edit</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#fetch">fetch</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#view">view</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#shell">shell</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#parse">parse</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#settings">settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#runspider">runspider</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#version">version</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#deploy">deploy</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#bench">bench</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/commands.html#id4">自定义项目命令</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/commands.html#commands-module">COMMANDS_MODULE</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/items.html">Items</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#item">声明Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#item-item-fields">Item字段(Item Fields)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#id1">与Item配合</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/items.html#id2">创建item</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/items.html#id3">获取字段的值</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/items.html#id4">设置字段的值</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/items.html#id5">获取所有获取到的值</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/items.html#id6">其他任务</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#id7">扩展Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#id8">Item对象</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/items.html#field">字段(Field)对象</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/spiders.html">Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/spiders.html#spider">Spider参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/spiders.html#topics-spiders-ref">内置Spider参考手册</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/spiders.html#id2">Spider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/spiders.html#id3">Spider样例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/spiders.html#crawlspider">CrawlSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/spiders.html#crawling-rules">爬取规则(Crawling rules)</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/spiders.html#id4">CrawlSpider样例</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/spiders.html#xmlfeedspider">XMLFeedSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/spiders.html#id5">XMLFeedSpider例子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/spiders.html#csvfeedspider">CSVFeedSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/spiders.html#id6">CSVFeedSpider例子</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/spiders.html#sitemapspider">SitemapSpider</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/spiders.html#id7">SitemapSpider样例</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/selectors.html">选择器(Selectors)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/selectors.html#id1">使用选择器(selectors)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/selectors.html#id2">构造选择器(selectors)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/selectors.html#id3">使用选择器(selectors)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/selectors.html#topics-selectors-nesting-selectors">嵌套选择器(selectors)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/selectors.html#id5">结合正则表达式使用选择器(selectors)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/selectors.html#xpaths">使用相对XPaths</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/selectors.html#exslt">使用EXSLT扩展</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/selectors.html#id6">正则表达式</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/selectors.html#id7">集合操作</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/selectors.html#some-xpath-tips">Some XPath tips</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/selectors.html#using-text-nodes-in-a-condition">Using text nodes in a condition</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/selectors.html#beware-the-difference-between-node-1-and-node-1">Beware the difference between //node[1] and (//node)[1]</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/selectors.html#when-querying-by-class-consider-using-css">When querying by class, consider using CSS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/selectors.html#module-scrapy.selector">内建选择器的参考</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/selectors.html#selectorlist">SelectorList对象</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/selectors.html#html">在HTML响应上的选择器样例</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/selectors.html#xml">在XML响应上的选择器样例</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/selectors.html#removing-namespaces">移除命名空间</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/loaders.html">Item Loaders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#item-loadersitems">用Item Loaders装载Items</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#input-and-output-processors">Input and Output processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#declaring-item-loaders">Declaring Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#declaring-input-and-output-processors">Declaring Input and Output Processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#item-loader-context">Item Loader Context</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#itemloader-objects">ItemLoader objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#reusing-and-extending-item-loaders">Reusing and extending Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/loaders.html#module-scrapy.contrib.loader.processor">Available built-in processors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/shell.html">Scrapy终端(Scrapy shell)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/shell.html#id1">启动终端</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/shell.html#id2">使用终端</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/shell.html#shortcut">可用的快捷命令(shortcut)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/shell.html#scrapy">可用的Scrapy对象</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/shell.html#shell-session">终端会话(shell session)样例</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/shell.html#spidershellresponse">在spider中启动shell来查看response</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/item-pipeline.html">Item Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/item-pipeline.html#id1">编写你自己的item pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/item-pipeline.html#id2">Item pipeline 样例</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/item-pipeline.html#item">验证价格，同时丢弃没有价格的item</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/item-pipeline.html#itemjson">将item写入JSON文件</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/item-pipeline.html#id3">去重</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/item-pipeline.html#id4">启用一个Item Pipeline组件</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/feed-exports.html">Feed exports</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/feed-exports.html#serialization-formats">序列化方式(Serialization formats)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#json">JSON</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#json-lines">JSON lines</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#csv">CSV</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#xml">XML</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#pickle">Pickle</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#marshal">Marshal</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/feed-exports.html#storages">存储(Storages)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/feed-exports.html#uri">存储URI参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/feed-exports.html#storage-backends">存储端(Storage backends)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#topics-feed-storage-fs">本地文件系统</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#ftp">FTP</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#s3">S3</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#topics-feed-storage-stdout">标准输出</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/feed-exports.html#settings">设定(Settings)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#feed-uri">FEED_URI</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#feed-format">FEED_FORMAT</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#feed-store-empty">FEED_STORE_EMPTY</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#feed-storages">FEED_STORAGES</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#feed-storages-base">FEED_STORAGES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#feed-exporters">FEED_EXPORTERS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/feed-exports.html#feed-exporters-base">FEED_EXPORTERS_BASE</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/link-extractors.html">Link Extractors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/link-extractors.html#module-scrapy.contrib.linkextractors">内置Link Extractor 参考</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/link-extractors.html#module-scrapy.contrib.linkextractors.lxmlhtml">LxmlLinkExtractor</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/link-extractors.html#module-scrapy.contrib.linkextractors.sgml">SgmlLinkExtractor</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/link-extractors.html#basesgmllinkextractor">BaseSgmlLinkExtractor</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/logging.html">Logging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#log-levels">Log levels</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#log">如何设置log级别</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#log-messages">如何记录信息(log messages)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#spiderlog-logging-from-spiders">在Spider中添加log(Logging from Spiders)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#module-scrapy.log">scrapy.log模块</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/logging.html#id1">Logging设置</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/stats.html">数据收集(Stats Collection)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/stats.html#topics-stats-usecases">常见数据收集器使用方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/stats.html#id2">可用的数据收集器</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/stats.html#memorystatscollector">MemoryStatsCollector</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/stats.html#dummystatscollector">DummyStatsCollector</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/email.html">发送email</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/email.html#id1">简单例子</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/email.html#mailsender">MailSender类参考手册</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/email.html#mail">Mail设置</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/email.html#mail-from">MAIL_FROM</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/email.html#mail-host">MAIL_HOST</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/email.html#mail-port">MAIL_PORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/email.html#mail-user">MAIL_USER</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/email.html#mail-pass">MAIL_PASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/email.html#mail-tls">MAIL_TLS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/email.html#mail-ssl">MAIL_SSL</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/telnetconsole.html">Telnet终端(Telnet Console)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/telnetconsole.html#telnet">如何访问telnet终端</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/telnetconsole.html#id1">telnet终端中可用的变量</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/telnetconsole.html#telnet-console-usage-examples">Telnet console usage examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/telnetconsole.html#id2">查看引擎状态</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/telnetconsole.html#scrapy">暂停，恢复和停止Scrapy引擎</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/telnetconsole.html#id3">Telnet终端信号</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/telnetconsole.html#id4">Telnet设定</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/telnetconsole.html#telnetconsole-port">TELNETCONSOLE_PORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/telnetconsole.html#telnetconsole-host">TELNETCONSOLE_HOST</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/webservice.html">Web Service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/webservice.html#web-service-resources">Web Service资源(resources)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#json-rpc">可用JSON-RPC对象</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/webservice.html#module-scrapy.contrib.webservice.crawler">Crawler JSON-RPC资源</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/webservice.html#module-scrapy.contrib.webservice.stats">状态收集器(Stats Collector)JSON-RPC资源</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/webservice.html#spider-manager-json-rpc">爬虫管理器(Spider Manager)JSON-RPC资源</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/webservice.html#extension-manager-json-rpc">扩展管理器(Extension Manager)JSON-RPC资源</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#json">可用JSON资源</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/webservice.html#module-scrapy.contrib.webservice.enginestatus">引擎状态JSON资源</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/webservice.html#web">Web服务设置</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#webservice-enabled">WEBSERVICE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#webservice-logfile">WEBSERVICE_LOGFILE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#webservice-port">WEBSERVICE_PORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#webservice-host">WEBSERVICE_HOST</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#webservice-resources">WEBSERVICE_RESOURCES</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#webservice-resources-base">WEBSERVICE_RESOURCES_BASE</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/webservice.html#web-resource">编写web服务资源(resource)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/webservice.html#id2">web服务资源例子</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#statsresource-json-rpc-resource">StatsResource (JSON-RPC resource)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#enginestatusresource-json-resource">EngineStatusResource (JSON resource)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/webservice.html#example-of-web-service-client">Example of web service client</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/webservice.html#scrapy-ws-py-script">scrapy-ws.py script</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">常见问题(FAQ)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapybeautifulsouplxml">Scrapy相BeautifulSoup或lxml比较,如何呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapypython">Scrapy支持那些Python版本？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapypython-3">Scrapy支持Python 3么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapydjango-x">Scrapy是否从Django中&#8221;剽窃&#8221;了X呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapyhttp">Scrapy支持HTTP代理么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#item">如何爬取属性在不同页面的item呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapy-importerror-nomodule-named-win32api">Scrapy退出，ImportError: Nomodule named win32api</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#spider">我要如何在spider里模拟用户登录呢?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapy">Scrapy是以广度优先还是深度优先进行爬取的呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#id3">我的Scrapy爬虫有内存泄露，怎么办?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#id4">如何让Scrapy减少内存消耗?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#spiderhttp">我能在spider中使用基本HTTP认证么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#id5">为什么Scrapy下载了英文的页面，而不是我的本国语言？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#id6">我能在哪里找到Scrapy项目的例子？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapy-spider">我能在不创建Scrapy项目的情况下运行一个爬虫(spider)么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#filtered-offsite-request">我收到了 &#8220;Filtered offsite request&#8221; 消息。如何修复？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#id7">发布Scrapy爬虫到生产环境的推荐方式？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#large-exports-json">我能对大数据(large exports)使用JSON么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#signal-handler-twisted">我能在信号处理器(signal handler)中返回(Twisted)引用么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#reponse999">reponse返回的状态值999代表了什么?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#spider-pdb-set-trace">我能在spider中调用 <code class="docutils literal"><span class="pre">pdb.set_trace()</span></code> 来调试么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#item-dump-json-csv-xml">将所有爬取到的item转存(dump)到JSON/CSV/XML文件的最简单的方法?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#viewstate">在某些表单中巨大神秘的 <code class="docutils literal"><span class="pre">__VIEWSTATE</span></code> 参数是什么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#xml-csv">分析大XML/CSV数据源的最好方法是?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapycookies">Scrapy自动管理cookies么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapyscrapy">如何才能看到Scrapy发出及接收到的Scrapy呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#id10">要怎么停止爬虫呢?</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#scrapy-bot-ban">如何避免我的Scrapy机器人(bot)被禁止(ban)呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#spider-arguments-settings-spider">我应该使用spider参数(arguments)还是设置(settings)来配置spider呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#xmlxpathitem">我爬取了一个XML文档但是XPath选择器不返回任何的item</a></li>
<li class="toctree-l2"><a class="reference internal" href="faq.html#name-crawler">我得到错误: &#8220;不能导入name crawler“</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/debug.html">调试(Debugging)Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/debug.html#parse">Parse命令</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/debug.html#scrapy-shell">Scrapy终端(Shell)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/debug.html#id1">在浏览器中打开</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/debug.html#logging">Logging</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/contracts.html">Spiders Contracts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/contracts.html#contracts">自定义Contracts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/practices.html">实践经验(Common Practices)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/practices.html#scrapy">在脚本中运行Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/practices.html#spider">同一进程运行多个spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/practices.html#distributed-crawls">分布式爬虫(Distributed crawls)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/practices.html#ban">避免被禁止(ban)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/practices.html#item">动态创建Item类</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/broad-crawls.html">通用爬虫(Broad Crawls)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#id1">增加并发</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#log">降低log级别</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#cookies">禁止cookies</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#id2">禁止重试</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#id3">减小下载超时</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#id4">禁止重定向</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/broad-crawls.html#ajax-crawlable-pages">启用 &#8220;Ajax Crawlable Pages&#8221; 爬取</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/firefox.html">借助Firefox来爬取</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/firefox.html#dom">在浏览器中检查DOM的注意事项</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/firefox.html#topics-firefox-addons">对爬取有帮助的实用Firefox插件</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/firefox.html#firebug">Firebug</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/firefox.html#xpather">XPather</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/firefox.html#xpath-checker">XPath Checker</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/firefox.html#tamper-data">Tamper Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/firefox.html#firecookie">Firecookie</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/firebug.html">使用Firebug进行爬取</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/firebug.html#id1">介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/firebug.html#follow">获取到跟进(follow)的链接</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/firebug.html#id4">提取数据</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/leaks.html">调试内存溢出</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/leaks.html#id2">内存泄露的常见原因</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/leaks.html#trackref">使用 <code class="docutils literal"><span class="pre">trackref</span></code> 调试内存泄露</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/leaks.html#id3">哪些对象被追踪了?</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/leaks.html#id4">真实例子</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/leaks.html#spider">很多spider?</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/leaks.html#scrapy-utils-trackref">scrapy.utils.trackref模块</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/leaks.html#guppy">使用Guppy调试内存泄露</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/leaks.html#leaks-without-leaks">Leaks without leaks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/images.html">下载项目图片</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#id2">使用图片管道</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#id3">使用样例</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#topics-images-enabling">开启你的图片管道</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#id5">图片存储</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/images.html#id6">文件系统存储</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#id7">额外的特性</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/images.html#id8">图片失效</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/images.html#topics-images-thumbnails">缩略图生成</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/images.html#id10">滤出小图片</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#module-scrapy.contrib.pipeline.images">实现定制图片管道</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/images.html#id12">定制图片管道的例子</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/ubuntu.html">Ubuntu 软件包</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/scrapyd.html">Scrapyd</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/autothrottle.html">自动限速(AutoThrottle)扩展</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/autothrottle.html#id1">设计目标</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/autothrottle.html#id2">扩展是如何实现的</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/autothrottle.html#autothrottle-algorithm">限速算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/autothrottle.html#id4">设置</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/autothrottle.html#autothrottle-enabled">AUTOTHROTTLE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/autothrottle.html#autothrottle-start-delay">AUTOTHROTTLE_START_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/autothrottle.html#autothrottle-max-delay">AUTOTHROTTLE_MAX_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/autothrottle.html#autothrottle-debug">AUTOTHROTTLE_DEBUG</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="topics/jobs.html">Jobs: 暂停，恢复爬虫</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/jobs.html#job">Job 路径</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/jobs.html#id1">怎么使用</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/jobs.html#id2">保持状态</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/jobs.html#id3">持久化的一些坑</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/jobs.html#cookies">Cookies的有效期</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/jobs.html#id4">请求序列化</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/djangoitem.html">DjangoItem</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/djangoitem.html#id1">使用DjangoItem</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/djangoitem.html#id2">DjangoItem注意事项</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/djangoitem.html#django">配置Django的设置</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/architecture.html">架构概览</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/architecture.html#id2">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/architecture.html#id3">组件</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/architecture.html#scrapy-engine">Scrapy Engine</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/architecture.html#scheduler">调度器(Scheduler)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/architecture.html#downloader">下载器(Downloader)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/architecture.html#spiders">Spiders</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/architecture.html#item-pipeline">Item Pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/architecture.html#downloader-middlewares">下载器中间件(Downloader middlewares)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/architecture.html#spider-spider-middlewares">Spider中间件(Spider middlewares)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/architecture.html#data-flow">数据流(Data flow)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/architecture.html#event-driven-networking">事件驱动网络(Event-driven networking)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/downloader-middleware.html">下载器中间件(Downloader Middleware)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/downloader-middleware.html#topics-downloader-middleware-setting">激活下载器中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/downloader-middleware.html#id2">编写您自己的下载器中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/downloader-middleware.html#topics-downloader-middleware-ref">内置下载中间件参考手册</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.cookies">CookiesMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#spidercookie-session">单spider多cookie session</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#cookies-enabled">COOKIES_ENABLED</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#cookies-debug">COOKIES_DEBUG</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.defaultheaders">DefaultHeadersMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.downloadtimeout">DownloadTimeoutMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.httpauth">HttpAuthMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.httpcache">HttpCacheMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#dummy">Dummy策略(默认值)</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#rfc2616">RFC2616策略</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#filesystem-storage-backend">Filesystem storage backend (默认值)</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#dbm-storage-backend">DBM storage backend</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#leveldb-storage-backend">LevelDB storage backend</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#httpcache">HTTPCache中间件设置</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.httpcompression">HttpCompressionMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#httpcompressionmiddleware-settings">HttpCompressionMiddleware Settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.chunked">ChunkedTransferMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.httpproxy">HttpProxyMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.redirect">RedirectMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#redirectmiddleware-settings">RedirectMiddleware settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#metarefreshmiddleware">MetaRefreshMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#metarefreshmiddleware-settings">MetaRefreshMiddleware settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.retry">RetryMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#retrymiddleware-settings">RetryMiddleware Settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.robotstxt">RobotsTxtMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.stats">DownloaderStats</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.useragent">UserAgentMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/downloader-middleware.html#module-scrapy.contrib.downloadermiddleware.ajaxcrawl">AjaxCrawlMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/downloader-middleware.html#id4">AjaxCrawlMiddleware设置</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/spider-middleware.html">Spider中间件(Middleware)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/spider-middleware.html#spider">激活spider中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/spider-middleware.html#id1">编写您自己的spider中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/spider-middleware.html#topics-spider-middleware-ref">内置spider中间件参考手册</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/spider-middleware.html#module-scrapy.contrib.spidermiddleware.depth">DepthMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/spider-middleware.html#module-scrapy.contrib.spidermiddleware.httperror">HttpErrorMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/spider-middleware.html#httperrormiddleware-settings">HttpErrorMiddleware settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/spider-middleware.html#module-scrapy.contrib.spidermiddleware.offsite">OffsiteMiddleware</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/spider-middleware.html#module-scrapy.contrib.spidermiddleware.referer">RefererMiddleware</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/spider-middleware.html#referermiddleware-settings">RefererMiddleware settings</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/spider-middleware.html#module-scrapy.contrib.spidermiddleware.urllength">UrlLengthMiddleware</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/extensions.html">扩展(Extensions)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#extension-settings">扩展设置(Extension settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#id1">加载和激活扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#available-enabled-disabled">可用的(Available)、开启的(enabled)和禁用的(disabled)的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#disabling-an-extension">禁用扩展(Disabling an extension)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#id2">实现你的扩展</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/extensions.html#sample-extension">扩展例子(Sample extension)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/extensions.html#topics-extensions-ref">内置扩展介绍</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/extensions.html#id4">通用扩展</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/extensions.html#module-scrapy.contrib.logstats">记录统计扩展(Log Stats extension)</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/extensions.html#module-scrapy.contrib.corestats">核心统计扩展(Core Stats extension)</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/extensions.html#module-scrapy.webservice">Web service 扩展</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/extensions.html#module-scrapy.telnet">Telnet console 扩展</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/extensions.html#module-scrapy.contrib.memusage">内存使用扩展(Memory usage extension)</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/extensions.html#module-scrapy.contrib.memdebug">内存调试扩展(Memory debugger extension)</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/extensions.html#module-scrapy.contrib.closespider">关闭spider扩展</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/extensions.html#module-scrapy.contrib.statsmailer">StatsMailer extension</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="topics/extensions.html#debugging-extensions">Debugging extensions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/extensions.html#stack-trace-dump-extension">Stack trace dump extension</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/extensions.html#debugger-extension">调试扩展(Debugger extension)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/api.html">核心API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/api.html#crawler-api">Crawler API</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/api.html#module-scrapy.settings">设置(Settings) API</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/api.html#module-scrapy.signalmanager">信号(Signals) API</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/api.html#stats-collector-api">状态收集器(Stats Collector) API</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="topics/request-response.html">Requests and Responses</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/request-response.html#request-objects">Request objects</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/request-response.html#passing-additional-data-to-callback-functions">Passing additional data to callback functions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/request-response.html#request-meta-special-keys">Request.meta special keys</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/request-response.html#bindaddress">bindaddress</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/request-response.html#request-subclasses">Request subclasses</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/request-response.html#formrequest-objects">FormRequest objects</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/request-response.html#request-usage-examples">Request usage examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="topics/request-response.html#using-formrequest-to-send-data-via-http-post">Using FormRequest to send data via HTTP POST</a></li>
<li class="toctree-l4"><a class="reference internal" href="topics/request-response.html#formrequest-from-response">使用FormRequest.from_response()方法模拟用户登录</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/request-response.html#response-objects">Response objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/request-response.html#response-subclasses">Response subclasses</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/request-response.html#textresponse-objects">TextResponse objects</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/request-response.html#htmlresponse-objects">HtmlResponse objects</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/request-response.html#xmlresponse-objects">XmlResponse objects</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/settings.html">Settings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/settings.html#designating-the-settings">指定设定(Designating the settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/settings.html#populating-the-settings">获取设定值(Populating the settings)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#command-line-options">1. 命令行选项(Command line options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#project-settings-module">2. 项目设定模块(Project settings module)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#default-settings-per-command">3. 命令默认设定(Default settings per-command)</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#default-global-settings">4. 默认全局设定(Default global settings)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/settings.html#how-to-access-settings">如何访问设定(How to access settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/settings.html#id1">设定名字的命名规则</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/settings.html#topics-settings-ref">内置设定参考手册</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#aws-access-key-id">AWS_ACCESS_KEY_ID</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#aws-secret-access-key">AWS_SECRET_ACCESS_KEY</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#bot-name">BOT_NAME</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#concurrent-items">CONCURRENT_ITEMS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#concurrent-requests">CONCURRENT_REQUESTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#concurrent-requests-per-domain">CONCURRENT_REQUESTS_PER_DOMAIN</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#concurrent-requests-per-ip">CONCURRENT_REQUESTS_PER_IP</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#default-item-class">DEFAULT_ITEM_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#default-request-headers">DEFAULT_REQUEST_HEADERS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#depth-limit">DEPTH_LIMIT</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#depth-priority">DEPTH_PRIORITY</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#depth-stats">DEPTH_STATS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#depth-stats-verbose">DEPTH_STATS_VERBOSE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#dnscache-enabled">DNSCACHE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#downloader">DOWNLOADER</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#downloader-middlewares">DOWNLOADER_MIDDLEWARES</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#downloader-middlewares-base">DOWNLOADER_MIDDLEWARES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#downloader-stats">DOWNLOADER_STATS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#download-delay">DOWNLOAD_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#download-handlers">DOWNLOAD_HANDLERS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#download-handlers-base">DOWNLOAD_HANDLERS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#download-timeout">DOWNLOAD_TIMEOUT</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#dupefilter-class">DUPEFILTER_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#dupefilter-debug">DUPEFILTER_DEBUG</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#editor">EDITOR</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#extensions">EXTENSIONS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#extensions-base">EXTENSIONS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#item-pipelines">ITEM_PIPELINES</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#item-pipelines-base">ITEM_PIPELINES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#log-enabled">LOG_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#log-encoding">LOG_ENCODING</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#log-file">LOG_FILE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#log-level">LOG_LEVEL</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#log-stdout">LOG_STDOUT</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#memdebug-enabled">MEMDEBUG_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#memdebug-notify">MEMDEBUG_NOTIFY</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#memusage-enabled">MEMUSAGE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#memusage-limit-mb">MEMUSAGE_LIMIT_MB</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#memusage-notify-mail">MEMUSAGE_NOTIFY_MAIL</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#memusage-report">MEMUSAGE_REPORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#memusage-warning-mb">MEMUSAGE_WARNING_MB</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#newspider-module">NEWSPIDER_MODULE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#randomize-download-delay">RANDOMIZE_DOWNLOAD_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#redirect-max-times">REDIRECT_MAX_TIMES</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#redirect-max-metarefresh-delay">REDIRECT_MAX_METAREFRESH_DELAY</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#redirect-priority-adjust">REDIRECT_PRIORITY_ADJUST</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#robotstxt-obey">ROBOTSTXT_OBEY</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#scheduler">SCHEDULER</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#spider-contracts">SPIDER_CONTRACTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#spider-contracts-base">SPIDER_CONTRACTS_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#spider-middlewares">SPIDER_MIDDLEWARES</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#spider-middlewares-base">SPIDER_MIDDLEWARES_BASE</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#spider-modules">SPIDER_MODULES</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#stats-class">STATS_CLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#stats-dump">STATS_DUMP</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#statsmailer-rcpts">STATSMAILER_RCPTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#telnetconsole-enabled">TELNETCONSOLE_ENABLED</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#telnetconsole-port">TELNETCONSOLE_PORT</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#templates-dir">TEMPLATES_DIR</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#urllength-limit">URLLENGTH_LIMIT</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/settings.html#user-agent">USER_AGENT</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/signals.html">信号(Signals)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/signals.html#deferred-signal-handlers">延迟的信号处理器(Deferred signal handlers)</a></li>
<li class="toctree-l2"><a class="reference internal" href="topics/signals.html#module-scrapy.signals">内置信号参考手册(Built-in signals reference)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#engine-started">engine_started</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#engine-stopped">engine_stopped</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#item-scraped">item_scraped</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#item-dropped">item_dropped</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#spider-closed">spider_closed</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#spider-opened">spider_opened</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#spider-idle">spider_idle</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#spider-error">spider_error</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#request-scheduled">request_scheduled</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#response-received">response_received</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/signals.html#response-downloaded">response_downloaded</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/exceptions.html">异常(Exceptions)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/exceptions.html#built-in-exceptions-reference">内置异常参考手册(Built-in Exceptions reference)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/exceptions.html#dropitem">DropItem</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exceptions.html#closespider">CloseSpider</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exceptions.html#ignorerequest">IgnoreRequest</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exceptions.html#notconfigured">NotConfigured</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exceptions.html#notsupported">NotSupported</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="topics/exporters.html">Item Exporters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="topics/exporters.html#item-exporter">使用 Item Exporter</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/exporters.html#field-serializer">1. 在 field 类中声明一个 serializer</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exporters.html#overriding-serialize-field">2. 覆盖(overriding) serialize_field() 方法</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="topics/exporters.html#topics-exporters-reference">Item Exporters 参考资料</a><ul>
<li class="toctree-l3"><a class="reference internal" href="topics/exporters.html#baseitemexporter">BaseItemExporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exporters.html#xmlitemexporter">XmlItemExporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exporters.html#csvitemexporter">CsvItemExporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exporters.html#pickleitemexporter">PickleItemExporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exporters.html#pprintitemexporter">PprintItemExporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exporters.html#jsonitemexporter">JsonItemExporter</a></li>
<li class="toctree-l3"><a class="reference internal" href="topics/exporters.html#jsonlinesitemexporter">JsonLinesItemExporter</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="">Release notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">0.24.4 (2014-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">0.24.3 (2014-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">0.24.2 (2014-07-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id4">0.24.1 (2014-06-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id5">0.24.0 (2014-06-26)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#enhancements">Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#bugfixes">Bugfixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#released-2014-02-14">0.22.2 (released 2014-02-14)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2014-02-08">0.22.1 (released 2014-02-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2014-01-17">0.22.0 (released 2014-01-17)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id6">Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fixes">Fixes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-12-09">0.20.2 (released 2013-12-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-11-28">0.20.1 (released 2013-11-28)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-11-08">0.20.0 (released 2013-11-08)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id7">Enhancements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id8">Bugfixes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other">Other</a></li>
<li class="toctree-l3"><a class="reference internal" href="#thanks">Thanks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-10-10">0.18.4 (released 2013-10-10)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-10-03">0.18.3 (released 2013-10-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-09-03">0.18.2 (released 2013-09-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-08-27">0.18.1 (released 2013-08-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-08-09">0.18.0 (released 2013-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-05-30">0.16.5 (released 2013-05-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2013-01-23">0.16.4 (released 2013-01-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2012-12-07">0.16.3 (released 2012-12-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2012-11-09">0.16.2 (released 2012-11-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2012-10-26">0.16.1 (released 2012-10-26)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#released-2012-10-18">0.16.0 (released 2012-10-18)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id9">0.14.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id10">0.14.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id11">0.14.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id12">0.14.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id13">0.14</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#new-features-and-settings">New features and settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="#code-rearranged-and-removed">Code rearranged and removed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id14">0.12</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#new-features-and-improvements">New features and improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#scrapyd-changes">Scrapyd changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#changes-to-settings">Changes to settings</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deprecated-obsoleted-functionality">Deprecated/obsoleted functionality</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id15">0.10</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id16">New features and improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#command-line-tool-changes">Command-line tool changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#api-changes">API changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id17">Changes to settings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id18">0.9</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id19">New features and improvements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id20">API changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#changes-to-default-settings">Changes to default settings</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id21">0.8</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#new-features">New features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#backwards-incompatible-changes">Backwards-incompatible changes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id22">0.7</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing to Scrapy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#reporting-bugs">Reporting bugs</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#writing-patches">Writing patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#submitting-patches">Submitting patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#coding-style">Coding style</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#scrapy-contrib">Scrapy Contrib</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#documentation-policies">Documentation policies</a></li>
<li class="toctree-l2"><a class="reference internal" href="contributing.html#tests">Tests</a><ul>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#running-tests">Running tests</a></li>
<li class="toctree-l3"><a class="reference internal" href="contributing.html#writing-tests">Writing tests</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="versioning.html">Versioning and API Stability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="versioning.html#id1">Versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="versioning.html#api-stability">API Stability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="experimental/index.html">试验阶段特性</a><ul>
<li class="toctree-l2"><a class="reference internal" href="experimental/index.html#id3">使用外部库插入命令</a></li>
</ul>
</li>
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Release notes</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="https://github.com/marchtea/scrapy_doc_chs/blob/0.24/news.rst" class="fa fa-github"> Edit on GitHub</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
    
  <div class="section" id="release-notes">
<span id="news"></span><h1>Release notes<a class="headerlink" href="#release-notes" title="永久链接至标题">¶</a></h1>
<div class="section" id="id1">
<h2>0.24.4 (2014-08-09)<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>pem file is used by mockserver and required by scrapy bench (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5eddc68">commit 5eddc68</a>)</li>
<li>scrapy bench needs scrapy.tests* (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d6cb999">commit d6cb999</a>)</li>
</ul>
</div>
<div class="section" id="id2">
<h2>0.24.3 (2014-08-09)<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>no need to waste travis-ci time on py3 for 0.24 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8e080c1">commit 8e080c1</a>)</li>
<li>Update installation docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1d0c096">commit 1d0c096</a>)</li>
<li>There is a trove classifier for Scrapy framework! (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4c701d7">commit 4c701d7</a>)</li>
<li>update other places where w3lib version is mentioned (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d109c13">commit d109c13</a>)</li>
<li>Update w3lib requirement to 1.8.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/39d2ce5">commit 39d2ce5</a>)</li>
<li>Use w3lib.html.replace_entities() (remove_entities() is deprecated) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/180d3ad">commit 180d3ad</a>)</li>
<li>set zip_safe=False (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a51ee8b">commit a51ee8b</a>)</li>
<li>do not ship tests package (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ee3b371">commit ee3b371</a>)</li>
<li>scrapy.bat is not needed anymore (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c3861cf">commit c3861cf</a>)</li>
<li>Modernize setup.py (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/362e322">commit 362e322</a>)</li>
<li>headers can not handle non-string values (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/94a5c65">commit 94a5c65</a>)</li>
<li>fix ftp test cases (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a274a7f">commit a274a7f</a>)</li>
<li>The sum up of travis-ci builds are taking like 50min to complete (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ae1e2cc">commit ae1e2cc</a>)</li>
<li>Update shell.rst typo (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e49c96a">commit e49c96a</a>)</li>
<li>removes weird indentation in the shell results (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1ca489d">commit 1ca489d</a>)</li>
<li>improved explanations, clarified blog post as source, added link for XPath string functions in the spec (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/65c8f05">commit 65c8f05</a>)</li>
<li>renamed UserTimeoutError and ServerTimeouterror #583 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/037f6ab">commit 037f6ab</a>)</li>
<li>adding some xpath tips to selectors docs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2d103e0">commit 2d103e0</a>)</li>
<li>fix tests to account for <a class="reference external" href="https://github.com/scrapy/w3lib/pull/23">https://github.com/scrapy/w3lib/pull/23</a> (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f8d366a">commit f8d366a</a>)</li>
<li>get_func_args maximum recursion fix #728 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/81344ea">commit 81344ea</a>)</li>
<li>Updated input/ouput processor example according to #560. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f7c4ea8">commit f7c4ea8</a>)</li>
<li>Fixed Python syntax in tutorial. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/db59ed9">commit db59ed9</a>)</li>
<li>Add test case for tunneling proxy (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f090260">commit f090260</a>)</li>
<li>Bugfix for leaking Proxy-Authorization header to remote host when using tunneling (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d8793af">commit d8793af</a>)</li>
<li>Extract links from XHTML documents with MIME-Type &#8220;application/xml&#8221; (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ed1f376">commit ed1f376</a>)</li>
<li>Merge pull request #793 from roysc/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/91a1106">commit 91a1106</a>)</li>
<li>Fix typo in commands.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/743e1e2">commit 743e1e2</a>)</li>
<li>better testcase for settings.overrides.setdefault (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e22daaf">commit e22daaf</a>)</li>
<li>Using CRLF as line marker according to http 1.1 definition (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5ec430b">commit 5ec430b</a>)</li>
</ul>
</div>
<div class="section" id="id3">
<h2>0.24.2 (2014-07-08)<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>Use a mutable mapping to proxy deprecated settings.overrides and settings.defaults attribute (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e5e8133">commit e5e8133</a>)</li>
<li>there is not support for python3 yet (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3cd6146">commit 3cd6146</a>)</li>
<li>Update python compatible version set to debian packages (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa5d76b">commit fa5d76b</a>)</li>
<li>DOC fix formatting in release notes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c6a9e20">commit c6a9e20</a>)</li>
</ul>
</div>
<div class="section" id="id4">
<h2>0.24.1 (2014-06-27)<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>Fix deprecated CrawlerSettings and increase backwards compatibility with
.defaults attribute (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8e3f20a">commit 8e3f20a</a>)</li>
</ul>
</div>
<div class="section" id="id5">
<h2>0.24.0 (2014-06-26)<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h2>
<div class="section" id="enhancements">
<h3>Enhancements<a class="headerlink" href="#enhancements" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Improve Scrapy top-level namespace (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/494">issue 494</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/684">issue 684</a>)</li>
<li>Add selector shortcuts to responses (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/554">issue 554</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/690">issue 690</a>)</li>
<li>Add new lxml based LinkExtractor to replace unmantained SgmlLinkExtractor
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/559">issue 559</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/761">issue 761</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/763">issue 763</a>)</li>
<li>Cleanup settings API - part of per-spider settings <strong>GSoC project</strong> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/737">issue 737</a>)</li>
<li>Add UTF8 encoding header to templates (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/688">issue 688</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/762">issue 762</a>)</li>
<li>Telnet console now binds to 127.0.0.1 by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/699">issue 699</a>)</li>
<li>Update debian/ubuntu install instructions (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/509">issue 509</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/549">issue 549</a>)</li>
<li>Disable smart strings in lxml XPath evaluations (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/535">issue 535</a>)</li>
<li>Restore filesystem based cache as default for http
cache middleware (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/541">issue 541</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/500">issue 500</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/571">issue 571</a>)</li>
<li>Expose current crawler in Scrapy shell (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/557">issue 557</a>)</li>
<li>Improve testsuite comparing CSV and XML exporters (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/570">issue 570</a>)</li>
<li>New <cite>offsite/filtered</cite> and <cite>offsite/domains</cite> stats (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/566">issue 566</a>)</li>
<li>Support process_links as generator in CrawlSpider (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/555">issue 555</a>)</li>
<li>Verbose logging and new stats counters for DupeFilter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/553">issue 553</a>)</li>
<li>Add a mimetype parameter to <cite>MailSender.send()</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/602">issue 602</a>)</li>
<li>Generalize file pipeline log messages (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/622">issue 622</a>)</li>
<li>Replace unencodeable codepoints with html entities in SGMLLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/565">issue 565</a>)</li>
<li>Converted SEP documents to rst format (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/629">issue 629</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/630">issue 630</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/638">issue 638</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/632">issue 632</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/636">issue 636</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/640">issue 640</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/635">issue 635</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/634">issue 634</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/639">issue 639</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/637">issue 637</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/631">issue 631</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/633">issue 633</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/641">issue 641</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/642">issue 642</a>)</li>
<li>Tests and docs for clickdata&#8217;s nr index in FormRequest (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/646">issue 646</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/645">issue 645</a>)</li>
<li>Allow to disable a downloader handler just like any other component (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/650">issue 650</a>)</li>
<li>Log when a request is discarded after too many redirections (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/654">issue 654</a>)</li>
<li>Log error responses if they are not handled by spider callbacks
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/612">issue 612</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/656">issue 656</a>)</li>
<li>Add content-type check to http compression mw (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/193">issue 193</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/660">issue 660</a>)</li>
<li>Run pypy tests using latest pypi from ppa (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/674">issue 674</a>)</li>
<li>Run test suite using pytest instead of trial (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/679">issue 679</a>)</li>
<li>Build docs and check for dead links in tox environment (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/687">issue 687</a>)</li>
<li>Make scrapy.version_info a tuple of integers (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/681">issue 681</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/692">issue 692</a>)</li>
<li>Infer exporter&#8217;s output format from filename extensions
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/546">issue 546</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/659">issue 659</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/760">issue 760</a>)</li>
<li>Support case-insensitive domains in <cite>url_is_from_any_domain()</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/693">issue 693</a>)</li>
<li>Remove pep8 warnings in project and spider templates (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/698">issue 698</a>)</li>
<li>Tests and docs for <cite>request_fingerprint</cite> function (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/597">issue 597</a>)</li>
<li>Update SEP-19 for GSoC project <cite>per-spider settings</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/705">issue 705</a>)</li>
<li>Set exit code to non-zero when contracts fails (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/727">issue 727</a>)</li>
<li>Add a setting to control what class is instanciated as Downloader component
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/738">issue 738</a>)</li>
<li>Pass response in <cite>item_dropped</cite> signal (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/724">issue 724</a>)</li>
<li>Improve <cite>scrapy check</cite> contracts command (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/733">issue 733</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/752">issue 752</a>)</li>
<li>Document <cite>spider.closed()</cite> shortcut (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/719">issue 719</a>)</li>
<li>Document <cite>request_scheduled</cite> signal (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/746">issue 746</a>)</li>
<li>Add a note about reporting security issues (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/697">issue 697</a>)</li>
<li>Add LevelDB http cache storage backend (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/626">issue 626</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/500">issue 500</a>)</li>
<li>Sort spider list output of <cite>scrapy list</cite> command (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/742">issue 742</a>)</li>
<li>Multiple documentation enhancemens and fixes
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/575">issue 575</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/587">issue 587</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/590">issue 590</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/596">issue 596</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/610">issue 610</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/617">issue 617</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/618">issue 618</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/627">issue 627</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/613">issue 613</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/643">issue 643</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/654">issue 654</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/675">issue 675</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/663">issue 663</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/711">issue 711</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/714">issue 714</a>)</li>
</ul>
</div>
<div class="section" id="bugfixes">
<h3>Bugfixes<a class="headerlink" href="#bugfixes" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Encode unicode URL value when creating Links in RegexLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/561">issue 561</a>)</li>
<li>Ignore None values in ItemLoader processors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/556">issue 556</a>)</li>
<li>Fix link text when there is an inner tag in SGMLLinkExtractor and
HtmlParserLinkExtractor (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/485">issue 485</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/574">issue 574</a>)</li>
<li>Fix wrong checks on subclassing of deprecated classes
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/581">issue 581</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/584">issue 584</a>)</li>
<li>Handle errors caused by inspect.stack() failures (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/582">issue 582</a>)</li>
<li>Fix a reference to unexistent engine attribute (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/593">issue 593</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/594">issue 594</a>)</li>
<li>Fix dynamic itemclass example usage of type() (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/603">issue 603</a>)</li>
<li>Use lucasdemarchi/codespell to fix typos (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/628">issue 628</a>)</li>
<li>Fix default value of attrs argument in SgmlLinkExtractor to be tuple (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/661">issue 661</a>)</li>
<li>Fix XXE flaw in sitemap reader (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/676">issue 676</a>)</li>
<li>Fix engine to support filtered start requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/707">issue 707</a>)</li>
<li>Fix offsite middleware case on urls with no hostnames (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/745">issue 745</a>)</li>
<li>Testsuite doesn&#8217;t require PIL anymore (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/585">issue 585</a>)</li>
</ul>
</div>
</div>
<div class="section" id="released-2014-02-14">
<h2>0.22.2 (released 2014-02-14)<a class="headerlink" href="#released-2014-02-14" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>fix a reference to unexistent engine.slots. closes #593 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/13c099a">commit 13c099a</a>)</li>
<li>downloaderMW doc typo (spiderMW doc copy remnant) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8ae11bf">commit 8ae11bf</a>)</li>
<li>Correct typos (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1346037">commit 1346037</a>)</li>
</ul>
</div>
<div class="section" id="released-2014-02-08">
<h2>0.22.1 (released 2014-02-08)<a class="headerlink" href="#released-2014-02-08" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>localhost666 can resolve under certain circumstances (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2ec2279">commit 2ec2279</a>)</li>
<li>test inspect.stack failure (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cc3eda3">commit cc3eda3</a>)</li>
<li>Handle cases when inspect.stack() fails (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8cb44f9">commit 8cb44f9</a>)</li>
<li>Fix wrong checks on subclassing of deprecated classes. closes #581 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/46d98d6">commit 46d98d6</a>)</li>
<li>Docs: 4-space indent for final spider example (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/13846de">commit 13846de</a>)</li>
<li>Fix HtmlParserLinkExtractor and tests after #485 merge (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/368a946">commit 368a946</a>)</li>
<li>BaseSgmlLinkExtractor: Fixed the missing space when the link has an inner tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b566388">commit b566388</a>)</li>
<li>BaseSgmlLinkExtractor: Added unit test of a link with an inner tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c1cb418">commit c1cb418</a>)</li>
<li>BaseSgmlLinkExtractor: Fixed unknown_endtag() so that it only set current_link=None when the end tag match the opening tag (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7e4d627">commit 7e4d627</a>)</li>
<li>Fix tests for Travis-CI build (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/76c7e20">commit 76c7e20</a>)</li>
<li>replace unencodeable codepoints with html entities. fixes #562 and #285 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5f87b17">commit 5f87b17</a>)</li>
<li>RegexLinkExtractor: encode URL unicode value when creating Links (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d0ee545">commit d0ee545</a>)</li>
<li>Updated the tutorial crawl output with latest output. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8da65de">commit 8da65de</a>)</li>
<li>Updated shell docs with the crawler reference and fixed the actual shell output. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/875b9ab">commit 875b9ab</a>)</li>
<li>PEP8 minor edits. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/f89efaf">commit f89efaf</a>)</li>
<li>Expose current crawler in the scrapy shell. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5349cec">commit 5349cec</a>)</li>
<li>Unused re import and PEP8 minor edits. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/387f414">commit 387f414</a>)</li>
<li>Ignore None&#8217;s values when using the ItemLoader. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0632546">commit 0632546</a>)</li>
<li>DOC Fixed HTTPCACHE_STORAGE typo in the default value which is now Filesystem instead Dbm. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cde9a8c">commit cde9a8c</a>)</li>
<li>show ubuntu setup instructions as literal code (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fb5c9c5">commit fb5c9c5</a>)</li>
<li>Update Ubuntu installation instructions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/70fb105">commit 70fb105</a>)</li>
<li>Merge pull request #550 from stray-leone/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6f70b6a">commit 6f70b6a</a>)</li>
<li>modify the version of scrapy ubuntu package (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/725900d">commit 725900d</a>)</li>
<li>fix 0.22.0 release date (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/af0219a">commit af0219a</a>)</li>
<li>fix typos in news.rst and remove (not released yet) header (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7f58f4">commit b7f58f4</a>)</li>
</ul>
</div>
<div class="section" id="released-2014-01-17">
<h2>0.22.0 (released 2014-01-17)<a class="headerlink" href="#released-2014-01-17" title="永久链接至标题">¶</a></h2>
<div class="section" id="id6">
<h3>Enhancements<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>[<strong>Backwards incompatible</strong>] Switched HTTPCacheMiddleware backend to filesystem (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/541">issue 541</a>)
To restore old backend set <cite>HTTPCACHE_STORAGE</cite> to <cite>scrapy.contrib.httpcache.DbmCacheStorage</cite></li>
<li>Proxy https:// urls using CONNECT method (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/392">issue 392</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/397">issue 397</a>)</li>
<li>Add a middleware to crawl ajax crawleable pages as defined by google (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/343">issue 343</a>)</li>
<li>Rename scrapy.spider.BaseSpider to scrapy.spider.Spider (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/510">issue 510</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/519">issue 519</a>)</li>
<li>Selectors register EXSLT namespaces by default (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/472">issue 472</a>)</li>
<li>Unify item loaders similar to selectors renaming (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/461">issue 461</a>)</li>
<li>Make <cite>RFPDupeFilter</cite> class easily subclassable (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/533">issue 533</a>)</li>
<li>Improve test coverage and forthcoming Python 3 support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/525">issue 525</a>)</li>
<li>Promote startup info on settings and middleware to INFO level (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/520">issue 520</a>)</li>
<li>Support partials in <cite>get_func_args</cite> util (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/506">issue 506</a>, issue:<cite>504</cite>)</li>
<li>Allow running indiviual tests via tox (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/503">issue 503</a>)</li>
<li>Update extensions ignored by link extractors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/498">issue 498</a>)</li>
<li>Add middleware methods to get files/images/thumbs paths (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/490">issue 490</a>)</li>
<li>Improve offsite middleware tests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/478">issue 478</a>)</li>
<li>Add a way to skip default Referer header set by RefererMiddleware (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/475">issue 475</a>)</li>
<li>Do not send <cite>x-gzip</cite> in default <cite>Accept-Encoding</cite> header (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/469">issue 469</a>)</li>
<li>Support defining http error handling using settings (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/466">issue 466</a>)</li>
<li>Use modern python idioms wherever you find legacies (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/497">issue 497</a>)</li>
<li>Improve and correct documentation
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/527">issue 527</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/524">issue 524</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/521">issue 521</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/517">issue 517</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/512">issue 512</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/505">issue 505</a>,
<a class="reference external" href="https://github.com/scrapy/scrapy/issues/502">issue 502</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/489">issue 489</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/465">issue 465</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/460">issue 460</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/425">issue 425</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/536">issue 536</a>)</li>
</ul>
</div>
<div class="section" id="fixes">
<h3>Fixes<a class="headerlink" href="#fixes" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Update Selector class imports in CrawlSpider template (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/484">issue 484</a>)</li>
<li>Fix unexistent reference to <cite>engine.slots</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/464">issue 464</a>)</li>
<li>Do not try to call <cite>body_as_unicode()</cite> on a non-TextResponse instance (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/462">issue 462</a>)</li>
<li>Warn when subclassing XPathItemLoader, previously it only warned on
instantiation. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/523">issue 523</a>)</li>
<li>Warn when subclassing XPathSelector, previously it only warned on
instantiation. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/537">issue 537</a>)</li>
<li>Multiple fixes to memory stats (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/531">issue 531</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/530">issue 530</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/529">issue 529</a>)</li>
<li>Fix overriding url in <cite>FormRequest.from_response()</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/507">issue 507</a>)</li>
<li>Fix tests runner under pip 1.5 (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/513">issue 513</a>)</li>
<li>Fix logging error when spider name is unicode (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/479">issue 479</a>)</li>
</ul>
</div>
</div>
<div class="section" id="released-2013-12-09">
<h2>0.20.2 (released 2013-12-09)<a class="headerlink" href="#released-2013-12-09" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>Update CrawlSpider Template with Selector changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6d1457d">commit 6d1457d</a>)</li>
<li>fix method name in tutorial. closes GH-480 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b4fc359">commit b4fc359</a></li>
</ul>
</div>
<div class="section" id="released-2013-11-28">
<h2>0.20.1 (released 2013-11-28)<a class="headerlink" href="#released-2013-11-28" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>include_package_data is required to build wheels from published sources (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5ba1ad5">commit 5ba1ad5</a>)</li>
<li>process_parallel was leaking the failures on its internal deferreds.  closes #458 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/419a780">commit 419a780</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-11-08">
<h2>0.20.0 (released 2013-11-08)<a class="headerlink" href="#released-2013-11-08" title="永久链接至标题">¶</a></h2>
<div class="section" id="id7">
<h3>Enhancements<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>New Selector&#8217;s API including CSS selectors (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/395">issue 395</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/426">issue 426</a>),</li>
<li>Request/Response url/body attributes are now immutable
(modifying them had been deprecated for a long time)</li>
<li><a class="reference internal" href="topics/settings.html#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></code></a> is now defined as a dict (instead of a list)</li>
<li>Sitemap spider can fetch alternate URLs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/360">issue 360</a>)</li>
<li><cite>Selector.remove_namespaces()</cite> now remove namespaces from element&#8217;s attributes. (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/416">issue 416</a>)</li>
<li>Paved the road for Python 3.3+ (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/435">issue 435</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/436">issue 436</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/431">issue 431</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/452">issue 452</a>)</li>
<li>New item exporter using native python types with nesting support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/366">issue 366</a>)</li>
<li>Tune HTTP1.1 pool size so it matches concurrency defined by settings (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b43b5f575">commit b43b5f575</a>)</li>
<li>scrapy.mail.MailSender now can connect over TLS or upgrade using STARTTLS (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/327">issue 327</a>)</li>
<li>New FilesPipeline with functionality factored out from ImagesPipeline (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/370">issue 370</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/409">issue 409</a>)</li>
<li>Recommend Pillow instead of PIL for image handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/317">issue 317</a>)</li>
<li>Added debian packages for Ubuntu quantal and raring (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/86230c0">commit 86230c0</a>)</li>
<li>Mock server (used for tests) can listen for HTTPS requests (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/410">issue 410</a>)</li>
<li>Remove multi spider support from multiple core components
(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/422">issue 422</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/421">issue 421</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/420">issue 420</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/419">issue 419</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/423">issue 423</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/418">issue 418</a>)</li>
<li>Travis-CI now tests Scrapy changes against development versions of <cite>w3lib</cite> and <cite>queuelib</cite> python packages.</li>
<li>Add pypy 2.1 to continuous integration tests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ecfa7431">commit ecfa7431</a>)</li>
<li>Pylinted, pep8 and removed old-style exceptions from source (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/430">issue 430</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/432">issue 432</a>)</li>
<li>Use importlib for parametric imports (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/445">issue 445</a>)</li>
<li>Handle a regression introduced in Python 2.7.5 that affects XmlItemExporter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/372">issue 372</a>)</li>
<li>Bugfix crawling shutdown on SIGINT (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/450">issue 450</a>)</li>
<li>Do not submit <cite>reset</cite> type inputs in FormRequest.from_response (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b326b87">commit b326b87</a>)</li>
<li>Do not silence download errors when request errback raises an exception (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/684cfc0">commit 684cfc0</a>)</li>
</ul>
</div>
<div class="section" id="id8">
<h3>Bugfixes<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Fix tests under Django 1.6 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b6bed44c">commit b6bed44c</a>)</li>
<li>Lot of bugfixes to retry middleware under disconnections using HTTP 1.1 download handler</li>
<li>Fix inconsistencies among Twisted releases (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/406">issue 406</a>)</li>
<li>Fix scrapy shell bugs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/418">issue 418</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/407">issue 407</a>)</li>
<li>Fix invalid variable name in setup.py (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/429">issue 429</a>)</li>
<li>Fix tutorial references (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/387">issue 387</a>)</li>
<li>Improve request-response docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/391">issue 391</a>)</li>
<li>Improve best practices docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/399">issue 399</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/400">issue 400</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/401">issue 401</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/402">issue 402</a>)</li>
<li>Improve django integration docs (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/404">issue 404</a>)</li>
<li>Document <cite>bindaddress</cite> request meta (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/37c24e01d7">commit 37c24e01d7</a>)</li>
<li>Improve <cite>Request</cite> class documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/226">issue 226</a>)</li>
</ul>
</div>
<div class="section" id="other">
<h3>Other<a class="headerlink" href="#other" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Dropped Python 2.6 support (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/448">issue 448</a>)</li>
<li>Add <a class="reference external" href="https://github.com/SimonSapin/cssselect">cssselect</a> python package as install dependency</li>
<li>Drop libxml2 and multi selector&#8217;s backend support, <a class="reference external" href="http://lxml.de/">lxml</a> is required from now on.</li>
<li>Minimum Twisted version increased to 10.0.0, dropped Twisted 8.0 support.</li>
<li>Running test suite now requires <cite>mock</cite> python library (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/390">issue 390</a>)</li>
</ul>
</div>
<div class="section" id="thanks">
<h3>Thanks<a class="headerlink" href="#thanks" title="永久链接至标题">¶</a></h3>
<p>Thanks to everyone who contribute to this release!</p>
<p>List of contributors sorted by number of commits:</p>
<div class="highlight-python"><div class="highlight"><pre>69 Daniel Graña &lt;dangra@...&gt;
37 Pablo Hoffman &lt;pablo@...&gt;
13 Mikhail Korobov &lt;kmike84@...&gt;
 9 Alex Cepoi &lt;alex.cepoi@...&gt;
 9 alexanderlukanin13 &lt;alexander.lukanin.13@...&gt;
 8 Rolando Espinoza La fuente &lt;darkrho@...&gt;
 8 Lukasz Biedrycki &lt;lukasz.biedrycki@...&gt;
 6 Nicolas Ramirez &lt;nramirez.uy@...&gt;
 3 Paul Tremberth &lt;paul.tremberth@...&gt;
 2 Martin Olveyra &lt;molveyra@...&gt;
 2 Stefan &lt;misc@...&gt;
 2 Rolando Espinoza &lt;darkrho@...&gt;
 2 Loren Davie &lt;loren@...&gt;
 2 irgmedeiros &lt;irgmedeiros@...&gt;
 1 Stefan Koch &lt;taikano@...&gt;
 1 Stefan &lt;cct@...&gt;
 1 scraperdragon &lt;dragon@...&gt;
 1 Kumara Tharmalingam &lt;ktharmal@...&gt;
 1 Francesco Piccinno &lt;stack.box@...&gt;
 1 Marcos Campal &lt;duendex@...&gt;
 1 Dragon Dave &lt;dragon@...&gt;
 1 Capi Etheriel &lt;barraponto@...&gt;
 1 cacovsky &lt;amarquesferraz@...&gt;
 1 Berend Iwema &lt;berend@...&gt;
</pre></div>
</div>
</div>
</div>
<div class="section" id="released-2013-10-10">
<h2>0.18.4 (released 2013-10-10)<a class="headerlink" href="#released-2013-10-10" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>IPython refuses to update the namespace. fix #396 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3d32c4f">commit 3d32c4f</a>)</li>
<li>Fix AlreadyCalledError replacing a request in shell command. closes #407 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b1d8919">commit b1d8919</a>)</li>
<li>Fix start_requests laziness and early hangs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/89faf52">commit 89faf52</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-10-03">
<h2>0.18.3 (released 2013-10-03)<a class="headerlink" href="#released-2013-10-03" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>fix regression on lazy evaluation of start requests (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/12693a5">commit 12693a5</a>)</li>
<li>forms: do not submit reset inputs (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e429f63">commit e429f63</a>)</li>
<li>increase unittest timeouts to decrease travis false positive failures (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/912202e">commit 912202e</a>)</li>
<li>backport master fixes to json exporter (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/cfc2d46">commit cfc2d46</a>)</li>
<li>Fix permission and set umask before generating sdist tarball (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/06149e0">commit 06149e0</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-09-03">
<h2>0.18.2 (released 2013-09-03)<a class="headerlink" href="#released-2013-09-03" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>Backport <cite>scrapy check</cite> command fixes and backward compatible multi
crawler process(<a class="reference external" href="https://github.com/scrapy/scrapy/issues/339">issue 339</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-08-27">
<h2>0.18.1 (released 2013-08-27)<a class="headerlink" href="#released-2013-08-27" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>remove extra import added by cherry picked changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d20304e">commit d20304e</a>)</li>
<li>fix crawling tests under twisted pre 11.0.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1994f38">commit 1994f38</a>)</li>
<li>py26 can not format zero length fields {} (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/abf756f">commit abf756f</a>)</li>
<li>test PotentiaDataLoss errors on unbound responses (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b15470d">commit b15470d</a>)</li>
<li>Treat responses without content-length or Transfer-Encoding as good responses (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c4bf324">commit c4bf324</a>)</li>
<li>do no include ResponseFailed if http11 handler is not enabled (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6cbe684">commit 6cbe684</a>)</li>
<li>New HTTP client wraps connection losts in ResponseFailed exception. fix #373 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1a20bba">commit 1a20bba</a>)</li>
<li>limit travis-ci build matrix (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3b01bb8">commit 3b01bb8</a>)</li>
<li>Merge pull request #375 from peterarenot/patch-1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa766d7">commit fa766d7</a>)</li>
<li>Fixed so it refers to the correct folder (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3283809">commit 3283809</a>)</li>
<li>added quantal &amp; raring to support ubuntu releases (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1411923">commit 1411923</a>)</li>
<li>fix retry middleware which didn&#8217;t retry certain connection errors after the upgrade to http1 client, closes GH-373 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bb35ed0">commit bb35ed0</a>)</li>
<li>fix XmlItemExporter in Python 2.7.4 and 2.7.5 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/de3e451">commit de3e451</a>)</li>
<li>minor updates to 0.18 release notes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c45e5f1">commit c45e5f1</a>)</li>
<li>fix contributters list format (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0b60031">commit 0b60031</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-08-09">
<h2>0.18.0 (released 2013-08-09)<a class="headerlink" href="#released-2013-08-09" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>Lot of improvements to testsuite run using Tox, including a way to test on pypi</li>
<li>Handle GET parameters for AJAX crawleable urls (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3fe2a32">commit 3fe2a32</a>)</li>
<li>Use lxml recover option to parse sitemaps (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/347">issue 347</a>)</li>
<li>Bugfix cookie merging by hostname and not by netloc (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/352">issue 352</a>)</li>
<li>Support disabling <cite>HttpCompressionMiddleware</cite> using a flag setting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/359">issue 359</a>)</li>
<li>Support xml namespaces using <cite>iternodes</cite> parser in <cite>XMLFeedSpider</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/12">issue 12</a>)</li>
<li>Support <cite>dont_cache</cite> request meta flag (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/19">issue 19</a>)</li>
<li>Bugfix <cite>scrapy.utils.gz.gunzip</cite> broken by changes in python 2.7.4 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4dc76e">commit 4dc76e</a>)</li>
<li>Bugfix url encoding on <cite>SgmlLinkExtractor</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/24">issue 24</a>)</li>
<li>Bugfix <cite>TakeFirst</cite> processor shouldn&#8217;t discard zero (0) value (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/59">issue 59</a>)</li>
<li>Support nested items in xml exporter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/66">issue 66</a>)</li>
<li>Improve cookies handling performance (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/77">issue 77</a>)</li>
<li>Log dupe filtered requests once (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/105">issue 105</a>)</li>
<li>Split redirection middleware into status and meta based middlewares (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/78">issue 78</a>)</li>
<li>Use HTTP1.1 as default downloader handler (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/109">issue 109</a> and <a class="reference external" href="https://github.com/scrapy/scrapy/issues/318">issue 318</a>)</li>
<li>Support xpath form selection on <cite>FormRequest.from_response</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/185">issue 185</a>)</li>
<li>Bugfix unicode decoding error on <cite>SgmlLinkExtractor</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/199">issue 199</a>)</li>
<li>Bugfix signal dispatching on pypi interpreter (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/205">issue 205</a>)</li>
<li>Improve request delay and concurrency handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/206">issue 206</a>)</li>
<li>Add RFC2616 cache policy to <cite>HttpCacheMiddleware</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/212">issue 212</a>)</li>
<li>Allow customization of messages logged by engine (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/214">issue 214</a>)</li>
<li>Multiples improvements to <cite>DjangoItem</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/217">issue 217</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/218">issue 218</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/issues/221">issue 221</a>)</li>
<li>Extend Scrapy commands using setuptools entry points (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/260">issue 260</a>)</li>
<li>Allow spider <cite>allowed_domains</cite> value to be set/tuple (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/261">issue 261</a>)</li>
<li>Support <cite>settings.getdict</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/269">issue 269</a>)</li>
<li>Simplify internal <cite>scrapy.core.scraper</cite> slot handling (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/271">issue 271</a>)</li>
<li>Added <cite>Item.copy</cite> (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/290">issue 290</a>)</li>
<li>Collect idle downloader slots (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/297">issue 297</a>)</li>
<li>Add <cite>ftp://</cite> scheme downloader handler (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/329">issue 329</a>)</li>
<li>Added downloader benchmark webserver and spider tools <a class="reference internal" href="topics/benchmarking.html#benchmarking"><span>Benchmarking</span></a></li>
<li>Moved persistent (on disk) queues to a separate project (<a class="reference external" href="https://github.com/scrapy/queuelib">queuelib</a>) which scrapy now depends on</li>
<li>Add scrapy commands using external libraries (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/260">issue 260</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">--pdb</span></code> option to <code class="docutils literal"><span class="pre">scrapy</span></code> command line tool</li>
<li>Added <code class="xref py py-meth docutils literal"><span class="pre">XPathSelector.remove_namespaces()</span></code> which allows to remove all namespaces from XML documents for convenience (to work with namespace-less XPaths). Documented in <a class="reference internal" href="topics/selectors.html#topics-selectors"><span>选择器(Selectors)</span></a>.</li>
<li>Several improvements to spider contracts</li>
<li>New default middleware named MetaRefreshMiddldeware that handles meta-refresh html tag redirections,</li>
<li>MetaRefreshMiddldeware and RedirectMiddleware have different priorities to address #62</li>
<li>added from_crawler method to spiders</li>
<li>added system tests with mock server</li>
<li>more improvements to Mac OS compatibility (thanks Alex Cepoi)</li>
<li>several more cleanups to singletons and multi-spider support (thanks Nicolas Ramirez)</li>
<li>support custom download slots</li>
<li>added &#8211;spider option to &#8220;shell&#8221; command.</li>
<li>log overridden settings when scrapy starts</li>
</ul>
<p>Thanks to everyone who contribute to this release. Here is a list of
contributors sorted by number of commits:</p>
<div class="highlight-python"><div class="highlight"><pre>130 Pablo Hoffman &lt;pablo@...&gt;
 97 Daniel Graña &lt;dangra@...&gt;
 20 Nicolás Ramírez &lt;nramirez.uy@...&gt;
 13 Mikhail Korobov &lt;kmike84@...&gt;
 12 Pedro Faustino &lt;pedrobandim@...&gt;
 11 Steven Almeroth &lt;sroth77@...&gt;
  5 Rolando Espinoza La fuente &lt;darkrho@...&gt;
  4 Michal Danilak &lt;mimino.coder@...&gt;
  4 Alex Cepoi &lt;alex.cepoi@...&gt;
  4 Alexandr N Zamaraev (aka tonal) &lt;tonal@...&gt;
  3 paul &lt;paul.tremberth@...&gt;
  3 Martin Olveyra &lt;molveyra@...&gt;
  3 Jordi Llonch &lt;llonchj@...&gt;
  3 arijitchakraborty &lt;myself.arijit@...&gt;
  2 Shane Evans &lt;shane.evans@...&gt;
  2 joehillen &lt;joehillen@...&gt;
  2 Hart &lt;HartSimha@...&gt;
  2 Dan &lt;ellisd23@...&gt;
  1 Zuhao Wan &lt;wanzuhao@...&gt;
  1 whodatninja &lt;blake@...&gt;
  1 vkrest &lt;v.krestiannykov@...&gt;
  1 tpeng &lt;pengtaoo@...&gt;
  1 Tom Mortimer-Jones &lt;tom@...&gt;
  1 Rocio Aramberri &lt;roschegel@...&gt;
  1 Pedro &lt;pedro@...&gt;
  1 notsobad &lt;wangxiaohugg@...&gt;
  1 Natan L &lt;kuyanatan.nlao@...&gt;
  1 Mark Grey &lt;mark.grey@...&gt;
  1 Luan &lt;luanpab@...&gt;
  1 Libor Nenadál &lt;libor.nenadal@...&gt;
  1 Juan M Uys &lt;opyate@...&gt;
  1 Jonas Brunsgaard &lt;jonas.brunsgaard@...&gt;
  1 Ilya Baryshev &lt;baryshev@...&gt;
  1 Hasnain Lakhani &lt;m.hasnain.lakhani@...&gt;
  1 Emanuel Schorsch &lt;emschorsch@...&gt;
  1 Chris Tilden &lt;chris.tilden@...&gt;
  1 Capi Etheriel &lt;barraponto@...&gt;
  1 cacovsky &lt;amarquesferraz@...&gt;
  1 Berend Iwema &lt;berend@...&gt;
</pre></div>
</div>
</div>
<div class="section" id="released-2013-05-30">
<h2>0.16.5 (released 2013-05-30)<a class="headerlink" href="#released-2013-05-30" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>obey request method when scrapy deploy is redirected to a new endpoint (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8c4fcee">commit 8c4fcee</a>)</li>
<li>fix inaccurate downloader middleware documentation. refs #280 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/40667cb">commit 40667cb</a>)</li>
<li>doc: remove links to diveintopython.org, which is no longer available. closes #246 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bd58bfa">commit bd58bfa</a>)</li>
<li>Find form nodes in invalid html5 documents (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e3d6945">commit e3d6945</a>)</li>
<li>Fix typo labeling attrs type bool instead of list (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a274276">commit a274276</a>)</li>
</ul>
</div>
<div class="section" id="released-2013-01-23">
<h2>0.16.4 (released 2013-01-23)<a class="headerlink" href="#released-2013-01-23" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>fixes spelling errors in documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6d2b3aa">commit 6d2b3aa</a>)</li>
<li>add doc about disabling an extension. refs #132 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c90de33">commit c90de33</a>)</li>
<li>Fixed error message formatting. log.err() doesn&#8217;t support cool formatting and when error occurred, the message was:    &#8220;ERROR: Error processing %(item)s&#8221; (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c16150c">commit c16150c</a>)</li>
<li>lint and improve images pipeline error logging (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/56b45fc">commit 56b45fc</a>)</li>
<li>fixed doc typos (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/243be84">commit 243be84</a>)</li>
<li>add documentation topics: Broad Crawls &amp; Common Practies (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1fbb715">commit 1fbb715</a>)</li>
<li>fix bug in scrapy parse command when spider is not specified explicitly. closes #209 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c72e682">commit c72e682</a>)</li>
<li>Update docs/topics/commands.rst (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/28eac7a">commit 28eac7a</a>)</li>
</ul>
</div>
<div class="section" id="released-2012-12-07">
<h2>0.16.3 (released 2012-12-07)<a class="headerlink" href="#released-2012-12-07" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>Remove concurrency limitation when using download delays and still ensure inter-request delays are enforced (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/487b9b5">commit 487b9b5</a>)</li>
<li>add error details when image pipeline fails (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8232569">commit 8232569</a>)</li>
<li>improve mac os compatibility (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8dcf8aa">commit 8dcf8aa</a>)</li>
<li>setup.py: use README.rst to populate long_description (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7b5310d">commit 7b5310d</a>)</li>
<li>doc: removed obsolete references to ClientForm (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/80f9bb6">commit 80f9bb6</a>)</li>
<li>correct docs for default storage backend (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2aa491b">commit 2aa491b</a>)</li>
<li>doc: removed broken proxyhub link from FAQ (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bdf61c4">commit bdf61c4</a>)</li>
<li>Fixed docs typo in SpiderOpenCloseLogging example (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/7184094">commit 7184094</a>)</li>
</ul>
</div>
<div class="section" id="released-2012-11-09">
<h2>0.16.2 (released 2012-11-09)<a class="headerlink" href="#released-2012-11-09" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>scrapy contracts: python2.6 compat (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/a4a9199">commit a4a9199</a>)</li>
<li>scrapy contracts verbose option (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ec41673">commit ec41673</a>)</li>
<li>proper unittest-like output for scrapy contracts (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/86635e4">commit 86635e4</a>)</li>
<li>added open_in_browser to debugging doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c9b690d">commit c9b690d</a>)</li>
<li>removed reference to global scrapy stats from settings doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/dd55067">commit dd55067</a>)</li>
<li>Fix SpiderState bug in Windows platforms (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/58998f4">commit 58998f4</a>)</li>
</ul>
</div>
<div class="section" id="released-2012-10-26">
<h2>0.16.1 (released 2012-10-26)<a class="headerlink" href="#released-2012-10-26" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>fixed LogStats extension, which got broken after a wrong merge before the 0.16 release (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8c780fd">commit 8c780fd</a>)</li>
<li>better backwards compatibility for scrapy.conf.settings (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/3403089">commit 3403089</a>)</li>
<li>extended documentation on how to access crawler stats from extensions (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c4da0b5">commit c4da0b5</a>)</li>
<li>removed .hgtags (no longer needed now that scrapy uses git) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/d52c188">commit d52c188</a>)</li>
<li>fix dashes under rst headers (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fa4f7f9">commit fa4f7f9</a>)</li>
<li>set release date for 0.16.0 in news (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/e292246">commit e292246</a>)</li>
</ul>
</div>
<div class="section" id="released-2012-10-18">
<h2>0.16.0 (released 2012-10-18)<a class="headerlink" href="#released-2012-10-18" title="永久链接至标题">¶</a></h2>
<p>Scrapy changes:</p>
<ul class="simple">
<li>added <a class="reference internal" href="topics/contracts.html#topics-contracts"><span>Spiders Contracts</span></a>, a mechanism for testing spiders in a formal/reproducible way</li>
<li>added options <code class="docutils literal"><span class="pre">-o</span></code> and <code class="docutils literal"><span class="pre">-t</span></code> to the <a class="reference internal" href="topics/commands.html#std:command-runspider"><code class="xref std std-command docutils literal"><span class="pre">runspider</span></code></a> command</li>
<li>documented <a class="reference internal" href="topics/autothrottle.html"><em>自动限速(AutoThrottle)扩展</em></a> and added to extensions installed by default. You still need to enable it with <a class="reference internal" href="topics/autothrottle.html#std:setting-AUTOTHROTTLE_ENABLED"><code class="xref std std-setting docutils literal"><span class="pre">AUTOTHROTTLE_ENABLED</span></code></a></li>
<li>major Stats Collection refactoring: removed separation of global/per-spider stats, removed stats-related signals (<code class="docutils literal"><span class="pre">stats_spider_opened</span></code>, etc). Stats are much simpler now, backwards compatibility is kept on the Stats Collector API and signals.</li>
<li>added <a class="reference internal" href="topics/spider-middleware.html#scrapy.contrib.spidermiddleware.SpiderMiddleware.process_start_requests" title="scrapy.contrib.spidermiddleware.SpiderMiddleware.process_start_requests"><code class="xref py py-meth docutils literal"><span class="pre">process_start_requests()</span></code></a> method to spider middlewares</li>
<li>dropped Signals singleton. Signals should now be accesed through the Crawler.signals attribute. See the signals documentation for more info.</li>
<li>dropped Signals singleton. Signals should now be accesed through the Crawler.signals attribute. See the signals documentation for more info.</li>
<li>dropped Stats Collector singleton. Stats can now be accessed through the Crawler.stats attribute. See the stats collection documentation for more info.</li>
<li>documented <a class="reference internal" href="topics/api.html#topics-api"><span>核心API</span></a></li>
<li><cite>lxml</cite> is now the default selectors backend instead of <cite>libxml2</cite></li>
<li>ported FormRequest.from_response() to use <a class="reference external" href="http://lxml.de/">lxml</a> instead of <a class="reference external" href="http://wwwsearch.sourceforge.net/old/ClientForm/">ClientForm</a></li>
<li>removed modules: <code class="docutils literal"><span class="pre">scrapy.xlib.BeautifulSoup</span></code> and <code class="docutils literal"><span class="pre">scrapy.xlib.ClientForm</span></code></li>
<li>SitemapSpider: added support for sitemap urls ending in .xml and .xml.gz, even if they advertise a wrong content type (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/10ed28b">commit 10ed28b</a>)</li>
<li>StackTraceDump extension: also dump trackref live references (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fe2ce93">commit fe2ce93</a>)</li>
<li>nested items now fully supported in JSON and JSONLines exporters</li>
<li>added <a class="reference internal" href="topics/downloader-middleware.html#std:reqmeta-cookiejar"><code class="xref std std-reqmeta docutils literal"><span class="pre">cookiejar</span></code></a> Request meta key to support multiple cookie sessions per spider</li>
<li>decoupled encoding detection code to <a class="reference external" href="https://github.com/scrapy/w3lib/blob/master/w3lib/encoding.py">w3lib.encoding</a>, and ported Scrapy code to use that mdule</li>
<li>dropped support for Python 2.5. See <a class="reference external" href="http://blog.scrapinghub.com/2012/02/27/scrapy-0-15-dropping-support-for-python-2-5/">http://blog.scrapinghub.com/2012/02/27/scrapy-0-15-dropping-support-for-python-2-5/</a></li>
<li>dropped support for Twisted 2.5</li>
<li>added <a class="reference internal" href="topics/spider-middleware.html#std:setting-REFERER_ENABLED"><code class="xref std std-setting docutils literal"><span class="pre">REFERER_ENABLED</span></code></a> setting, to control referer middleware</li>
<li>changed default user agent to: <code class="docutils literal"><span class="pre">Scrapy/VERSION</span> <span class="pre">(+http://scrapy.org)</span></code></li>
<li>removed (undocumented) <code class="docutils literal"><span class="pre">HTMLImageLinkExtractor</span></code> class from <code class="docutils literal"><span class="pre">scrapy.contrib.linkextractors.image</span></code></li>
<li>removed per-spider settings (to be replaced by instantiating multiple crawler objects)</li>
<li><code class="docutils literal"><span class="pre">USER_AGENT</span></code> spider attribute will no longer work, use <code class="docutils literal"><span class="pre">user_agent</span></code> attribute instead</li>
<li><code class="docutils literal"><span class="pre">DOWNLOAD_TIMEOUT</span></code> spider attribute will no longer work, use <code class="docutils literal"><span class="pre">download_timeout</span></code> attribute instead</li>
<li>removed <code class="docutils literal"><span class="pre">ENCODING_ALIASES</span></code> setting, as encoding auto-detection has been moved to the <a class="reference external" href="https://github.com/scrapy/w3lib">w3lib</a> library</li>
<li>promoted <a class="reference internal" href="topics/djangoitem.html#topics-djangoitem"><span>DjangoItem</span></a> to main contrib</li>
<li>LogFormatter method now return dicts(instead of strings) to support lazy formatting (<a class="reference external" href="https://github.com/scrapy/scrapy/issues/164">issue 164</a>, <a class="reference external" href="https://github.com/scrapy/scrapy/commit/dcef7b0">commit dcef7b0</a>)</li>
<li>downloader handlers (<a class="reference internal" href="topics/settings.html#std:setting-DOWNLOAD_HANDLERS"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_HANDLERS</span></code></a> setting) now receive settings as the first argument of the constructor</li>
<li>replaced memory usage acounting with (more portable) <a class="reference external" href="http://docs.python.org/library/resource.html">resource</a> module, removed <code class="docutils literal"><span class="pre">scrapy.utils.memory</span></code> module</li>
<li>removed signal: <code class="docutils literal"><span class="pre">scrapy.mail.mail_sent</span></code></li>
<li>removed <code class="docutils literal"><span class="pre">TRACK_REFS</span></code> setting, now <a class="reference internal" href="topics/leaks.html#topics-leaks-trackrefs"><span>trackrefs</span></a> is always enabled</li>
<li>DBM is now the default storage backend for HTTP cache middleware</li>
<li>number of log messages (per level) are now tracked through Scrapy stats (stat name: <code class="docutils literal"><span class="pre">log_count/LEVEL</span></code>)</li>
<li>number received responses are now tracked through Scrapy stats (stat name: <code class="docutils literal"><span class="pre">response_received_count</span></code>)</li>
<li>removed <code class="docutils literal"><span class="pre">scrapy.log.started</span></code> attribute</li>
</ul>
</div>
<div class="section" id="id9">
<h2>0.14.4<a class="headerlink" href="#id9" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>added precise to supported ubuntu distros (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7e46df">commit b7e46df</a>)</li>
<li>fixed bug in json-rpc webservice reported in <a class="reference external" href="https://groups.google.com/d/topic/scrapy-users/qgVBmFybNAQ/discussion">https://groups.google.com/d/topic/scrapy-users/qgVBmFybNAQ/discussion</a>. also removed no longer supported &#8216;run&#8217; command from extras/scrapy-ws.py (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/340fbdb">commit 340fbdb</a>)</li>
<li>meta tag attributes for content-type http equiv can be in any order. #123 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0cb68af">commit 0cb68af</a>)</li>
<li>replace &#8220;import Image&#8221; by more standard &#8220;from PIL import Image&#8221;. closes #88 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4d17048">commit 4d17048</a>)</li>
<li>return trial status as bin/runtests.sh exit value. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b7b2e7f">commit b7b2e7f</a>)</li>
</ul>
</div>
<div class="section" id="id10">
<h2>0.14.3<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>forgot to include pydispatch license. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/fd85f9c">commit fd85f9c</a>)</li>
<li>include egg files used by testsuite in source distribution. #118 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/c897793">commit c897793</a>)</li>
<li>update docstring in project template to avoid confusion with genspider command, which may be considered as an advanced feature. refs #107 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2548dcc">commit 2548dcc</a>)</li>
<li>added note to docs/topics/firebug.rst about google directory being shut down (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/668e352">commit 668e352</a>)</li>
<li>dont discard slot when empty, just save in another dict in order to recycle if needed again. (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8e9f607">commit 8e9f607</a>)</li>
<li>do not fail handling unicode xpaths in libxml2 backed selectors (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/b830e95">commit b830e95</a>)</li>
<li>fixed minor mistake in Request objects documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bf3c9ee">commit bf3c9ee</a>)</li>
<li>fixed minor defect in link extractors documentation (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/ba14f38">commit ba14f38</a>)</li>
<li>removed some obsolete remaining code related to sqlite support in scrapy (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0665175">commit 0665175</a>)</li>
</ul>
</div>
<div class="section" id="id11">
<h2>0.14.2<a class="headerlink" href="#id11" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>move buffer pointing to start of file before computing checksum. refs #92 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6a5bef2">commit 6a5bef2</a>)</li>
<li>Compute image checksum before persisting images. closes #92 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/9817df1">commit 9817df1</a>)</li>
<li>remove leaking references in cached failures (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/673a120">commit 673a120</a>)</li>
<li>fixed bug in MemoryUsage extension: get_engine_status() takes exactly 1 argument (0 given) (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/11133e9">commit 11133e9</a>)</li>
<li>fixed struct.error on http compression middleware. closes #87 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1423140">commit 1423140</a>)</li>
<li>ajax crawling wasn&#8217;t expanding for unicode urls (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0de3fb4">commit 0de3fb4</a>)</li>
<li>Catch start_requests iterator errors. refs #83 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/454a21d">commit 454a21d</a>)</li>
<li>Speed-up libxml2 XPathSelector (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2fbd662">commit 2fbd662</a>)</li>
<li>updated versioning doc according to recent changes (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/0a070f5">commit 0a070f5</a>)</li>
<li>scrapyd: fixed documentation link (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/2b4e4c3">commit 2b4e4c3</a>)</li>
<li>extras/makedeb.py: no longer obtaining version from git (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/caffe0e">commit caffe0e</a>)</li>
</ul>
</div>
<div class="section" id="id12">
<h2>0.14.1<a class="headerlink" href="#id12" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li>extras/makedeb.py: no longer obtaining version from git (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/caffe0e">commit caffe0e</a>)</li>
<li>bumped version to 0.14.1 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/6cb9e1c">commit 6cb9e1c</a>)</li>
<li>fixed reference to tutorial directory (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/4b86bd6">commit 4b86bd6</a>)</li>
<li>doc: removed duplicated callback argument from Request.replace() (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/1aeccdd">commit 1aeccdd</a>)</li>
<li>fixed formatting of scrapyd doc (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/8bf19e6">commit 8bf19e6</a>)</li>
<li>Dump stacks for all running threads and fix engine status dumped by StackTraceDump extension (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/14a8e6e">commit 14a8e6e</a>)</li>
<li>added comment about why we disable ssl on boto images upload (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/5223575">commit 5223575</a>)</li>
<li>SSL handshaking hangs when doing too many parallel connections to S3 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/63d583d">commit 63d583d</a>)</li>
<li>change tutorial to follow changes on dmoz site (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/bcb3198">commit bcb3198</a>)</li>
<li>Avoid _disconnectedDeferred AttributeError exception in Twisted&gt;=11.1.0 (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/98f3f87">commit 98f3f87</a>)</li>
<li>allow spider to set autothrottle max concurrency (<a class="reference external" href="https://github.com/scrapy/scrapy/commit/175a4b5">commit 175a4b5</a>)</li>
</ul>
</div>
<div class="section" id="id13">
<h2>0.14<a class="headerlink" href="#id13" title="永久链接至标题">¶</a></h2>
<div class="section" id="new-features-and-settings">
<h3>New features and settings<a class="headerlink" href="#new-features-and-settings" title="永久链接至标题">¶</a></h3>
<ul>
<li><p class="first">Support for <a class="reference external" href="http://code.google.com/web/ajaxcrawling/docs/getting-started.html">AJAX crawleable urls</a></p>
</li>
<li><p class="first">New persistent scheduler that stores requests on disk, allowing to suspend and resume crawls (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2737">r2737</a>)</p>
</li>
<li><p class="first">added <code class="docutils literal"><span class="pre">-o</span></code> option to <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">crawl</span></code>, a shortcut for dumping scraped items into a file (or standard output using <code class="docutils literal"><span class="pre">-</span></code>)</p>
</li>
<li><p class="first">Added support for passing custom settings to Scrapyd <code class="docutils literal"><span class="pre">schedule.json</span></code> api (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2779">r2779</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2783">r2783</a>)</p>
</li>
<li><p class="first">New <code class="docutils literal"><span class="pre">ChunkedTransferMiddleware</span></code> (enabled by default) to support <a class="reference external" href="http://en.wikipedia.org/wiki/Chunked_transfer_encoding">chunked transfer encoding</a> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2769">r2769</a>)</p>
</li>
<li><p class="first">Add boto 2.0 support for S3 downloader handler (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2763">r2763</a>)</p>
</li>
<li><p class="first">Added <a class="reference external" href="http://docs.python.org/library/marshal.html">marshal</a> to formats supported by feed exports (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2744">r2744</a>)</p>
</li>
<li><p class="first">In request errbacks, offending requests are now received in <cite>failure.request</cite> attribute (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2738">r2738</a>)</p>
</li>
<li><dl class="first docutils">
<dt>Big downloader refactoring to support per domain/ip concurrency limits (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2732">r2732</a>)</dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt><code class="docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_SPIDER</span></code> setting has been deprecated and replaced by:</dt>
<dd><ul class="first last simple">
<li><a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS"><code class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS</span></code></a>, <a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"><code class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_DOMAIN</span></code></a>, <a class="reference internal" href="topics/settings.html#std:setting-CONCURRENT_REQUESTS_PER_IP"><code class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></code></a></li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">check the documentation for more details</p>
</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Added builtin caching DNS resolver (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2728">r2728</a>)</p>
</li>
<li><p class="first">Moved Amazon AWS-related components/extensions (SQS spider queue, SimpleDB stats collector) to a separate project: [scaws](<a class="reference external" href="https://github.com/scrapinghub/scaws">https://github.com/scrapinghub/scaws</a>) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2706">r2706</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2714">r2714</a>)</p>
</li>
<li><p class="first">Moved spider queues to scrapyd: <cite>scrapy.spiderqueue</cite> -&gt; <cite>scrapyd.spiderqueue</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2708">r2708</a>)</p>
</li>
<li><p class="first">Moved sqlite utils to scrapyd: <cite>scrapy.utils.sqlite</cite> -&gt; <cite>scrapyd.sqlite</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2781">r2781</a>)</p>
</li>
<li><p class="first">Real support for returning iterators on <cite>start_requests()</cite> method. The iterator is now consumed during the crawl when the spider is getting idle (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</p>
</li>
<li><p class="first">Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-REDIRECT_ENABLED"><code class="xref std std-setting docutils literal"><span class="pre">REDIRECT_ENABLED</span></code></a> setting to quickly enable/disable the redirect middleware (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2697">r2697</a>)</p>
</li>
<li><p class="first">Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-RETRY_ENABLED"><code class="xref std std-setting docutils literal"><span class="pre">RETRY_ENABLED</span></code></a> setting to quickly enable/disable the retry middleware (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2694">r2694</a>)</p>
</li>
<li><p class="first">Added <code class="docutils literal"><span class="pre">CloseSpider</span></code> exception to manually close spiders (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2691">r2691</a>)</p>
</li>
<li><p class="first">Improved encoding detection by adding support for HTML5 meta charset declaration (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2690">r2690</a>)</p>
</li>
<li><p class="first">Refactored close spider behavior to wait for all downloads to finish and be processed by spiders, before closing the spider (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2688">r2688</a>)</p>
</li>
<li><p class="first">Added <code class="docutils literal"><span class="pre">SitemapSpider</span></code> (see documentation in Spiders page) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2658">r2658</a>)</p>
</li>
<li><p class="first">Added <code class="docutils literal"><span class="pre">LogStats</span></code> extension for periodically logging basic stats (like crawled pages and scraped items) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2657">r2657</a>)</p>
</li>
<li><p class="first">Make handling of gzipped responses more robust (#319, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2643">r2643</a>). Now Scrapy will try and decompress as much as possible from a gzipped response, instead of failing with an <cite>IOError</cite>.</p>
</li>
<li><p class="first">Simplified !MemoryDebugger extension to use stats for dumping memory debugging info (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2639">r2639</a>)</p>
</li>
<li><p class="first">Added new command to edit spiders: <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">edit</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2636">r2636</a>) and <cite>-e</cite> flag to <cite>genspider</cite> command that uses it (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2653">r2653</a>)</p>
</li>
<li><p class="first">Changed default representation of items to pretty-printed dicts. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2631">r2631</a>). This improves default logging by making log more readable in the default case, for both Scraped and Dropped lines.</p>
</li>
<li><p class="first">Added <a class="reference internal" href="topics/signals.html#std:signal-spider_error"><code class="xref std std-signal docutils literal"><span class="pre">spider_error</span></code></a> signal (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2628">r2628</a>)</p>
</li>
<li><p class="first">Added <a class="reference internal" href="topics/downloader-middleware.html#std:setting-COOKIES_ENABLED"><code class="xref std std-setting docutils literal"><span class="pre">COOKIES_ENABLED</span></code></a> setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2625">r2625</a>)</p>
</li>
<li><p class="first">Stats are now dumped to Scrapy log (default value of <a class="reference internal" href="topics/settings.html#std:setting-STATS_DUMP"><code class="xref std std-setting docutils literal"><span class="pre">STATS_DUMP</span></code></a> setting has been changed to <cite>True</cite>). This is to make Scrapy users more aware of Scrapy stats and the data that is collected there.</p>
</li>
<li><p class="first">Added support for dynamically adjusting download delay and maximum concurrent requests (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2599">r2599</a>)</p>
</li>
<li><p class="first">Added new DBM HTTP cache storage backend (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2576">r2576</a>)</p>
</li>
<li><p class="first">Added <code class="docutils literal"><span class="pre">listjobs.json</span></code> API to Scrapyd (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2571">r2571</a>)</p>
</li>
<li><p class="first"><code class="docutils literal"><span class="pre">CsvItemExporter</span></code>: added <code class="docutils literal"><span class="pre">join_multivalued</span></code> parameter (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2578">r2578</a>)</p>
</li>
<li><p class="first">Added namespace support to <code class="docutils literal"><span class="pre">xmliter_lxml</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2552">r2552</a>)</p>
</li>
<li><p class="first">Improved cookies middleware by making <cite>COOKIES_DEBUG</cite> nicer and documenting it (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2579">r2579</a>)</p>
</li>
<li><p class="first">Several improvements to Scrapyd and Link extractors</p>
</li>
</ul>
</div>
<div class="section" id="code-rearranged-and-removed">
<h3>Code rearranged and removed<a class="headerlink" href="#code-rearranged-and-removed" title="永久链接至标题">¶</a></h3>
<ul>
<li><dl class="first docutils">
<dt>Merged item passed and item scraped concepts, as they have often proved confusing in the past. This means: (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2630">r2630</a>)</dt>
<dd><ul class="first last simple">
<li>original item_scraped signal was removed</li>
<li>original item_passed signal was renamed to item_scraped</li>
<li>old log lines <code class="docutils literal"><span class="pre">Scraped</span> <span class="pre">Item...</span></code> were removed</li>
<li>old log lines <code class="docutils literal"><span class="pre">Passed</span> <span class="pre">Item...</span></code> were renamed to <code class="docutils literal"><span class="pre">Scraped</span> <span class="pre">Item...</span></code> lines and downgraded to <code class="docutils literal"><span class="pre">DEBUG</span></code> level</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Reduced Scrapy codebase by striping part of Scrapy code into two new libraries:</dt>
<dd><ul class="first last simple">
<li><a class="reference external" href="https://github.com/scrapy/w3lib">w3lib</a> (several functions from <code class="docutils literal"><span class="pre">scrapy.utils.{http,markup,multipart,response,url}</span></code>, done in <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2584">r2584</a>)</li>
<li><a class="reference external" href="https://github.com/scrapy/scrapely">scrapely</a> (was <code class="docutils literal"><span class="pre">scrapy.contrib.ibl</span></code>, done in <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2586">r2586</a>)</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Removed unused function: <cite>scrapy.utils.request.request_info()</cite> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2577">r2577</a>)</p>
</li>
<li><p class="first">Removed googledir project from <cite>examples/googledir</cite>. There&#8217;s now a new example project called <cite>dirbot</cite> available on github: <a class="reference external" href="https://github.com/scrapy/dirbot">https://github.com/scrapy/dirbot</a></p>
</li>
<li><p class="first">Removed support for default field values in Scrapy items (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2616">r2616</a>)</p>
</li>
<li><p class="first">Removed experimental crawlspider v2 (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2632">r2632</a>)</p>
</li>
<li><p class="first">Removed scheduler middleware to simplify architecture. Duplicates filter is now done in the scheduler itself, using the same dupe fltering class as before (<cite>DUPEFILTER_CLASS</cite> setting) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2640">r2640</a>)</p>
</li>
<li><p class="first">Removed support for passing urls to <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">crawl</span></code> command (use <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">parse</span></code> instead) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</p>
</li>
<li><p class="first">Removed deprecated Execution Queue (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2704">r2704</a>)</p>
</li>
<li><p class="first">Removed (undocumented) spider context extension (from scrapy.contrib.spidercontext) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2780">r2780</a>)</p>
</li>
<li><p class="first">removed <code class="docutils literal"><span class="pre">CONCURRENT_SPIDERS</span></code> setting (use scrapyd maxproc instead) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2789">r2789</a>)</p>
</li>
<li><p class="first">Renamed attributes of core components: downloader.sites -&gt; downloader.slots, scraper.sites -&gt; scraper.slots (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2717">r2717</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2718">r2718</a>)</p>
</li>
<li><p class="first">Renamed setting <code class="docutils literal"><span class="pre">CLOSESPIDER_ITEMPASSED</span></code> to <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_ITEMCOUNT"><code class="xref std std-setting docutils literal"><span class="pre">CLOSESPIDER_ITEMCOUNT</span></code></a> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2655">r2655</a>). Backwards compatibility kept.</p>
</li>
</ul>
</div>
</div>
<div class="section" id="id14">
<h2>0.12<a class="headerlink" href="#id14" title="永久链接至标题">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="new-features-and-improvements">
<h3>New features and improvements<a class="headerlink" href="#new-features-and-improvements" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Passed item is now sent in the <code class="docutils literal"><span class="pre">item</span></code> argument of the <code class="xref std std-signal docutils literal"><span class="pre">item_passed</span></code> (#273)</li>
<li>Added verbose option to <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">version</span></code> command, useful for bug reports (#298)</li>
<li>HTTP cache now stored by default in the project data dir (#279)</li>
<li>Added project data storage directory (#276, #277)</li>
<li>Documented file structure of Scrapy projects (see command-line tool doc)</li>
<li>New lxml backend for XPath selectors (#147)</li>
<li>Per-spider settings (#245)</li>
<li>Support exit codes to signal errors in Scrapy commands (#248)</li>
<li>Added <code class="docutils literal"><span class="pre">-c</span></code> argument to <code class="docutils literal"><span class="pre">scrapy</span> <span class="pre">shell</span></code> command</li>
<li>Made <code class="docutils literal"><span class="pre">libxml2</span></code> optional (#260)</li>
<li>New <code class="docutils literal"><span class="pre">deploy</span></code> command (#261)</li>
<li>Added <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_PAGECOUNT"><code class="xref std std-setting docutils literal"><span class="pre">CLOSESPIDER_PAGECOUNT</span></code></a> setting (#253)</li>
<li>Added <a class="reference internal" href="topics/extensions.html#std:setting-CLOSESPIDER_ERRORCOUNT"><code class="xref std std-setting docutils literal"><span class="pre">CLOSESPIDER_ERRORCOUNT</span></code></a> setting (#254)</li>
</ul>
</div>
<div class="section" id="scrapyd-changes">
<h3>Scrapyd changes<a class="headerlink" href="#scrapyd-changes" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Scrapyd now uses one process per spider</li>
<li>It stores one log file per spider run, and rotate them keeping the lastest 5 logs per spider (by default)</li>
<li>A minimal web ui was added, available at <a class="reference external" href="http://localhost:6800">http://localhost:6800</a> by default</li>
<li>There is now a <cite>scrapy server</cite> command to start a Scrapyd server of the current project</li>
</ul>
</div>
<div class="section" id="changes-to-settings">
<h3>Changes to settings<a class="headerlink" href="#changes-to-settings" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>added <cite>HTTPCACHE_ENABLED</cite> setting (False by default) to enable HTTP cache middleware</li>
<li>changed <cite>HTTPCACHE_EXPIRATION_SECS</cite> semantics: now zero means &#8220;never expire&#8221;.</li>
</ul>
</div>
<div class="section" id="deprecated-obsoleted-functionality">
<h3>Deprecated/obsoleted functionality<a class="headerlink" href="#deprecated-obsoleted-functionality" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Deprecated <code class="docutils literal"><span class="pre">runserver</span></code> command in favor of <code class="docutils literal"><span class="pre">server</span></code> command which starts a Scrapyd server. See also: Scrapyd changes</li>
<li>Deprecated <code class="docutils literal"><span class="pre">queue</span></code> command in favor of using Scrapyd <code class="docutils literal"><span class="pre">schedule.json</span></code> API. See also: Scrapyd changes</li>
<li>Removed the !LxmlItemLoader (experimental contrib which never graduated to main contrib)</li>
</ul>
</div>
</div>
<div class="section" id="id15">
<h2>0.10<a class="headerlink" href="#id15" title="永久链接至标题">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="id16">
<h3>New features and improvements<a class="headerlink" href="#id16" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>New Scrapy service called <code class="docutils literal"><span class="pre">scrapyd</span></code> for deploying Scrapy crawlers in production (#218) (documentation available)</li>
<li>Simplified Images pipeline usage which doesn&#8217;t require subclassing your own images pipeline now (#217)</li>
<li>Scrapy shell now shows the Scrapy log by default (#206)</li>
<li>Refactored execution queue in a common base code and pluggable backends called &#8220;spider queues&#8221; (#220)</li>
<li>New persistent spider queue (based on SQLite) (#198), available by default, which allows to start Scrapy in server mode and then schedule spiders to run.</li>
<li>Added documentation for Scrapy command-line tool and all its available sub-commands. (documentation available)</li>
<li>Feed exporters with pluggable backends (#197) (documentation available)</li>
<li>Deferred signals (#193)</li>
<li>Added two new methods to item pipeline open_spider(), close_spider() with deferred support (#195)</li>
<li>Support for overriding default request headers per spider (#181)</li>
<li>Replaced default Spider Manager with one with similar functionality but not depending on Twisted Plugins (#186)</li>
<li>Splitted Debian package into two packages - the library and the service (#187)</li>
<li>Scrapy log refactoring (#188)</li>
<li>New extension for keeping persistent spider contexts among different runs (#203)</li>
<li>Added <cite>dont_redirect</cite> request.meta key for avoiding redirects (#233)</li>
<li>Added <cite>dont_retry</cite> request.meta key for avoiding retries (#234)</li>
</ul>
</div>
<div class="section" id="command-line-tool-changes">
<h3>Command-line tool changes<a class="headerlink" href="#command-line-tool-changes" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>New <cite>scrapy</cite> command which replaces the old <cite>scrapy-ctl.py</cite> (#199)
- there is only one global <cite>scrapy</cite> command now, instead of one <cite>scrapy-ctl.py</cite> per project
- Added <cite>scrapy.bat</cite> script for running more conveniently from Windows</li>
<li>Added bash completion to command-line tool (#210)</li>
<li>Renamed command <cite>start</cite> to <cite>runserver</cite> (#209)</li>
</ul>
</div>
<div class="section" id="api-changes">
<h3>API changes<a class="headerlink" href="#api-changes" title="永久链接至标题">¶</a></h3>
<ul>
<li><p class="first"><code class="docutils literal"><span class="pre">url</span></code> and <code class="docutils literal"><span class="pre">body</span></code> attributes of Request objects are now read-only (#230)</p>
</li>
<li><p class="first"><code class="docutils literal"><span class="pre">Request.copy()</span></code> and <code class="docutils literal"><span class="pre">Request.replace()</span></code> now also copies their <code class="docutils literal"><span class="pre">callback</span></code> and <code class="docutils literal"><span class="pre">errback</span></code> attributes (#231)</p>
</li>
<li><p class="first">Removed <code class="docutils literal"><span class="pre">UrlFilterMiddleware</span></code> from <code class="docutils literal"><span class="pre">scrapy.contrib</span></code> (already disabled by default)</p>
</li>
<li><p class="first">Offsite middelware doesn&#8217;t filter out any request coming from a spider that doesn&#8217;t have a allowed_domains attribute (#225)</p>
</li>
<li><p class="first">Removed Spider Manager <code class="docutils literal"><span class="pre">load()</span></code> method. Now spiders are loaded in the constructor itself.</p>
</li>
<li><dl class="first docutils">
<dt>Changes to Scrapy Manager (now called &#8220;Crawler&#8221;):</dt>
<dd><ul class="first last simple">
<li><code class="docutils literal"><span class="pre">scrapy.core.manager.ScrapyManager</span></code> class renamed to <code class="docutils literal"><span class="pre">scrapy.crawler.Crawler</span></code></li>
<li><code class="docutils literal"><span class="pre">scrapy.core.manager.scrapymanager</span></code> singleton moved to <code class="docutils literal"><span class="pre">scrapy.project.crawler</span></code></li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Moved module: <code class="docutils literal"><span class="pre">scrapy.contrib.spidermanager</span></code> to <code class="docutils literal"><span class="pre">scrapy.spidermanager</span></code></p>
</li>
<li><p class="first">Spider Manager singleton moved from <code class="docutils literal"><span class="pre">scrapy.spider.spiders</span></code> to the <code class="docutils literal"><span class="pre">spiders`</span> <span class="pre">attribute</span> <span class="pre">of</span> <span class="pre">``scrapy.project.crawler</span></code> singleton.</p>
</li>
<li><dl class="first docutils">
<dt>moved Stats Collector classes: (#204)</dt>
<dd><ul class="first last simple">
<li><code class="docutils literal"><span class="pre">scrapy.stats.collector.StatsCollector</span></code> to <code class="docutils literal"><span class="pre">scrapy.statscol.StatsCollector</span></code></li>
<li><code class="docutils literal"><span class="pre">scrapy.stats.collector.SimpledbStatsCollector</span></code> to <code class="docutils literal"><span class="pre">scrapy.contrib.statscol.SimpledbStatsCollector</span></code></li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">default per-command settings are now specified in the <code class="docutils literal"><span class="pre">default_settings</span></code> attribute of command object class (#201)</p>
</li>
<li><dl class="first docutils">
<dt>changed arguments of Item pipeline <code class="docutils literal"><span class="pre">process_item()</span></code> method from <code class="docutils literal"><span class="pre">(spider,</span> <span class="pre">item)</span></code> to <code class="docutils literal"><span class="pre">(item,</span> <span class="pre">spider)</span></code></dt>
<dd><ul class="first last simple">
<li>backwards compatibility kept (with deprecation warning)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>moved <code class="docutils literal"><span class="pre">scrapy.core.signals</span></code> module to <code class="docutils literal"><span class="pre">scrapy.signals</span></code></dt>
<dd><ul class="first last simple">
<li>backwards compatibility kept (with deprecation warning)</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>moved <code class="docutils literal"><span class="pre">scrapy.core.exceptions</span></code> module to <code class="docutils literal"><span class="pre">scrapy.exceptions</span></code></dt>
<dd><ul class="first last simple">
<li>backwards compatibility kept (with deprecation warning)</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">added <code class="docutils literal"><span class="pre">handles_request()</span></code> class method to <code class="docutils literal"><span class="pre">BaseSpider</span></code></p>
</li>
<li><p class="first">dropped <code class="docutils literal"><span class="pre">scrapy.log.exc()</span></code> function (use <code class="docutils literal"><span class="pre">scrapy.log.err()</span></code> instead)</p>
</li>
<li><p class="first">dropped <code class="docutils literal"><span class="pre">component</span></code> argument of <code class="docutils literal"><span class="pre">scrapy.log.msg()</span></code> function</p>
</li>
<li><p class="first">dropped <code class="docutils literal"><span class="pre">scrapy.log.log_level</span></code> attribute</p>
</li>
<li><p class="first">Added <code class="docutils literal"><span class="pre">from_settings()</span></code> class methods to Spider Manager, and Item Pipeline Manager</p>
</li>
</ul>
</div>
<div class="section" id="id17">
<h3>Changes to settings<a class="headerlink" href="#id17" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Added <code class="docutils literal"><span class="pre">HTTPCACHE_IGNORE_SCHEMES</span></code> setting to ignore certain schemes on !HttpCacheMiddleware (#225)</li>
<li>Added <code class="docutils literal"><span class="pre">SPIDER_QUEUE_CLASS</span></code> setting which defines the spider queue to use (#220)</li>
<li>Added <code class="docutils literal"><span class="pre">KEEP_ALIVE</span></code> setting (#220)</li>
<li>Removed <code class="docutils literal"><span class="pre">SERVICE_QUEUE</span></code> setting (#220)</li>
<li>Removed <code class="docutils literal"><span class="pre">COMMANDS_SETTINGS_MODULE</span></code> setting (#201)</li>
<li>Renamed <code class="docutils literal"><span class="pre">REQUEST_HANDLERS</span></code> to <code class="docutils literal"><span class="pre">DOWNLOAD_HANDLERS</span></code> and make download handlers classes (instead of functions)</li>
</ul>
</div>
</div>
<div class="section" id="id18">
<h2>0.9<a class="headerlink" href="#id18" title="永久链接至标题">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="id19">
<h3>New features and improvements<a class="headerlink" href="#id19" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Added SMTP-AUTH support to scrapy.mail</li>
<li>New settings added: <code class="docutils literal"><span class="pre">MAIL_USER</span></code>, <code class="docutils literal"><span class="pre">MAIL_PASS</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2065">r2065</a> | #149)</li>
<li>Added new scrapy-ctl view command - To view URL in the browser, as seen by Scrapy (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2039">r2039</a>)</li>
<li>Added web service for controlling Scrapy process (this also deprecates the web console. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2053">r2053</a> | #167)</li>
<li>Support for running Scrapy as a service, for production systems (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1988">r1988</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2054">r2054</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2055">r2055</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2056">r2056</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2057">r2057</a> | #168)</li>
<li>Added wrapper induction library (documentation only available in source code for now). (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2011">r2011</a>)</li>
<li>Simplified and improved response encoding support (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1961">r1961</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1969">r1969</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">LOG_ENCODING</span></code> setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1956">r1956</a>, documentation available)</li>
<li>Added <code class="docutils literal"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></code> setting (enabled by default) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1923">r1923</a>, doc available)</li>
<li><code class="docutils literal"><span class="pre">MailSender</span></code> is no longer IO-blocking (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1955">r1955</a> | #146)</li>
<li>Linkextractors and new Crawlspider now handle relative base tag urls (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1960">r1960</a> | #148)</li>
<li>Several improvements to Item Loaders and processors (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2022">r2022</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2023">r2023</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2024">r2024</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2025">r2025</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2026">r2026</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2027">r2027</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2028">r2028</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2029">r2029</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2030">r2030</a>)</li>
<li>Added support for adding variables to telnet console (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2047">r2047</a> | #165)</li>
<li>Support for requests without callbacks (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2050">r2050</a> | #166)</li>
</ul>
</div>
<div class="section" id="id20">
<h3>API changes<a class="headerlink" href="#id20" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Change <code class="docutils literal"><span class="pre">Spider.domain_name</span></code> to <code class="docutils literal"><span class="pre">Spider.name</span></code> (SEP-012, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1975">r1975</a>)</li>
<li><code class="docutils literal"><span class="pre">Response.encoding</span></code> is now the detected encoding (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1961">r1961</a>)</li>
<li><code class="docutils literal"><span class="pre">HttpErrorMiddleware</span></code> now returns None or raises an exception (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2006">r2006</a> | #157)</li>
<li><code class="docutils literal"><span class="pre">scrapy.command</span></code> modules relocation (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2035">r2035</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2036">r2036</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2037">r2037</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">ExecutionQueue</span></code> for feeding spiders to scrape (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2034">r2034</a>)</li>
<li>Removed <code class="docutils literal"><span class="pre">ExecutionEngine</span></code> singleton (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2039">r2039</a>)</li>
<li>Ported <code class="docutils literal"><span class="pre">S3ImagesStore</span></code> (images pipeline) to use boto and threads (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2033">r2033</a>)</li>
<li>Moved module: <code class="docutils literal"><span class="pre">scrapy.management.telnet</span></code> to <code class="docutils literal"><span class="pre">scrapy.telnet</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/2047">r2047</a>)</li>
</ul>
</div>
<div class="section" id="changes-to-default-settings">
<h3>Changes to default settings<a class="headerlink" href="#changes-to-default-settings" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Changed default <code class="docutils literal"><span class="pre">SCHEDULER_ORDER</span></code> to <code class="docutils literal"><span class="pre">DFO</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1939">r1939</a>)</li>
</ul>
</div>
</div>
<div class="section" id="id21">
<h2>0.8<a class="headerlink" href="#id21" title="永久链接至标题">¶</a></h2>
<p>The numbers like #NNN reference tickets in the old issue tracker (Trac) which is no longer available.</p>
<div class="section" id="new-features">
<h3>New features<a class="headerlink" href="#new-features" title="永久链接至标题">¶</a></h3>
<ul class="simple">
<li>Added DEFAULT_RESPONSE_ENCODING setting (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1809">r1809</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">dont_click</span></code> argument to <code class="docutils literal"><span class="pre">FormRequest.from_response()</span></code> method (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1813">r1813</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1816">r1816</a>)</li>
<li>Added <code class="docutils literal"><span class="pre">clickdata</span></code> argument to <code class="docutils literal"><span class="pre">FormRequest.from_response()</span></code> method (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1802">r1802</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1803">r1803</a>)</li>
<li>Added support for HTTP proxies (<code class="docutils literal"><span class="pre">HttpProxyMiddleware</span></code>) (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1781">r1781</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1785">r1785</a>)</li>
<li>Offiste spider middleware now logs messages when filtering out requests (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1841">r1841</a>)</li>
</ul>
</div>
<div class="section" id="backwards-incompatible-changes">
<h3>Backwards-incompatible changes<a class="headerlink" href="#backwards-incompatible-changes" title="永久链接至标题">¶</a></h3>
<ul>
<li><p class="first">Changed <code class="docutils literal"><span class="pre">scrapy.utils.response.get_meta_refresh()</span></code> signature (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1804">r1804</a>)</p>
</li>
<li><p class="first">Removed deprecated <code class="docutils literal"><span class="pre">scrapy.item.ScrapedItem</span></code> class - use <code class="docutils literal"><span class="pre">scrapy.item.Item</span> <span class="pre">instead</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1838">r1838</a>)</p>
</li>
<li><p class="first">Removed deprecated <code class="docutils literal"><span class="pre">scrapy.xpath</span></code> module - use <code class="docutils literal"><span class="pre">scrapy.selector</span></code> instead. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1836">r1836</a>)</p>
</li>
<li><p class="first">Removed deprecated <code class="docutils literal"><span class="pre">core.signals.domain_open</span></code> signal - use <code class="docutils literal"><span class="pre">core.signals.domain_opened</span></code> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1822">r1822</a>)</p>
</li>
<li><dl class="first docutils">
<dt><code class="docutils literal"><span class="pre">log.msg()</span></code> now receives a <code class="docutils literal"><span class="pre">spider</span></code> argument (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1822">r1822</a>)</dt>
<dd><ul class="first last simple">
<li>Old domain argument has been deprecated and will be removed in 0.9. For spiders, you should always use the <code class="docutils literal"><span class="pre">spider</span></code> argument and pass spider references. If you really want to pass a string, use the <code class="docutils literal"><span class="pre">component</span></code> argument instead.</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Changed core signals <code class="docutils literal"><span class="pre">domain_opened</span></code>, <code class="docutils literal"><span class="pre">domain_closed</span></code>, <code class="docutils literal"><span class="pre">domain_idle</span></code></p>
</li>
<li><dl class="first docutils">
<dt>Changed Item pipeline to use spiders instead of domains</dt>
<dd><ul class="first last simple">
<li>The <code class="docutils literal"><span class="pre">domain</span></code> argument of  <code class="docutils literal"><span class="pre">process_item()</span></code> item pipeline method was changed to  <code class="docutils literal"><span class="pre">spider</span></code>, the new signature is: <code class="docutils literal"><span class="pre">process_item(spider,</span> <span class="pre">item)</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1827">r1827</a> | #105)</li>
<li>To quickly port your code (to work with Scrapy 0.8) just use <code class="docutils literal"><span class="pre">spider.domain_name</span></code> where you previously used <code class="docutils literal"><span class="pre">domain</span></code>.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Changed Stats API to use spiders instead of domains (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1849">r1849</a> | #113)</dt>
<dd><ul class="first last simple">
<li><code class="docutils literal"><span class="pre">StatsCollector</span></code> was changed to receive spider references (instead of domains) in its methods (<code class="docutils literal"><span class="pre">set_value</span></code>, <code class="docutils literal"><span class="pre">inc_value</span></code>, etc).</li>
<li>added <code class="docutils literal"><span class="pre">StatsCollector.iter_spider_stats()</span></code> method</li>
<li>removed <code class="docutils literal"><span class="pre">StatsCollector.list_domains()</span></code> method</li>
<li>Also, Stats signals were renamed and now pass around spider references (instead of domains). Here&#8217;s a summary of the changes:</li>
<li>To quickly port your code (to work with Scrapy 0.8) just use <code class="docutils literal"><span class="pre">spider.domain_name</span></code> where you previously used <code class="docutils literal"><span class="pre">domain</span></code>. <code class="docutils literal"><span class="pre">spider_stats</span></code> contains exactly the same data as <code class="docutils literal"><span class="pre">domain_stats</span></code>.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><code class="docutils literal"><span class="pre">CloseDomain</span></code> extension moved to <code class="docutils literal"><span class="pre">scrapy.contrib.closespider.CloseSpider</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1833">r1833</a>)</dt>
<dd><ul class="first last">
<li><dl class="first docutils">
<dt>Its settings were also renamed:</dt>
<dd><ul class="first last simple">
<li><code class="docutils literal"><span class="pre">CLOSEDOMAIN_TIMEOUT</span></code> to <code class="docutils literal"><span class="pre">CLOSESPIDER_TIMEOUT</span></code></li>
<li><code class="docutils literal"><span class="pre">CLOSEDOMAIN_ITEMCOUNT</span></code> to <code class="docutils literal"><span class="pre">CLOSESPIDER_ITEMCOUNT</span></code></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first">Removed deprecated <code class="docutils literal"><span class="pre">SCRAPYSETTINGS_MODULE</span></code> environment variable - use <code class="docutils literal"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1840">r1840</a>)</p>
</li>
<li><p class="first">Renamed setting: <code class="docutils literal"><span class="pre">REQUESTS_PER_DOMAIN</span></code> to <code class="docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_SPIDER</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1830">r1830</a>, <a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1844">r1844</a>)</p>
</li>
<li><p class="first">Renamed setting: <code class="docutils literal"><span class="pre">CONCURRENT_DOMAINS</span></code> to <code class="docutils literal"><span class="pre">CONCURRENT_SPIDERS</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1830">r1830</a>)</p>
</li>
<li><p class="first">Refactored HTTP Cache middleware</p>
</li>
<li><p class="first">HTTP Cache middleware has been heavilty refactored, retaining the same functionality except for the domain sectorization which was removed. (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1843">r1843</a> )</p>
</li>
<li><p class="first">Renamed exception: <code class="docutils literal"><span class="pre">DontCloseDomain</span></code> to <code class="docutils literal"><span class="pre">DontCloseSpider</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1859">r1859</a> | #120)</p>
</li>
<li><p class="first">Renamed extension: <code class="docutils literal"><span class="pre">DelayedCloseDomain</span></code> to <code class="docutils literal"><span class="pre">SpiderCloseDelay</span></code> (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1861">r1861</a> | #121)</p>
</li>
<li><p class="first">Removed obsolete <code class="docutils literal"><span class="pre">scrapy.utils.markup.remove_escape_chars</span></code> function - use <code class="docutils literal"><span class="pre">scrapy.utils.markup.replace_escape_chars</span></code> instead (<a class="reference external" href="http://hg.scrapy.org/scrapy/changeset/1865">r1865</a>)</p>
</li>
</ul>
</div>
</div>
<div class="section" id="id22">
<h2>0.7<a class="headerlink" href="#id22" title="永久链接至标题">¶</a></h2>
<p>First release of Scrapy.</p>
</div>
</div>


    
        <h2>
            讨论
            <a class="headerlink" href="#discuss" title="永久链接至标题">¶</a>
        </h2>

        <div id="disqus_thread"></div>
    

          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="contributing.html" class="btn btn-neutral float-right" title="Contributing to Scrapy" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="topics/exporters.html" class="btn btn-neutral" title="Item Exporters" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; 版权所有 2008-2014, written by Scrapy developers, translated by Summer&amp;Friends.
      最后更新于 May 05, 2015.
    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 0.24
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="/zh_CN/latest/">latest</a></dd>
        
          <dd><a href="/zh_CN/stable/">stable</a></dd>
        
          <dd><a href="/zh_CN/master/">master</a></dd>
        
          <dd><a href="/zh_CN/0.24/">0.24</a></dd>
        
          <dd><a href="/zh_CN/0.22/">0.22</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="//readthedocs.org/projects/scrapy-chs/downloads/htmlzip/0.24/">htmlzip</a></dd>
        
          <dd><a href="//readthedocs.org/projects/scrapy-chs/downloads/epub/0.24/">epub</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="//readthedocs.org/projects/scrapy-chs/?fromdocs=scrapy-chs">Project Home</a>
          </dd>
          <dd>
            <a href="//readthedocs.org/builds/scrapy-chs/?fromdocs=scrapy-chs">Builds</a>
          </dd>
      </dl>
      <hr/>
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.

    </div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.24.4',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="_static/translations.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
     
    
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'scrapychs'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
     var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
     dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
     (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();

    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
         (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
           m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
             })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-50189694-1', 'readthedocs.org');
      ga('send', 'pageview');

    </script>
    


</body>
</html>