

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>下载器中间件(Downloader Middleware) &mdash; Scrapy 0.22.2 文档</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  
    

  

  
  

  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />
  
    <link rel="top" title="Scrapy 0.22.2 文档" href="../index.html"/>
        <link rel="next" title="Spider中间件(Middleware)" href="spider-middleware.html"/>
        <link rel="prev" title="架构概览" href="architecture.html"/>
 
<!-- RTD Extra Head -->



<!-- 
Read the Docs is acting as the canonical URL for your project. 
If you want to change it, more info is available in our docs:
  http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://scrapy-chs.readthedocs.org/zh_CN/latest/topics/downloader-middleware.html" />

<script type="text/javascript">
  // This is included here because other places don't have access to the pagename variable.
  var READTHEDOCS_DATA = {
    project: "scrapy-chs",
    version: "stable",
    language: "zh_CN",
    page: "topics/downloader-middleware",
    builder: "sphinx",
    theme: "sphinx_rtd_theme",
    docroot: "/",
    source_suffix: ".rst",
    api_host: "https://readthedocs.org",
    commit: "094b55236635f45d4531e48ee9f693c796e0144d"
  }
  // Old variables
  var doc_version = "stable";
  var doc_slug = "scrapy-chs";
  var page_name = "topics/downloader-middleware";
  var html_theme = "sphinx_rtd_theme";
</script>
<!-- RTD Analytics Code -->
<!-- Included in the header because you don't have a footer block. -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-17997319-1']);
  _gaq.push(['_trackPageview']);


  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<!-- end RTD Analytics Code -->
<!-- end RTD <extrahead> -->


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        
          <a href="../index.html" class="fa fa-home"> Scrapy</a>
        
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">初窥Scrapy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#id1">选择一个网站</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#intro-overview-item">定义您想抓取的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#spider">编写提取数据的Spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#id3">执行spider，获取数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#id4">查看提取到的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#topics-whatelse">还有什么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#id6">接下来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">安装指南</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#id2">前期准备</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#scrapy">安装Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#intro-install-platform-notes">平台安装指南</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy入门教程</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#id2">创建项目</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#item">定义Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#spider">编写第一个爬虫(Spider)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#id9">保存爬取到的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#id10">下一步</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">例子</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="commands.html">命令行工具(Command line tools)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="commands.html#scrapy">默认的Scrapy项目结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#id1">使用 <tt class="docutils literal"><span class="pre">scrapy</span></tt> 工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#tool-commands">可用的工具命令(tool commands)</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#id4">自定义项目命令</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a><ul>
<li class="toctree-l2"><a class="reference internal" href="items.html#item">声明Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#item-item-fields">Item字段(Item Fields)</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#id1">与Item配合</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#id7">扩展Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#id8">Item对象</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#field">字段(Field)对象</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spiders.html">Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="spiders.html#spider">Spider参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="spiders.html#topics-spiders-ref">内置Spider参考手册</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">选择器（Selectors）</a><ul>
<li class="toctree-l2"><a class="reference internal" href="selectors.html#id1">使用选择器（selectors）</a></li>
<li class="toctree-l2"><a class="reference internal" href="selectors.html#module-scrapy.selector">内建选择器的参考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#using-item-loaders-to-populate-items">Using Item Loaders to populate items</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#input-and-output-processors">Input and Output processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#declaring-item-loaders">Declaring Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#declaring-input-and-output-processors">Declaring Input and Output Processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#item-loader-context">Item Loader Context</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#itemloader-objects">ItemLoader objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#reusing-and-extending-item-loaders">Reusing and extending Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#module-scrapy.contrib.loader.processor">Available built-in processors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy终端(Scrapy shell)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="shell.html#id1">启动终端</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#id2">使用终端</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#shell-session">终端会话(shell session)样例</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#spidershellresponse">在spider中启动shell来查看response</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#id1">编写你自己的item pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#id2">Item pipeline 样例</a></li>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#id4">启用一个Item Pipeline组件</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a><ul>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#serialization-formats">序列化方式(Serialization formats)</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#storages">存储(Storages)</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#uri">存储URI参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#storage-backends">存储端(Storage backends)</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#settings">设定(Settings)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="link-extractors.html#module-scrapy.contrib.linkextractors">内置Link Extractor 参考</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="logging.html#log-levels">Log levels</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#log">如何设置log级别</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#log-messages">如何记录信息(log messages)</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#spiderlog-logging-from-spiders">在Spider中添加log(Logging from Spiders)</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#module-scrapy.log">scrapy.log模块</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#id1">Logging设置</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">数据收集(Stats Collection)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="stats.html#topics-stats-usecases">常见数据收集器使用方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="stats.html#id2">可用的数据收集器</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="email.html">发送email</a><ul>
<li class="toctree-l2"><a class="reference internal" href="email.html#id1">简单例子</a></li>
<li class="toctree-l2"><a class="reference internal" href="email.html#mailsender">MailSender类参考手册</a></li>
<li class="toctree-l2"><a class="reference internal" href="email.html#mail">Mail设置</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet终端(Telnet Console)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#telnet">如何访问telnet终端</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#id1">telnet终端中可用的变量</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#telnet-console-usage-examples">Telnet console usage examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#id3">Telnet终端信号</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#id4">Telnet设定</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#web-service-resources">Web Service资源(resources)</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#web">Web服务设置</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#web-resource">编写web服务资源(resource)</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#id2">web服务资源例子</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#example-of-web-service-client">Example of web service client</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">常见问题(FAQ)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapybeautifulsouplxml">Scrapy相BeautifulSoup或lxml比较,如何呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapypython">Scrapy支持那些Python版本？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapypython-3">Scrapy支持Python 3么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapydjango-x">Scrapy是否从Django中&#8221;剽窃&#8221;了X呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapyhttp">Scrapy支持HTTP代理么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#item">如何爬取属性在不同页面的item呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy-importerror-nomodule-named-win32api">Scrapy退出，ImportError: Nomodule named win32api</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#spider">我要如何在spider里模拟用户登录呢?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy">Scrapy是以广度优先还是深度优先进行爬取的呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id3">我的Scrapy爬虫有内存泄露，怎么办?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id4">如何让Scrapy减少内存消耗?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#spiderhttp">我能在spider中使用基本HTTP认证么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id5">为什么Scrapy下载了英文的页面，而不是我的本国语言？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id6">我能在哪里找到Scrapy项目的例子？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy-spider">我能在不创建Scrapy项目的情况下运行一个爬虫(spider)么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#filtered-offsite-request">我收到了 &#8220;Filtered offsite request&#8221; 消息。如何修复？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id7">发布Scrapy爬虫到生产环境的推荐方式？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#large-exports-json">我能对大数据(large exports)使用JSON么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#signal-handler-twisted">我能在信号处理器(signal handler)中返回(Twisted)引用么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#reponse999">reponse返回的状态值999代表了什么?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#spider-pdb-set-trace">我能在spider中调用 <tt class="docutils literal"><span class="pre">pdb.set_trace()</span></tt> 来调试么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#item-dump-json-csv-xml">将所有爬取到的item转存(dump)到JSON/CSV/XML文件的最简单的方法?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#viewstate">在某些表单中巨大神秘的 <tt class="docutils literal"><span class="pre">__VIEWSTATE</span></tt> 参数是什么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#xml-csv">分析大XML/CSV数据源的最好方法是?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapycookies">Scrapy自动管理cookies么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapyscrapy">如何才能看到Scrapy发出及接收到的Scrapy呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id10">要怎么停止爬虫呢?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy-bot-ban">如何避免我的Scrapy机器人(bot)被禁止(ban)呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#spider-arguments-settings-spider">我应该使用spider参数(arguments)还是设置(settings)来配置spider呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#xmlxpathitem">我爬取了一个XML文档但是XPath选择器不返回任何的item</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#name-crawler">我得到错误: &#8220;不能导入name crawler“</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">调试(Debugging)Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="debug.html#parse">Parse命令</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#scrapy-shell">Scrapy终端(Shell)</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#id1">在浏览器中打开</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#logging">Logging</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contracts.html#contracts">自定义Contracts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">实践经验(Common Practices)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="practices.html#scrapy">在脚本中运行Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#spider">同一进程运行多个spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#distributed-crawls">分布式爬虫(Distributed crawls)</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#ban">避免被禁止(ban)</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#item">动态创建Item类</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">通用爬虫(Broad Crawls)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#id1">增加并发</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#log">降低log级别</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#cookies">禁止cookies</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#id2">禁止重试</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#id3">减小下载超时</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#id4">禁止重定向</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#ajax-crawlable-pages">启用 &#8220;Ajax Crawlable Pages&#8221; 爬取</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="firefox.html">借助Firefox来爬取</a><ul>
<li class="toctree-l2"><a class="reference internal" href="firefox.html#dom">在浏览器中检查DOM的注意事项</a></li>
<li class="toctree-l2"><a class="reference internal" href="firefox.html#topics-firefox-addons">对爬取有帮助的实用Firefox插件</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="firebug.html">使用Firebug进行爬取</a><ul>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#id1">介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#follow">获取到跟进(follow)的链接</a></li>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#id4">提取数据</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">调试内存溢出</a><ul>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#id2">内存泄露的常见原因</a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#trackref">使用 <tt class="docutils literal"><span class="pre">trackref</span></tt> 调试内存泄露</a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#guppy">使用Guppy调试内存泄露</a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#leaks-without-leaks">Leaks without leaks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="images.html">下载项目图片</a><ul>
<li class="toctree-l2"><a class="reference internal" href="images.html#id2">使用图片管道</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#id3">使用样例</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#topics-images-enabling">开启你的图片管道</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#id5">图片存储</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#id7">额外的特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#module-scrapy.contrib.pipeline.images">实现定制图片管道</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#id12">定制图片管道的例子</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ubuntu.html">Ubuntu 软件包</a></li>
<li class="toctree-l1"><a class="reference internal" href="scrapyd.html">Scrapyd</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">自动限速(AutoThrottle)扩展</a><ul>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#id1">设计目标</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#id2">扩展是如何实现的</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#autothrottle-algorithm">限速算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#id4">设置</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: 暂停，恢复爬虫</a><ul>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#job">Job 路径</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#id1">怎么使用</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#id2">保持状态</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#id3">持久化的一些坑</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="djangoitem.html">DjangoItem</a><ul>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#id1">使用DjangoItem</a></li>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#id2">DjangoItem注意事项</a></li>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#django">配置Django的设置</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="architecture.html">架构概览</a><ul>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#id2">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#id3">组件</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#data-flow">数据流(Data flow)</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#event-driven-networking">事件驱动网络(Event-driven networking)</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="">下载器中间件(Downloader Middleware)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#topics-downloader-middleware-setting">激活下载器中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">编写您自己的下载器中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="#topics-downloader-middleware-ref">内置下载中间件参考手册</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider中间件(Middleware)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="spider-middleware.html#spider">激活spider中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="spider-middleware.html#id1">编写您自己的spider中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="spider-middleware.html#topics-spider-middleware-ref">内置spider中间件参考手册</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">扩展(Extensions)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#extension-settings">扩展设置(Extension settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#id1">加载和激活扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#available-enabled-disabled">可用的(Available)、开启的(enabled)和禁用的(disabled)的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#disabling-an-extension">禁用扩展(Disabling an extension)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#id2">实现你的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#topics-extensions-ref">内置扩展介绍</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">核心API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api.html#crawler-api">Crawler API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#module-scrapy.settings">设置(Settings) API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#module-scrapy.signalmanager">信号(Signals) API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#stats-collector-api">状态收集器(Stats Collector) API</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a><ul>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-objects">Request objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-meta-special-keys">Request.meta special keys</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-subclasses">Request subclasses</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#response-objects">Response objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#response-subclasses">Response subclasses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">Settings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="settings.html#designating-the-settings">指定设定(Designating the settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#populating-the-settings">获取设定值(Populating the settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#how-to-access-settings">如何访问设定(How to access settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#id1">设定名字的命名规则</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#topics-settings-ref">内置设定参考手册</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">信号(Signals)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="signals.html#deferred-signal-handlers">延迟的信号处理器(Deferred signal handlers)</a></li>
<li class="toctree-l2"><a class="reference internal" href="signals.html#module-scrapy.signals">内置信号参考手册(Built-in signals reference)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">异常(Exceptions)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="exceptions.html#built-in-exceptions-reference">内置异常参考手册(Built-in Exceptions reference)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="exporters.html#item-exporter">使用 Item Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="exporters.html#topics-exporters-reference">Item Exporters 参考资料</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-02-14">0.22.2 (released 2014-02-14)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-02-08">0.22.1 (released 2014-02-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-01-17">0.22.0 (released 2014-01-17)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-12-09">0.20.2 (released 2013-12-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-11-28">0.20.1 (released 2013-11-28)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-11-08">0.20.0 (released 2013-11-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-10-10">0.18.4 (released 2013-10-10)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-10-03">0.18.3 (released 2013-10-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-09-03">0.18.2 (released 2013-09-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-08-27">0.18.1 (released 2013-08-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-08-09">0.18.0 (released 2013-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-05-30">0.16.5 (released 2013-05-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-01-23">0.16.4 (released 2013-01-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-12-07">0.16.3 (released 2012-12-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-11-09">0.16.2 (released 2012-11-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-10-26">0.16.1 (released 2012-10-26)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-10-18">0.16.0 (released 2012-10-18)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id2">0.14.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id3">0.14.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id4">0.14.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id5">0.14.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id6">0.14</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id7">0.12</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id8">0.10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id11">0.9</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id14">0.8</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id15">0.7</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#reporting-bugs">Reporting bugs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#writing-patches">Writing patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#submitting-patches">Submitting patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#coding-style">Coding style</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#scrapy-contrib">Scrapy Contrib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#documentation-policies">Documentation policies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#tests">Tests</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../versioning.html#id1">Versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../versioning.html#api-stability">API Stability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../experimental/index.html">试验阶段特性</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../experimental/index.html#id3">使用外部库插入命令</a></li>
</ul>
</li>
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>下载器中间件(Downloader Middleware)</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="https://github.com/marchtea/scrapy_doc_chs/blob/stable/topics/downloader-middleware.rst" class="fa fa-github"> Edit on GitHub</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
    
  <div class="section" id="downloader-middleware">
<span id="topics-downloader-middleware"></span><h1>下载器中间件(Downloader Middleware)<a class="headerlink" href="#downloader-middleware" title="永久链接至标题">¶</a></h1>
<p>下载器中间件是介于Scrapy的request/response处理的钩子框架。
是用于全局修改Scrapy request和response的一个轻量、底层的系统。</p>
<div class="section" id="topics-downloader-middleware-setting">
<span id="id1"></span><h2>激活下载器中间件<a class="headerlink" href="#topics-downloader-middleware-setting" title="永久链接至标题">¶</a></h2>
<p>要激活下载器中间件组件，将其加入到 <a class="reference internal" href="settings.html#std:setting-DOWNLOADER_MIDDLEWARES"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_MIDDLEWARES</span></tt></a> 设置中。
该设置是一个字典(dict)，键为中间件类的路径，值为其中间件的顺序(order)。</p>
<p>这里是一个例子:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">DOWNLOADER_MIDDLEWARES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;myproject.middlewares.CustomDownloaderMiddleware&#39;</span><span class="p">:</span> <span class="mi">543</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p><a class="reference internal" href="settings.html#std:setting-DOWNLOADER_MIDDLEWARES"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_MIDDLEWARES</span></tt></a> 设置会与Scrapy定义的
<a class="reference internal" href="settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_MIDDLEWARES_BASE</span></tt></a> 设置合并(但不是覆盖)，
而后根据顺序(order)进行排序，最后得到启用中间件的有序列表:
第一个中间件是最靠近引擎的，最后一个中间件是最靠近下载器的。</p>
<p>关于如何分配中间件的顺序请查看
<a class="reference internal" href="settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_MIDDLEWARES_BASE</span></tt></a> 设置，而后根据您想要放置中间件的位置选择一个值。
由于每个中间件执行不同的动作，您的中间件可能会依赖于之前(或者之后)执行的中间件，因此顺序是很重要的。</p>
<p>如果您想禁止内置的(在
<a class="reference internal" href="settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_MIDDLEWARES_BASE</span></tt></a> 中设置并默认启用的)中间件，
您必须在项目的 <a class="reference internal" href="settings.html#std:setting-DOWNLOADER_MIDDLEWARES"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_MIDDLEWARES</span></tt></a> 设置中定义该中间件，并将其值赋为 <cite>None</cite> 。
例如，如果您想要关闭user-agent中间件:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">DOWNLOADER_MIDDLEWARES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">&#39;myproject.middlewares.CustomDownloaderMiddleware&#39;</span><span class="p">:</span> <span class="mi">543</span><span class="p">,</span>
    <span class="s">&#39;scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware&#39;</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>最后，请注意，有些中间件需要通过特定的设置来启用。更多内容请查看相关中间件文档。</p>
</div>
<div class="section" id="id2">
<h2>编写您自己的下载器中间件<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>编写下载器中间件十分简单。每个中间件组件是一个定义了以下一个或多个方法的Python类:</p>
<span class="target" id="module-scrapy.contrib.downloadermiddleware"></span><dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.DownloaderMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.</tt><tt class="descname">DownloaderMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware" title="永久链接至目标">¶</a></dt>
<dd><dl class="method">
<dt id="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request">
<tt class="descname">process_request</tt><big>(</big><em>request</em>, <em>spider</em><big>)</big><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request" title="永久链接至目标">¶</a></dt>
<dd><p>当每个request通过下载中间件时，该方法被调用。</p>
<p><a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request"><tt class="xref py py-meth docutils literal"><span class="pre">process_request()</span></tt></a> 必须返回其中之一: 返回 <tt class="docutils literal"><span class="pre">None</span></tt> 、返回一个
<a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> 对象、返回一个 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a>
对象或raise <a class="reference internal" href="exceptions.html#scrapy.exceptions.IgnoreRequest" title="scrapy.exceptions.IgnoreRequest"><tt class="xref py py-exc docutils literal"><span class="pre">IgnoreRequest</span></tt></a> 。</p>
<p>如果其返回 <tt class="docutils literal"><span class="pre">None</span></tt> ，Scrapy将继续处理该request，执行其他的中间件的相应方法，直到合适的下载器处理函数(download handler)被调用，
该request被执行(其response被下载)。</p>
<p>如果其返回 <a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> 对象，Scrapy将不会调用 <em>任何</em>
其他的 <a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request"><tt class="xref py py-meth docutils literal"><span class="pre">process_request()</span></tt></a> 或 <a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_exception()</span></tt></a> 方法，或相应地下载函数；
其将返回该response。 已安装的中间件的 <a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_response" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_response"><tt class="xref py py-meth docutils literal"><span class="pre">process_response()</span></tt></a> 方法则会在每个response返回时被调用。</p>
<p>如果其返回 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象，Scrapy则停止调用
process_request方法并重新调度返回的request。当新返回的request被执行后，
相应地中间件链将会根据下载的response被调用。</p>
<p>如果其raise一个 <a class="reference internal" href="exceptions.html#scrapy.exceptions.IgnoreRequest" title="scrapy.exceptions.IgnoreRequest"><tt class="xref py py-exc docutils literal"><span class="pre">IgnoreRequest</span></tt></a> 异常，则安装的下载中间件的
<a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_exception()</span></tt></a> 方法会被调用。如果没有任何一个方法处理该异常，
则request的errback(<tt class="docutils literal"><span class="pre">Request.errback</span></tt>)方法会被调用。如果没有代码处理抛出的异常，
则该异常被忽略且不记录(不同于其他异常那样)。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>request</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象) &#8211; 处理的request</li>
<li><strong>spider</strong> (<a class="reference internal" href="spiders.html#scrapy.spider.Spider" title="scrapy.spider.Spider"><tt class="xref py py-class docutils literal"><span class="pre">Spider</span></tt></a> 对象) &#8211; 该request对应的spider</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_response">
<tt class="descname">process_response</tt><big>(</big><em>request</em>, <em>response</em>, <em>spider</em><big>)</big><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_response" title="永久链接至目标">¶</a></dt>
<dd><p><a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request"><tt class="xref py py-meth docutils literal"><span class="pre">process_request()</span></tt></a> 必须返回以下之一: 返回一个 <a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> 对象、
返回一个 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象或raise一个 <a class="reference internal" href="exceptions.html#scrapy.exceptions.IgnoreRequest" title="scrapy.exceptions.IgnoreRequest"><tt class="xref py py-exc docutils literal"><span class="pre">IgnoreRequest</span></tt></a> 异常。</p>
<p>如果其返回一个 <a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> (可以与传入的response相同，也可以是全新的对象)，
该response会被在链中的其他中间件的 <a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_response" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_response"><tt class="xref py py-meth docutils literal"><span class="pre">process_response()</span></tt></a> 方法处理。</p>
<p>如果其返回一个 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象，则中间件链停止，
返回的request会被重新调度下载。处理类似于 <a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request"><tt class="xref py py-meth docutils literal"><span class="pre">process_request()</span></tt></a> 返回request所做的那样。</p>
<p>如果其抛出一个 <a class="reference internal" href="exceptions.html#scrapy.exceptions.IgnoreRequest" title="scrapy.exceptions.IgnoreRequest"><tt class="xref py py-exc docutils literal"><span class="pre">IgnoreRequest</span></tt></a> 异常，则调用request的errback(<tt class="docutils literal"><span class="pre">Request.errback</span></tt>)。
如果没有代码处理抛出的异常，则该异常被忽略且不记录(不同于其他异常那样)。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>request</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象) &#8211; response所对应的request</li>
<li><strong>response</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> 对象) &#8211; 被处理的response</li>
<li><strong>spider</strong> (<a class="reference internal" href="spiders.html#scrapy.spider.Spider" title="scrapy.spider.Spider"><tt class="xref py py-class docutils literal"><span class="pre">Spider</span></tt></a> 对象) &#8211; response所对应的spider</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception">
<tt class="descname">process_exception</tt><big>(</big><em>request</em>, <em>exception</em>, <em>spider</em><big>)</big><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception" title="永久链接至目标">¶</a></dt>
<dd><p>当下载处理器(download handler)或 <a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_request"><tt class="xref py py-meth docutils literal"><span class="pre">process_request()</span></tt></a>
(下载中间件)抛出异常(包括 <a class="reference internal" href="exceptions.html#scrapy.exceptions.IgnoreRequest" title="scrapy.exceptions.IgnoreRequest"><tt class="xref py py-exc docutils literal"><span class="pre">IgnoreRequest</span></tt></a> 异常)时，
Scrapy调用 <a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_exception()</span></tt></a> 。</p>
<p><a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_exception()</span></tt></a> 应该返回以下之一: 返回 <tt class="docutils literal"><span class="pre">None</span></tt> 、
一个 <a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> 对象、或者一个 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象。</p>
<p>如果其返回 <tt class="docutils literal"><span class="pre">None</span></tt> ，Scrapy将会继续处理该异常，接着调用已安装的其他中间件的
<a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_exception()</span></tt></a> 方法，直到所有中间件都被调用完毕，则调用默认的异常处理。</p>
<p>如果其返回一个 <a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a> 对象，则已安装的中间件链的
<a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_response" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_response"><tt class="xref py py-meth docutils literal"><span class="pre">process_response()</span></tt></a> 方法被调用。Scrapy将不会调用任何其他中间件的
<a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_exception()</span></tt></a> 方法。</p>
<p>如果其返回一个 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象，
则返回的request将会被重新调用下载。这将停止中间件的
<a class="reference internal" href="#scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception" title="scrapy.contrib.downloadermiddleware.DownloaderMiddleware.process_exception"><tt class="xref py py-meth docutils literal"><span class="pre">process_exception()</span></tt></a> 方法执行，就如返回一个response的那样。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><ul class="first last simple">
<li><strong>request</strong> (是 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象) &#8211; 产生异常的request</li>
<li><strong>exception</strong> (<tt class="docutils literal"><span class="pre">Exception</span></tt> 对象) &#8211; 抛出的异常</li>
<li><strong>spider</strong> (<a class="reference internal" href="spiders.html#scrapy.spider.Spider" title="scrapy.spider.Spider"><tt class="xref py py-class docutils literal"><span class="pre">Spider</span></tt></a> 对象) &#8211; request对应的spider</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="topics-downloader-middleware-ref">
<span id="id3"></span><h2>内置下载中间件参考手册<a class="headerlink" href="#topics-downloader-middleware-ref" title="永久链接至标题">¶</a></h2>
<p>本页面介绍了Scrapy自带的所有下载中间件。关于如何使用及编写您自己的中间件，请参考
<a class="reference internal" href="#topics-downloader-middleware"><em>downloader middleware usage guide</em></a>.</p>
<p>关于默认启用的中间件列表(及其顺序)请参考
<a class="reference internal" href="settings.html#std:setting-DOWNLOADER_MIDDLEWARES_BASE"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_MIDDLEWARES_BASE</span></tt></a> 设置。</p>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.cookies">
<span id="cookiesmiddleware"></span><span id="cookies-mw"></span><h3>CookiesMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.cookies" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.cookies.CookiesMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.cookies.</tt><tt class="descname">CookiesMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.cookies.CookiesMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件使得爬取需要cookie(例如使用session)的网站成为了可能。
其追踪了web server发送的cookie，并在之后的request中发送回去，
就如浏览器所做的那样。</p>
</dd></dl>

<p>以下设置可以用来配置cookie中间件:</p>
<ul class="simple">
<li><a class="reference internal" href="#std:setting-COOKIES_ENABLED"><tt class="xref std std-setting docutils literal"><span class="pre">COOKIES_ENABLED</span></tt></a></li>
<li><a class="reference internal" href="#std:setting-COOKIES_DEBUG"><tt class="xref std std-setting docutils literal"><span class="pre">COOKIES_DEBUG</span></tt></a></li>
</ul>
<div class="section" id="spidercookie-session">
<span id="std:reqmeta-cookiejar"></span><h4>单spider多cookie session<a class="headerlink" href="#spidercookie-session" title="永久链接至标题">¶</a></h4>
<div class="versionadded">
<p><span class="versionmodified">0.15 新版功能.</span></p>
</div>
<p>Scrapy通过使用 <a class="reference internal" href="#std:reqmeta-cookiejar"><tt class="xref std std-reqmeta docutils literal"><span class="pre">cookiejar</span></tt></a> Request meta key来支持单spider追踪多cookie session。
默认情况下其使用一个cookie jar(session)，不过您可以传递一个标示符来使用多个。</p>
<p>例如:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">url</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">urls</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">Request</span><span class="p">(</span><span class="s">&quot;http://www.example.com&quot;</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;cookiejar&#39;</span><span class="p">:</span> <span class="n">i</span><span class="p">},</span>
        <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_page</span><span class="p">)</span>
</pre></div>
</div>
<p>需要注意的是 <a class="reference internal" href="#std:reqmeta-cookiejar"><tt class="xref std std-reqmeta docutils literal"><span class="pre">cookiejar</span></tt></a> meta key不是&#8221;黏性的(sticky)&#8221;。
您需要在之后的request请求中接着传递。例如:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">parse_page</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="c"># do some processing</span>
    <span class="k">return</span> <span class="n">Request</span><span class="p">(</span><span class="s">&quot;http://www.example.com/otherpage&quot;</span><span class="p">,</span>
        <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;cookiejar&#39;</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">&#39;cookiejar&#39;</span><span class="p">]},</span>
        <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_other_page</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="cookies-enabled">
<span id="std:setting-COOKIES_ENABLED"></span><h4>COOKIES_ENABLED<a class="headerlink" href="#cookies-enabled" title="永久链接至标题">¶</a></h4>
<p>默认: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>是否启用cookies middleware。如果关闭，cookies将不会发送给web server。</p>
</div>
<div class="section" id="cookies-debug">
<span id="std:setting-COOKIES_DEBUG"></span><h4>COOKIES_DEBUG<a class="headerlink" href="#cookies-debug" title="永久链接至标题">¶</a></h4>
<p>默认: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>如果启用，Scrapy将记录所有在request(<tt class="docutils literal"><span class="pre">Cookie</span></tt>
请求头)发送的cookies及response接收到的cookies(<tt class="docutils literal"><span class="pre">Set-Cookie</span></tt> 接收头)。</p>
<p>下边是启用 <a class="reference internal" href="#std:setting-COOKIES_DEBUG"><tt class="xref std std-setting docutils literal"><span class="pre">COOKIES_DEBUG</span></tt></a> 的记录的样例:</p>
<div class="highlight-python"><div class="highlight"><pre>2011-04-06 14:35:10-0300 [diningcity] INFO: Spider opened
2011-04-06 14:35:10-0300 [diningcity] DEBUG: Sending cookies to: &lt;GET http://www.diningcity.com/netherlands/index.html&gt;
        Cookie: clientlanguage_nl=en_EN
2011-04-06 14:35:14-0300 [diningcity] DEBUG: Received cookies from: &lt;200 http://www.diningcity.com/netherlands/index.html&gt;
        Set-Cookie: JSESSIONID=B~FA4DC0C496C8762AE4F1A620EAB34F38; Path=/
        Set-Cookie: ip_isocode=US
        Set-Cookie: clientlanguage_nl=en_EN; Expires=Thu, 07-Apr-2011 21:21:34 GMT; Path=/
2011-04-06 14:49:50-0300 [diningcity] DEBUG: Crawled (200) &lt;GET http://www.diningcity.com/netherlands/index.html&gt; (referer: None)
[...]
</pre></div>
</div>
</div>
</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.defaultheaders">
<span id="defaultheadersmiddleware"></span><h3>DefaultHeadersMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.defaultheaders" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.defaultheaders.</tt><tt class="descname">DefaultHeadersMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件设置
<a class="reference internal" href="settings.html#std:setting-DEFAULT_REQUEST_HEADERS"><tt class="xref std std-setting docutils literal"><span class="pre">DEFAULT_REQUEST_HEADERS</span></tt></a> 指定的默认request header。</p>
</dd></dl>

</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.downloadtimeout">
<span id="downloadtimeoutmiddleware"></span><h3>DownloadTimeoutMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.downloadtimeout" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.downloadtimeout.DownloadTimeoutMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.downloadtimeout.</tt><tt class="descname">DownloadTimeoutMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.downloadtimeout.DownloadTimeoutMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件设置
<a class="reference internal" href="settings.html#std:setting-DOWNLOAD_TIMEOUT"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_TIMEOUT</span></tt></a> 指定的request下载超时时间.</p>
</dd></dl>

</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.httpauth">
<span id="httpauthmiddleware"></span><h3>HttpAuthMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.httpauth" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.httpauth.HttpAuthMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.httpauth.</tt><tt class="descname">HttpAuthMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.httpauth.HttpAuthMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件完成某些使用 <a class="reference external" href="http://en.wikipedia.org/wiki/Basic_access_authentication">Basic access authentication</a> (或者叫HTTP认证)的spider生成的请求的认证过程。</p>
<p>在spider中启用HTTP认证，请设置spider的 <tt class="docutils literal"><span class="pre">http_user</span></tt> 及 <tt class="docutils literal"><span class="pre">http_pass</span></tt> 属性。</p>
<p>样例:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span>

<span class="k">class</span> <span class="nc">SomeIntranetSiteSpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>

    <span class="n">http_user</span> <span class="o">=</span> <span class="s">&#39;someuser&#39;</span>
    <span class="n">http_pass</span> <span class="o">=</span> <span class="s">&#39;somepass&#39;</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;intranet.example.com&#39;</span>

    <span class="c"># .. rest of the spider code omitted ...</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.httpcache">
<span id="httpcachemiddleware"></span><h3>HttpCacheMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.httpcache" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.httpcache.HttpCacheMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.httpcache.</tt><tt class="descname">HttpCacheMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.httpcache.HttpCacheMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件为所有HTTP request及response提供了底层(low-level)缓存支持。
其由cache存储后端及cache策略组成。</p>
<p>Scrapy提供了两种HTTP缓存存储后端:</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference internal" href="#httpcache-storage-fs"><em>Filesystem storage backend (默认值)</em></a></li>
<li><a class="reference internal" href="#httpcache-storage-dbm"><em>DBM storage backend</em></a></li>
</ul>
</div></blockquote>
<p>您可以使用 <a class="reference internal" href="#std:setting-HTTPCACHE_STORAGE"><tt class="xref std std-setting docutils literal"><span class="pre">HTTPCACHE_STORAGE</span></tt></a> 设定来修改HTTP缓存存储后端。
您也可以实现您自己的存储后端。</p>
<p>Scrapy提供了两种了缓存策略:</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference internal" href="#httpcache-policy-rfc2616"><em>RFC2616策略</em></a></li>
<li><a class="reference internal" href="#httpcache-policy-dummy"><em>Dummy策略(默认值)</em></a></li>
</ul>
</div></blockquote>
<p>您可以使用 <a class="reference internal" href="#std:setting-HTTPCACHE_POLICY"><tt class="xref std std-setting docutils literal"><span class="pre">HTTPCACHE_POLICY</span></tt></a> 设定来修改HTTP缓存存储后端。
您也可以实现您自己的存储策略。</p>
</dd></dl>

<div class="section" id="dummy">
<span id="httpcache-policy-dummy"></span><h4>Dummy策略(默认值)<a class="headerlink" href="#dummy" title="永久链接至标题">¶</a></h4>
<p>该策略不考虑任何HTTP Cache-Control指令。每个request及其对应的response都被缓存。
当相同的request发生时，其不发送任何数据，直接返回response。</p>
<p>Dummpy策略对于测试spider十分有用。其能使spider运行更快(不需要每次等待下载完成)，
同时在没有网络连接时也能测试。其目的是为了能够回放spider的运行过程， <em>使之与之前的运行过程一模一样</em> 。</p>
<p>使用这个策略请设置:</p>
<ul class="simple">
<li><a class="reference internal" href="#std:setting-HTTPCACHE_POLICY"><tt class="xref std std-setting docutils literal"><span class="pre">HTTPCACHE_POLICY</span></tt></a> 为 <tt class="docutils literal"><span class="pre">scrapy.contrib.httpcache.DummyPolicy</span></tt></li>
</ul>
</div>
<div class="section" id="rfc2616">
<span id="httpcache-policy-rfc2616"></span><h4>RFC2616策略<a class="headerlink" href="#rfc2616" title="永久链接至标题">¶</a></h4>
<p>该策略提供了符合RFC2616的HTTP缓存，例如符合HTTP Cache-Control，
针对生产环境并且应用在持续性运行环境所设置。该策略能避免下载未修改的数据(来节省带宽，提高爬取速度)。</p>
<p>实现了:</p>
<ul class="simple">
<li>当 <cite>no-store</cite> cache-control指令设置时不存储response/request。</li>
<li>当 <cite>no-cache</cite> cache-control指定设置时不从cache中提取response，即使response为最新。</li>
<li>根据 <cite>max-age</cite> cache-control指令中计算保存时间(freshness lifetime)。</li>
<li>根据 <cite>Expires</cite> 指令来计算保存时间(freshness lifetime)。</li>
<li>根据response包头的 <cite>Last-Modified</cite> 指令来计算保存时间(freshness lifetime)(Firefox使用的启发式算法)。</li>
<li>根据response包头的 <cite>Age</cite> 计算当前年龄(current age)</li>
<li>根据 <cite>Date</cite> 计算当前年龄(current age)</li>
<li>根据response包头的 <cite>Last-Modified</cite> 验证老旧的response。</li>
<li>根据response包头的 <cite>ETag</cite> 验证老旧的response。</li>
<li>为接收到的response设置缺失的 <cite>Date</cite> 字段。</li>
</ul>
<p>目前仍然缺失:</p>
<ul class="simple">
<li><cite>Pragma: no-cache</cite> 支持 <a class="reference external" href="http://www.mnot.net/cache_docs/#PRAGMA">http://www.mnot.net/cache_docs/#PRAGMA</a></li>
<li><cite>Vary</cite> 字段支持 <a class="reference external" href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.6">http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.6</a></li>
<li>当update或delete之后失效相应的response <a class="reference external" href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.10">http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.10</a></li>
<li>... 以及其他可能缺失的特性 ..</li>
</ul>
<p>使用这个策略，设置:</p>
<ul class="simple">
<li><a class="reference internal" href="#std:setting-HTTPCACHE_POLICY"><tt class="xref std std-setting docutils literal"><span class="pre">HTTPCACHE_POLICY</span></tt></a> 为 <tt class="docutils literal"><span class="pre">scrapy.contrib.httpcache.RFC2616Policy</span></tt></li>
</ul>
</div>
<div class="section" id="filesystem-storage-backend">
<span id="httpcache-storage-fs"></span><h4>Filesystem storage backend (默认值)<a class="headerlink" href="#filesystem-storage-backend" title="永久链接至标题">¶</a></h4>
<p>文件系统存储后端可以用于HTTP缓存中间件。</p>
<p>使用该存储端，设置:</p>
<ul class="simple">
<li><a class="reference internal" href="#std:setting-HTTPCACHE_STORAGE"><tt class="xref std std-setting docutils literal"><span class="pre">HTTPCACHE_STORAGE</span></tt></a> 为 <tt class="docutils literal"><span class="pre">scrapy.contrib.httpcache.FilesystemCacheStorage</span></tt></li>
</ul>
<p>每个request/response组存储在不同的目录中，包含下列文件:</p>
<blockquote>
<div><ul class="simple">
<li><tt class="docutils literal"><span class="pre">request_body</span></tt> - the plain request body</li>
<li><tt class="docutils literal"><span class="pre">request_headers</span></tt> - the request headers (原始HTTP格式)</li>
<li><tt class="docutils literal"><span class="pre">response_body</span></tt> - the plain response body</li>
<li><tt class="docutils literal"><span class="pre">response_headers</span></tt> - the request headers (原始HTTP格式)</li>
<li><tt class="docutils literal"><span class="pre">meta</span></tt> - 以Python <tt class="docutils literal"><span class="pre">repr()</span></tt> 格式(grep-friendly格式)存储的该缓存资源的一些元数据。</li>
<li><tt class="docutils literal"><span class="pre">pickled_meta</span></tt> - 与 <tt class="docutils literal"><span class="pre">meta</span></tt> 相同的元数据，不过使用pickle来获得更高效的反序列化性能。</li>
</ul>
</div></blockquote>
<p>目录的名称与request的指纹(参考
<tt class="docutils literal"><span class="pre">scrapy.utils.request.fingerprint</span></tt>)有关，而二级目录是为了避免在同一文件夹下有太多文件
(这在很多文件系统中是十分低效的)。目录的例子:</p>
<div class="highlight-python"><div class="highlight"><pre>/path/to/cache/dir/example.com/72/72811f648e718090f041317756c03adb0ada46c7
</pre></div>
</div>
</div>
<div class="section" id="dbm-storage-backend">
<span id="httpcache-storage-dbm"></span><h4>DBM storage backend<a class="headerlink" href="#dbm-storage-backend" title="永久链接至标题">¶</a></h4>
<div class="versionadded">
<p><span class="versionmodified">0.13 新版功能.</span></p>
</div>
<p>同时也有 <a class="reference external" href="http://en.wikipedia.org/wiki/Dbm">DBM</a> 存储后端可以用于HTTP缓存中间件。</p>
<p>默认情况下，其采用 <a class="reference external" href="http://docs.python.org/library/anydbm.html">anydbm</a> 模块，不过您也可以通过
<a class="reference internal" href="#std:setting-HTTPCACHE_DBM_MODULE"><tt class="xref std std-setting docutils literal"><span class="pre">HTTPCACHE_DBM_MODULE</span></tt></a> 设置进行修改。</p>
<p>使用该存储端，设置:</p>
<ul class="simple">
<li><a class="reference internal" href="#std:setting-HTTPCACHE_STORAGE"><tt class="xref std std-setting docutils literal"><span class="pre">HTTPCACHE_STORAGE</span></tt></a> 为 <tt class="docutils literal"><span class="pre">scrapy.contrib.httpcache.DbmCacheStorage</span></tt></li>
</ul>
</div>
<div class="section" id="httpcache">
<h4>HTTPCache中间件设置<a class="headerlink" href="#httpcache" title="永久链接至标题">¶</a></h4>
<p><a class="reference internal" href="#scrapy.contrib.downloadermiddleware.httpcache.HttpCacheMiddleware" title="scrapy.contrib.downloadermiddleware.httpcache.HttpCacheMiddleware"><tt class="xref py py-class docutils literal"><span class="pre">HttpCacheMiddleware</span></tt></a> 可以通过以下设置进行配置:</p>
<div class="section" id="httpcache-enabled">
<span id="std:setting-HTTPCACHE_ENABLED"></span><h5>HTTPCACHE_ENABLED<a class="headerlink" href="#httpcache-enabled" title="永久链接至标题">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified">0.11 新版功能.</span></p>
</div>
<p>默认: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>HTTP缓存是否开启。</p>
<div class="versionchanged">
<p><span class="versionmodified">在 0.11 版更改: </span>在0.11版本前，是使用 <a class="reference internal" href="#std:setting-HTTPCACHE_DIR"><tt class="xref std std-setting docutils literal"><span class="pre">HTTPCACHE_DIR</span></tt></a> 来开启缓存。</p>
</div>
</div>
<div class="section" id="httpcache-expiration-secs">
<span id="std:setting-HTTPCACHE_EXPIRATION_SECS"></span><h5>HTTPCACHE_EXPIRATION_SECS<a class="headerlink" href="#httpcache-expiration-secs" title="永久链接至标题">¶</a></h5>
<p>默认: <tt class="docutils literal"><span class="pre">0</span></tt></p>
<p>缓存的request的超时时间，单位秒。</p>
<p>超过这个时间的缓存request将会被重新下载。如果为0，则缓存的request将永远不会超时。</p>
<div class="versionchanged">
<p><span class="versionmodified">在 0.11 版更改: </span>在0.11版本前，0的意义是缓存的request永远超时。</p>
</div>
</div>
<div class="section" id="httpcache-dir">
<span id="std:setting-HTTPCACHE_DIR"></span><h5>HTTPCACHE_DIR<a class="headerlink" href="#httpcache-dir" title="永久链接至标题">¶</a></h5>
<p>默认: <tt class="docutils literal"><span class="pre">'httpcache'</span></tt></p>
<p>存储(底层的)HTTP缓存的目录。如果为空，则HTTP缓存将会被关闭。
如果为相对目录，则相对于项目数据目录(project data dir)。更多内容请参考 <a class="reference internal" href="commands.html#topics-project-structure"><em>默认的Scrapy项目结构</em></a> 。</p>
</div>
<div class="section" id="httpcache-ignore-http-codes">
<span id="std:setting-HTTPCACHE_IGNORE_HTTP_CODES"></span><h5>HTTPCACHE_IGNORE_HTTP_CODES<a class="headerlink" href="#httpcache-ignore-http-codes" title="永久链接至标题">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified">0.10 新版功能.</span></p>
</div>
<p>默认: <tt class="docutils literal"><span class="pre">[]</span></tt></p>
<p>不缓存设置中的HTTP返回值(code)的request。</p>
</div>
<div class="section" id="httpcache-ignore-missing">
<span id="std:setting-HTTPCACHE_IGNORE_MISSING"></span><h5>HTTPCACHE_IGNORE_MISSING<a class="headerlink" href="#httpcache-ignore-missing" title="永久链接至标题">¶</a></h5>
<p>默认: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>如果启用，在缓存中没找到的request将会被忽略，不下载。</p>
</div>
<div class="section" id="httpcache-ignore-schemes">
<span id="std:setting-HTTPCACHE_IGNORE_SCHEMES"></span><h5>HTTPCACHE_IGNORE_SCHEMES<a class="headerlink" href="#httpcache-ignore-schemes" title="永久链接至标题">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified">0.10 新版功能.</span></p>
</div>
<p>默认: <tt class="docutils literal"><span class="pre">['file']</span></tt></p>
<p>不缓存这些URI标准(scheme)的response。</p>
</div>
<div class="section" id="httpcache-storage">
<span id="std:setting-HTTPCACHE_STORAGE"></span><h5>HTTPCACHE_STORAGE<a class="headerlink" href="#httpcache-storage" title="永久链接至标题">¶</a></h5>
<p>默认: <tt class="docutils literal"><span class="pre">'scrapy.contrib.httpcache.FilesystemCacheStorage'</span></tt></p>
<p>实现缓存存储后端的类。</p>
</div>
<div class="section" id="httpcache-dbm-module">
<span id="std:setting-HTTPCACHE_DBM_MODULE"></span><h5>HTTPCACHE_DBM_MODULE<a class="headerlink" href="#httpcache-dbm-module" title="永久链接至标题">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified">0.13 新版功能.</span></p>
</div>
<p>默认: <tt class="docutils literal"><span class="pre">'anydbm'</span></tt></p>
<p>在 <a class="reference internal" href="#httpcache-storage-dbm"><em>DBM存储后端</em></a> 的数据库模块。
该设定针对DBM后端。</p>
</div>
<div class="section" id="httpcache-policy">
<span id="std:setting-HTTPCACHE_POLICY"></span><h5>HTTPCACHE_POLICY<a class="headerlink" href="#httpcache-policy" title="永久链接至标题">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified">0.18 新版功能.</span></p>
</div>
<p>默认: <tt class="docutils literal"><span class="pre">'scrapy.contrib.httpcache.DummyPolicy'</span></tt></p>
<p>实现缓存策略的类。</p>
</div>
</div>
</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.httpcompression">
<span id="httpcompressionmiddleware"></span><h3>HttpCompressionMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.httpcompression" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.httpcompression.HttpCompressionMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.httpcompression.</tt><tt class="descname">HttpCompressionMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.httpcompression.HttpCompressionMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件提供了对压缩(gzip, deflate)数据的支持。</p>
</dd></dl>

<div class="section" id="httpcompressionmiddleware-settings">
<h4>HttpCompressionMiddleware Settings<a class="headerlink" href="#httpcompressionmiddleware-settings" title="永久链接至标题">¶</a></h4>
<div class="section" id="compression-enabled">
<span id="std:setting-COMPRESSION_ENABLED"></span><h5>COMPRESSION_ENABLED<a class="headerlink" href="#compression-enabled" title="永久链接至标题">¶</a></h5>
<p>默认: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>Compression Middleware(压缩中间件)是否开启。</p>
</div>
</div>
</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.chunked">
<span id="chunkedtransfermiddleware"></span><h3>ChunkedTransferMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.chunked" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.chunked.ChunkedTransferMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.chunked.</tt><tt class="descname">ChunkedTransferMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.chunked.ChunkedTransferMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件添加了对 <a class="reference external" href="http://en.wikipedia.org/wiki/Chunked_transfer_encoding">chunked transfer encoding</a> 的支持。</p>
</dd></dl>

</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.httpproxy">
<span id="httpproxymiddleware"></span><h3>HttpProxyMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.httpproxy" title="永久链接至标题">¶</a></h3>
<div class="versionadded">
<p><span class="versionmodified">0.8 新版功能.</span></p>
</div>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.httpproxy.</tt><tt class="descname">HttpProxyMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件提供了对request设置HTTP代理的支持。您可以通过在
<a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象中设置 <tt class="docutils literal"><span class="pre">proxy</span></tt> 元数据来开启代理。</p>
<p>类似于Python标准库模块 <a class="reference external" href="http://docs.python.org/library/urllib.html">urllib</a> 及 <a class="reference external" href="http://docs.python.org/library/urllib2.html">urllib2</a> ，其使用了下列环境变量:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">http_proxy</span></tt></li>
<li><tt class="docutils literal"><span class="pre">https_proxy</span></tt></li>
<li><tt class="docutils literal"><span class="pre">no_proxy</span></tt></li>
</ul>
</dd></dl>

</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.redirect">
<span id="redirectmiddleware"></span><h3>RedirectMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.redirect" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.redirect.RedirectMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.redirect.</tt><tt class="descname">RedirectMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.redirect.RedirectMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件根据response的状态处理重定向的request。</p>
</dd></dl>

<p id="std:reqmeta-redirect_urls">通过该中间件的(被重定向的)request的url可以通过
<a class="reference internal" href="request-response.html#scrapy.http.Request.meta" title="scrapy.http.Request.meta"><tt class="xref py py-attr docutils literal"><span class="pre">Request.meta</span></tt></a> 的 <tt class="docutils literal"><span class="pre">redirect_urls</span></tt> 键找到。</p>
<p><a class="reference internal" href="#scrapy.contrib.downloadermiddleware.redirect.RedirectMiddleware" title="scrapy.contrib.downloadermiddleware.redirect.RedirectMiddleware"><tt class="xref py py-class docutils literal"><span class="pre">RedirectMiddleware</span></tt></a> 可以通过下列设置进行配置(更多内容请参考设置文档):</p>
<ul class="simple">
<li><a class="reference internal" href="#std:setting-REDIRECT_ENABLED"><tt class="xref std std-setting docutils literal"><span class="pre">REDIRECT_ENABLED</span></tt></a></li>
<li><a class="reference internal" href="settings.html#std:setting-REDIRECT_MAX_TIMES"><tt class="xref std std-setting docutils literal"><span class="pre">REDIRECT_MAX_TIMES</span></tt></a></li>
</ul>
<p id="std:reqmeta-dont_redirect">如果 <a class="reference internal" href="request-response.html#scrapy.http.Request.meta" title="scrapy.http.Request.meta"><tt class="xref py py-attr docutils literal"><span class="pre">Request.meta</span></tt></a> 包含
<tt class="docutils literal"><span class="pre">dont_redirect</span></tt> 键，则该request将会被此中间件忽略。</p>
<div class="section" id="redirectmiddleware-settings">
<h4>RedirectMiddleware settings<a class="headerlink" href="#redirectmiddleware-settings" title="永久链接至标题">¶</a></h4>
<div class="section" id="redirect-enabled">
<span id="std:setting-REDIRECT_ENABLED"></span><h5>REDIRECT_ENABLED<a class="headerlink" href="#redirect-enabled" title="永久链接至标题">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified">0.13 新版功能.</span></p>
</div>
<p>默认: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>是否启用Redirect中间件。</p>
</div>
<div class="section" id="redirect-max-times">
<span id="std:setting-REDIRECT_MAX_TIMES"></span><h5>REDIRECT_MAX_TIMES<a class="headerlink" href="#redirect-max-times" title="永久链接至标题">¶</a></h5>
<p>默认: <tt class="docutils literal"><span class="pre">20</span></tt></p>
<p>单个request被重定向的最大次数。</p>
</div>
</div>
</div>
<div class="section" id="metarefreshmiddleware">
<h3>MetaRefreshMiddleware<a class="headerlink" href="#metarefreshmiddleware" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.redirect.MetaRefreshMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.redirect.</tt><tt class="descname">MetaRefreshMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.redirect.MetaRefreshMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件根据meta-refresh html标签处理request重定向。</p>
</dd></dl>

<p><a class="reference internal" href="#scrapy.contrib.downloadermiddleware.redirect.MetaRefreshMiddleware" title="scrapy.contrib.downloadermiddleware.redirect.MetaRefreshMiddleware"><tt class="xref py py-class docutils literal"><span class="pre">MetaRefreshMiddleware</span></tt></a> 可以通过以下设定进行配置
(更多内容请参考设置文档)。</p>
<ul class="simple">
<li><a class="reference internal" href="#std:setting-METAREFRESH_ENABLED"><tt class="xref std std-setting docutils literal"><span class="pre">METAREFRESH_ENABLED</span></tt></a></li>
<li><tt class="xref std std-setting docutils literal"><span class="pre">METAREFRESH_MAXDELAY</span></tt></li>
</ul>
<p>该中间件遵循 <a class="reference internal" href="#scrapy.contrib.downloadermiddleware.redirect.RedirectMiddleware" title="scrapy.contrib.downloadermiddleware.redirect.RedirectMiddleware"><tt class="xref py py-class docutils literal"><span class="pre">RedirectMiddleware</span></tt></a> 描述的
<a class="reference internal" href="settings.html#std:setting-REDIRECT_MAX_TIMES"><tt class="xref std std-setting docutils literal"><span class="pre">REDIRECT_MAX_TIMES</span></tt></a> 设定，<a class="reference internal" href="#std:reqmeta-dont_redirect"><tt class="xref std std-reqmeta docutils literal"><span class="pre">dont_redirect</span></tt></a>
及 <a class="reference internal" href="#std:reqmeta-redirect_urls"><tt class="xref std std-reqmeta docutils literal"><span class="pre">redirect_urls</span></tt></a> meta key。</p>
<div class="section" id="metarefreshmiddleware-settings">
<h4>MetaRefreshMiddleware settings<a class="headerlink" href="#metarefreshmiddleware-settings" title="永久链接至标题">¶</a></h4>
<div class="section" id="metarefresh-enabled">
<span id="std:setting-METAREFRESH_ENABLED"></span><h5>METAREFRESH_ENABLED<a class="headerlink" href="#metarefresh-enabled" title="永久链接至标题">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified">0.17 新版功能.</span></p>
</div>
<p>默认: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>Meta Refresh中间件是否启用。</p>
</div>
<div class="section" id="redirect-max-metarefresh-delay">
<span id="std:setting-REDIRECT_MAX_METAREFRESH_DELAY"></span><h5>REDIRECT_MAX_METAREFRESH_DELAY<a class="headerlink" href="#redirect-max-metarefresh-delay" title="永久链接至标题">¶</a></h5>
<p>默认: <tt class="docutils literal"><span class="pre">100</span></tt></p>
<p>跟进重定向的最大 meta-refresh 延迟(单位:秒)。</p>
</div>
</div>
</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.retry">
<span id="retrymiddleware"></span><h3>RetryMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.retry" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.retry.RetryMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.retry.</tt><tt class="descname">RetryMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.retry.RetryMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件将重试可能由于临时的问题，例如连接超时或者HTTP 500错误导致失败的页面。</p>
</dd></dl>

<p>爬取进程会收集失败的页面并在最后，spider爬取完所有正常(不失败)的页面后重新调度。
一旦没有更多需要重试的失败页面，该中间件将会发送一个信号(retry_complete)，
其他插件可以监听该信号。</p>
<p><a class="reference internal" href="#scrapy.contrib.downloadermiddleware.retry.RetryMiddleware" title="scrapy.contrib.downloadermiddleware.retry.RetryMiddleware"><tt class="xref py py-class docutils literal"><span class="pre">RetryMiddleware</span></tt></a> 可以通过下列设定进行配置
(更多内容请参考设置文档):</p>
<ul class="simple">
<li><a class="reference internal" href="#std:setting-RETRY_ENABLED"><tt class="xref std std-setting docutils literal"><span class="pre">RETRY_ENABLED</span></tt></a></li>
<li><a class="reference internal" href="#std:setting-RETRY_TIMES"><tt class="xref std std-setting docutils literal"><span class="pre">RETRY_TIMES</span></tt></a></li>
<li><a class="reference internal" href="#std:setting-RETRY_HTTP_CODES"><tt class="xref std std-setting docutils literal"><span class="pre">RETRY_HTTP_CODES</span></tt></a></li>
</ul>
<p>关于HTTP错误的考虑:</p>
<p>如果根据HTTP协议，您可能想要在设定 <a class="reference internal" href="#std:setting-RETRY_HTTP_CODES"><tt class="xref std std-setting docutils literal"><span class="pre">RETRY_HTTP_CODES</span></tt></a> 中移除400错误。
该错误被默认包括是由于这个代码经常被用来指示服务器过载(overload)了。而在这种情况下，我们想进行重试。</p>
<p id="std:reqmeta-dont_retry">如果 <a class="reference internal" href="request-response.html#scrapy.http.Request.meta" title="scrapy.http.Request.meta"><tt class="xref py py-attr docutils literal"><span class="pre">Request.meta</span></tt></a> 包含 <tt class="docutils literal"><span class="pre">dont_retry</span></tt> 键，
该request将会被本中间件忽略。</p>
<div class="section" id="retrymiddleware-settings">
<h4>RetryMiddleware Settings<a class="headerlink" href="#retrymiddleware-settings" title="永久链接至标题">¶</a></h4>
<div class="section" id="retry-enabled">
<span id="std:setting-RETRY_ENABLED"></span><h5>RETRY_ENABLED<a class="headerlink" href="#retry-enabled" title="永久链接至标题">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified">0.13 新版功能.</span></p>
</div>
<p>默认: <tt class="docutils literal"><span class="pre">True</span></tt></p>
<p>Retry Middleware是否启用。</p>
</div>
<div class="section" id="retry-times">
<span id="std:setting-RETRY_TIMES"></span><h5>RETRY_TIMES<a class="headerlink" href="#retry-times" title="永久链接至标题">¶</a></h5>
<p>默认: <tt class="docutils literal"><span class="pre">2</span></tt></p>
<p>包括第一次下载，最多的重试次数</p>
</div>
<div class="section" id="retry-http-codes">
<span id="std:setting-RETRY_HTTP_CODES"></span><h5>RETRY_HTTP_CODES<a class="headerlink" href="#retry-http-codes" title="永久链接至标题">¶</a></h5>
<p>默认: <tt class="docutils literal"><span class="pre">[500,</span> <span class="pre">502,</span> <span class="pre">503,</span> <span class="pre">504,</span> <span class="pre">400,</span> <span class="pre">408]</span></tt></p>
<p>重试的response 返回值(code)。其他错误(DNS查找问题、连接失败及其他)则一定会进行重试。</p>
</div>
</div>
</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.robotstxt">
<span id="robotstxtmiddleware"></span><span id="topics-dlmw-robots"></span><h3>RobotsTxtMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.robotstxt" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.robotstxt.RobotsTxtMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.robotstxt.</tt><tt class="descname">RobotsTxtMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.robotstxt.RobotsTxtMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>该中间件过滤所有robots.txt eclusion standard中禁止的request。</p>
<p>确认该中间件及 <a class="reference internal" href="settings.html#std:setting-ROBOTSTXT_OBEY"><tt class="xref std std-setting docutils literal"><span class="pre">ROBOTSTXT_OBEY</span></tt></a> 设置被启用以确保Scrapy尊重robots.txt。</p>
<div class="admonition warning">
<p class="first admonition-title">警告</p>
<p class="last">记住, 如果您在一个网站中使用了多个并发请求，
Scrapy仍然可能下载一些被禁止的页面。这是由于这些页面是在robots.txt被下载前被请求的。
这是当前robots.txt中间件已知的限制，并将在未来进行修复。</p>
</div>
</dd></dl>

</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.stats">
<span id="downloaderstats"></span><h3>DownloaderStats<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.stats" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.stats.DownloaderStats">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.stats.</tt><tt class="descname">DownloaderStats</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.stats.DownloaderStats" title="永久链接至目标">¶</a></dt>
<dd><p>保存所有通过的request、response及exception的中间件。</p>
<p>您必须启用 <a class="reference internal" href="settings.html#std:setting-DOWNLOADER_STATS"><tt class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_STATS</span></tt></a> 来启用该中间件。</p>
</dd></dl>

</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.useragent">
<span id="useragentmiddleware"></span><h3>UserAgentMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.useragent" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.useragent.</tt><tt class="descname">UserAgentMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>用于覆盖spider的默认user agent的中间件。</p>
<p>要使得spider能覆盖默认的user agent，其 <cite>user_agent</cite> 属性必须被设置。</p>
</dd></dl>

</div>
<div class="section" id="module-scrapy.contrib.downloadermiddleware.ajaxcrawl">
<span id="ajaxcrawlmiddleware"></span><span id="ajaxcrawl-middleware"></span><h3>AjaxCrawlMiddleware<a class="headerlink" href="#module-scrapy.contrib.downloadermiddleware.ajaxcrawl" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.downloadermiddleware.ajaxcrawl.AjaxCrawlMiddleware">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.downloadermiddleware.ajaxcrawl.</tt><tt class="descname">AjaxCrawlMiddleware</tt><a class="headerlink" href="#scrapy.contrib.downloadermiddleware.ajaxcrawl.AjaxCrawlMiddleware" title="永久链接至目标">¶</a></dt>
<dd><p>根据meta-fragment html标签查找 &#8216;AJAX可爬取&#8217; 页面的中间件。查看
<a class="reference external" href="https://developers.google.com/webmasters/ajax-crawling/docs/getting-started">https://developers.google.com/webmasters/ajax-crawling/docs/getting-started</a>
来获得更多内容。</p>
<div class="admonition note">
<p class="first admonition-title">注解</p>
<p class="last">即使没有启用该中间件，Scrapy仍能查找类似于
<tt class="docutils literal"><span class="pre">'http://example.com/!#foo=bar'</span></tt> 这样的&#8217;AJAX可爬取&#8217;页面。
AjaxCrawlMiddleware是针对不具有 <tt class="docutils literal"><span class="pre">'!#'</span></tt> 的URL，通常发生在&#8217;index&#8217;或者&#8217;main&#8217;页面中。</p>
</div>
</dd></dl>

<div class="section" id="id4">
<h4>AjaxCrawlMiddleware设置<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h4>
<div class="section" id="ajaxcrawl-enabled">
<span id="std:setting-AJAXCRAWL_ENABLED"></span><h5>AJAXCRAWL_ENABLED<a class="headerlink" href="#ajaxcrawl-enabled" title="永久链接至标题">¶</a></h5>
<div class="versionadded">
<p><span class="versionmodified">0.21 新版功能.</span></p>
</div>
<p>默认: <tt class="docutils literal"><span class="pre">False</span></tt></p>
<p>AjaxCrawlMiddleware是否启用。您可能需要针对 <a class="reference internal" href="broad-crawls.html#topics-broad-crawls"><em>通用爬虫</em></a> 启用该中间件。</p>
</div>
</div>
</div>
</div>
</div>


    
        <h2>
            讨论
            <a class="headerlink" href="#discuss" title="永久链接至标题">¶</a>
        </h2>

        <div id="disqus_thread"></div>
    

          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="spider-middleware.html" class="btn btn-neutral float-right" title="Spider中间件(Middleware)">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="architecture.html" class="btn btn-neutral" title="架构概览"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; 版权所有 2008-2014, written by Scrapy developers, translated by Summer&amp;Friends.
      最后更新于 Feb 03, 2015.
    </p>
  </div>

  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
</footer>
        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: stable
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="/zh_CN/latest/">latest</a></dd>
        
          <dd><a href="/zh_CN/stable/">stable</a></dd>
        
          <dd><a href="/zh_CN/master/">master</a></dd>
        
          <dd><a href="/zh_CN/0.24/">0.24</a></dd>
        
          <dd><a href="/zh_CN/0.22/">0.22</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="//readthedocs.org/projects/scrapy-chs/downloads/htmlzip/stable/">HTML</a></dd>
        
          <dd><a href="//readthedocs.org/projects/scrapy-chs/downloads/epub/stable/">Epub</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="//readthedocs.org/projects/scrapy-chs/?fromdocs=scrapy-chs">Project Home</a>
          </dd>
          <dd>
            <a href="//readthedocs.org/builds/scrapy-chs/?fromdocs=scrapy-chs">Builds</a>
          </dd>
      </dl>
      <hr/>
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.

    </div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.22.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="../_static/translations.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
     
    
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'scrapychs'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
     var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
     dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
     (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();

    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
         (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
           m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
             })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-50189694-1', 'readthedocs.org');
      ga('send', 'pageview');

    </script>
    


</body>
</html>