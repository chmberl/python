

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Spiders &mdash; Scrapy 0.22.2 文档</title>
  

  
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  
  
    

  

  
  

  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/sphinx_rtd_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />
  
    <link rel="top" title="Scrapy 0.22.2 文档" href="../index.html"/>
        <link rel="next" title="选择器（Selectors）" href="selectors.html"/>
        <link rel="prev" title="Items" href="items.html"/>
 
<!-- RTD Extra Head -->



<!-- 
Read the Docs is acting as the canonical URL for your project. 
If you want to change it, more info is available in our docs:
  http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="http://scrapy-chs.readthedocs.org/zh_CN/latest/topics/spiders.html" />

<script type="text/javascript">
  // This is included here because other places don't have access to the pagename variable.
  var READTHEDOCS_DATA = {
    project: "scrapy-chs",
    version: "stable",
    language: "zh_CN",
    page: "topics/spiders",
    builder: "sphinx",
    theme: "sphinx_rtd_theme",
    docroot: "/",
    source_suffix: ".rst",
    api_host: "https://readthedocs.org",
    commit: "094b55236635f45d4531e48ee9f693c796e0144d"
  }
  // Old variables
  var doc_version = "stable";
  var doc_slug = "scrapy-chs";
  var page_name = "topics/spiders";
  var html_theme = "sphinx_rtd_theme";
</script>
<!-- RTD Analytics Code -->
<!-- Included in the header because you don't have a footer block. -->
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-17997319-1']);
  _gaq.push(['_trackPageview']);


  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<!-- end RTD Analytics Code -->
<!-- end RTD <extrahead> -->


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        
          <a href="../index.html" class="fa fa-home"> Scrapy</a>
        
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
        
            <ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/overview.html">初窥Scrapy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#id1">选择一个网站</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#intro-overview-item">定义您想抓取的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#spider">编写提取数据的Spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#id3">执行spider，获取数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#id4">查看提取到的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#topics-whatelse">还有什么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/overview.html#id6">接下来</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/install.html">安装指南</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#id2">前期准备</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#scrapy">安装Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/install.html#intro-install-platform-notes">平台安装指南</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/tutorial.html">Scrapy入门教程</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#id2">创建项目</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#item">定义Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#spider">编写第一个爬虫(Spider)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#id9">保存爬取到的数据</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intro/tutorial.html#id10">下一步</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intro/examples.html">例子</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="commands.html">命令行工具(Command line tools)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="commands.html#scrapy">默认的Scrapy项目结构</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#id1">使用 <tt class="docutils literal"><span class="pre">scrapy</span></tt> 工具</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#tool-commands">可用的工具命令(tool commands)</a></li>
<li class="toctree-l2"><a class="reference internal" href="commands.html#id4">自定义项目命令</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="items.html">Items</a><ul>
<li class="toctree-l2"><a class="reference internal" href="items.html#item">声明Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#item-item-fields">Item字段(Item Fields)</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#id1">与Item配合</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#id7">扩展Item</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#id8">Item对象</a></li>
<li class="toctree-l2"><a class="reference internal" href="items.html#field">字段(Field)对象</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="">Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#spider">Spider参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="#topics-spiders-ref">内置Spider参考手册</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="selectors.html">选择器（Selectors）</a><ul>
<li class="toctree-l2"><a class="reference internal" href="selectors.html#id1">使用选择器（selectors）</a></li>
<li class="toctree-l2"><a class="reference internal" href="selectors.html#module-scrapy.selector">内建选择器的参考</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="loaders.html">Item Loaders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#using-item-loaders-to-populate-items">Using Item Loaders to populate items</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#input-and-output-processors">Input and Output processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#declaring-item-loaders">Declaring Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#declaring-input-and-output-processors">Declaring Input and Output Processors</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#item-loader-context">Item Loader Context</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#itemloader-objects">ItemLoader objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#reusing-and-extending-item-loaders">Reusing and extending Item Loaders</a></li>
<li class="toctree-l2"><a class="reference internal" href="loaders.html#module-scrapy.contrib.loader.processor">Available built-in processors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="shell.html">Scrapy终端(Scrapy shell)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="shell.html#id1">启动终端</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#id2">使用终端</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#shell-session">终端会话(shell session)样例</a></li>
<li class="toctree-l2"><a class="reference internal" href="shell.html#spidershellresponse">在spider中启动shell来查看response</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="item-pipeline.html">Item Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#id1">编写你自己的item pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#id2">Item pipeline 样例</a></li>
<li class="toctree-l2"><a class="reference internal" href="item-pipeline.html#id4">启用一个Item Pipeline组件</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="feed-exports.html">Feed exports</a><ul>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#serialization-formats">序列化方式(Serialization formats)</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#storages">存储(Storages)</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#uri">存储URI参数</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#storage-backends">存储端(Storage backends)</a></li>
<li class="toctree-l2"><a class="reference internal" href="feed-exports.html#settings">设定(Settings)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="link-extractors.html">Link Extractors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="link-extractors.html#module-scrapy.contrib.linkextractors">内置Link Extractor 参考</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="logging.html">Logging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="logging.html#log-levels">Log levels</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#log">如何设置log级别</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#log-messages">如何记录信息(log messages)</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#spiderlog-logging-from-spiders">在Spider中添加log(Logging from Spiders)</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#module-scrapy.log">scrapy.log模块</a></li>
<li class="toctree-l2"><a class="reference internal" href="logging.html#id1">Logging设置</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="stats.html">数据收集(Stats Collection)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="stats.html#topics-stats-usecases">常见数据收集器使用方法</a></li>
<li class="toctree-l2"><a class="reference internal" href="stats.html#id2">可用的数据收集器</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="email.html">发送email</a><ul>
<li class="toctree-l2"><a class="reference internal" href="email.html#id1">简单例子</a></li>
<li class="toctree-l2"><a class="reference internal" href="email.html#mailsender">MailSender类参考手册</a></li>
<li class="toctree-l2"><a class="reference internal" href="email.html#mail">Mail设置</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="telnetconsole.html">Telnet终端(Telnet Console)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#telnet">如何访问telnet终端</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#id1">telnet终端中可用的变量</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#telnet-console-usage-examples">Telnet console usage examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#id3">Telnet终端信号</a></li>
<li class="toctree-l2"><a class="reference internal" href="telnetconsole.html#id4">Telnet设定</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="webservice.html">Web Service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#web-service-resources">Web Service资源(resources)</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#web">Web服务设置</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#web-resource">编写web服务资源(resource)</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#id2">web服务资源例子</a></li>
<li class="toctree-l2"><a class="reference internal" href="webservice.html#example-of-web-service-client">Example of web service client</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">常见问题(FAQ)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapybeautifulsouplxml">Scrapy相BeautifulSoup或lxml比较,如何呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapypython">Scrapy支持那些Python版本？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapypython-3">Scrapy支持Python 3么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapydjango-x">Scrapy是否从Django中&#8221;剽窃&#8221;了X呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapyhttp">Scrapy支持HTTP代理么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#item">如何爬取属性在不同页面的item呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy-importerror-nomodule-named-win32api">Scrapy退出，ImportError: Nomodule named win32api</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#spider">我要如何在spider里模拟用户登录呢?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy">Scrapy是以广度优先还是深度优先进行爬取的呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id3">我的Scrapy爬虫有内存泄露，怎么办?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id4">如何让Scrapy减少内存消耗?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#spiderhttp">我能在spider中使用基本HTTP认证么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id5">为什么Scrapy下载了英文的页面，而不是我的本国语言？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id6">我能在哪里找到Scrapy项目的例子？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy-spider">我能在不创建Scrapy项目的情况下运行一个爬虫(spider)么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#filtered-offsite-request">我收到了 &#8220;Filtered offsite request&#8221; 消息。如何修复？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id7">发布Scrapy爬虫到生产环境的推荐方式？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#large-exports-json">我能对大数据(large exports)使用JSON么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#signal-handler-twisted">我能在信号处理器(signal handler)中返回(Twisted)引用么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#reponse999">reponse返回的状态值999代表了什么?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#spider-pdb-set-trace">我能在spider中调用 <tt class="docutils literal"><span class="pre">pdb.set_trace()</span></tt> 来调试么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#item-dump-json-csv-xml">将所有爬取到的item转存(dump)到JSON/CSV/XML文件的最简单的方法?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#viewstate">在某些表单中巨大神秘的 <tt class="docutils literal"><span class="pre">__VIEWSTATE</span></tt> 参数是什么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#xml-csv">分析大XML/CSV数据源的最好方法是?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapycookies">Scrapy自动管理cookies么？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapyscrapy">如何才能看到Scrapy发出及接收到的Scrapy呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#id10">要怎么停止爬虫呢?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#scrapy-bot-ban">如何避免我的Scrapy机器人(bot)被禁止(ban)呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#spider-arguments-settings-spider">我应该使用spider参数(arguments)还是设置(settings)来配置spider呢？</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#xmlxpathitem">我爬取了一个XML文档但是XPath选择器不返回任何的item</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#name-crawler">我得到错误: &#8220;不能导入name crawler“</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">调试(Debugging)Spiders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="debug.html#parse">Parse命令</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#scrapy-shell">Scrapy终端(Shell)</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#id1">在浏览器中打开</a></li>
<li class="toctree-l2"><a class="reference internal" href="debug.html#logging">Logging</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="contracts.html">Spiders Contracts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contracts.html#contracts">自定义Contracts</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="practices.html">实践经验(Common Practices)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="practices.html#scrapy">在脚本中运行Scrapy</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#spider">同一进程运行多个spider</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#distributed-crawls">分布式爬虫(Distributed crawls)</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#ban">避免被禁止(ban)</a></li>
<li class="toctree-l2"><a class="reference internal" href="practices.html#item">动态创建Item类</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="broad-crawls.html">通用爬虫(Broad Crawls)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#id1">增加并发</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#log">降低log级别</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#cookies">禁止cookies</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#id2">禁止重试</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#id3">减小下载超时</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#id4">禁止重定向</a></li>
<li class="toctree-l2"><a class="reference internal" href="broad-crawls.html#ajax-crawlable-pages">启用 &#8220;Ajax Crawlable Pages&#8221; 爬取</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="firefox.html">借助Firefox来爬取</a><ul>
<li class="toctree-l2"><a class="reference internal" href="firefox.html#dom">在浏览器中检查DOM的注意事项</a></li>
<li class="toctree-l2"><a class="reference internal" href="firefox.html#topics-firefox-addons">对爬取有帮助的实用Firefox插件</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="firebug.html">使用Firebug进行爬取</a><ul>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#id1">介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#follow">获取到跟进(follow)的链接</a></li>
<li class="toctree-l2"><a class="reference internal" href="firebug.html#id4">提取数据</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="leaks.html">调试内存溢出</a><ul>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#id2">内存泄露的常见原因</a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#trackref">使用 <tt class="docutils literal"><span class="pre">trackref</span></tt> 调试内存泄露</a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#guppy">使用Guppy调试内存泄露</a></li>
<li class="toctree-l2"><a class="reference internal" href="leaks.html#leaks-without-leaks">Leaks without leaks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="images.html">下载项目图片</a><ul>
<li class="toctree-l2"><a class="reference internal" href="images.html#id2">使用图片管道</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#id3">使用样例</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#topics-images-enabling">开启你的图片管道</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#id5">图片存储</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#id7">额外的特性</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#module-scrapy.contrib.pipeline.images">实现定制图片管道</a></li>
<li class="toctree-l2"><a class="reference internal" href="images.html#id12">定制图片管道的例子</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ubuntu.html">Ubuntu 软件包</a></li>
<li class="toctree-l1"><a class="reference internal" href="scrapyd.html">Scrapyd</a></li>
<li class="toctree-l1"><a class="reference internal" href="autothrottle.html">自动限速(AutoThrottle)扩展</a><ul>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#id1">设计目标</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#id2">扩展是如何实现的</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#autothrottle-algorithm">限速算法</a></li>
<li class="toctree-l2"><a class="reference internal" href="autothrottle.html#id4">设置</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="jobs.html">Jobs: 暂停，恢复爬虫</a><ul>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#job">Job 路径</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#id1">怎么使用</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#id2">保持状态</a></li>
<li class="toctree-l2"><a class="reference internal" href="jobs.html#id3">持久化的一些坑</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="djangoitem.html">DjangoItem</a><ul>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#id1">使用DjangoItem</a></li>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#id2">DjangoItem注意事项</a></li>
<li class="toctree-l2"><a class="reference internal" href="djangoitem.html#django">配置Django的设置</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">架构概览</a><ul>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#id2">概述</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#id3">组件</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#data-flow">数据流(Data flow)</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html#event-driven-networking">事件驱动网络(Event-driven networking)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="downloader-middleware.html">下载器中间件(Downloader Middleware)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting">激活下载器中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="downloader-middleware.html#id2">编写您自己的下载器中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-ref">内置下载中间件参考手册</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="spider-middleware.html">Spider中间件(Middleware)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="spider-middleware.html#spider">激活spider中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="spider-middleware.html#id1">编写您自己的spider中间件</a></li>
<li class="toctree-l2"><a class="reference internal" href="spider-middleware.html#topics-spider-middleware-ref">内置spider中间件参考手册</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="extensions.html">扩展(Extensions)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#extension-settings">扩展设置(Extension settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#id1">加载和激活扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#available-enabled-disabled">可用的(Available)、开启的(enabled)和禁用的(disabled)的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#disabling-an-extension">禁用扩展(Disabling an extension)</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#id2">实现你的扩展</a></li>
<li class="toctree-l2"><a class="reference internal" href="extensions.html#topics-extensions-ref">内置扩展介绍</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">核心API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api.html#crawler-api">Crawler API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#module-scrapy.settings">设置(Settings) API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#module-scrapy.signalmanager">信号(Signals) API</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#stats-collector-api">状态收集器(Stats Collector) API</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="request-response.html">Requests and Responses</a><ul>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-objects">Request objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-meta-special-keys">Request.meta special keys</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#request-subclasses">Request subclasses</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#response-objects">Response objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="request-response.html#response-subclasses">Response subclasses</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="settings.html">Settings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="settings.html#designating-the-settings">指定设定(Designating the settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#populating-the-settings">获取设定值(Populating the settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#how-to-access-settings">如何访问设定(How to access settings)</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#id1">设定名字的命名规则</a></li>
<li class="toctree-l2"><a class="reference internal" href="settings.html#topics-settings-ref">内置设定参考手册</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="signals.html">信号(Signals)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="signals.html#deferred-signal-handlers">延迟的信号处理器(Deferred signal handlers)</a></li>
<li class="toctree-l2"><a class="reference internal" href="signals.html#module-scrapy.signals">内置信号参考手册(Built-in signals reference)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exceptions.html">异常(Exceptions)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="exceptions.html#built-in-exceptions-reference">内置异常参考手册(Built-in Exceptions reference)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="exporters.html">Item Exporters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="exporters.html#item-exporter">使用 Item Exporter</a></li>
<li class="toctree-l2"><a class="reference internal" href="exporters.html#topics-exporters-reference">Item Exporters 参考资料</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">Release notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-02-14">0.22.2 (released 2014-02-14)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-02-08">0.22.1 (released 2014-02-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2014-01-17">0.22.0 (released 2014-01-17)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-12-09">0.20.2 (released 2013-12-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-11-28">0.20.1 (released 2013-11-28)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-11-08">0.20.0 (released 2013-11-08)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-10-10">0.18.4 (released 2013-10-10)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-10-03">0.18.3 (released 2013-10-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-09-03">0.18.2 (released 2013-09-03)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-08-27">0.18.1 (released 2013-08-27)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-08-09">0.18.0 (released 2013-08-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-05-30">0.16.5 (released 2013-05-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2013-01-23">0.16.4 (released 2013-01-23)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-12-07">0.16.3 (released 2012-12-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-11-09">0.16.2 (released 2012-11-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-10-26">0.16.1 (released 2012-10-26)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#released-2012-10-18">0.16.0 (released 2012-10-18)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id2">0.14.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id3">0.14.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id4">0.14.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id5">0.14.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id6">0.14</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id7">0.12</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id8">0.10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id11">0.9</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id14">0.8</a></li>
<li class="toctree-l2"><a class="reference internal" href="../news.html#id15">0.7</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to Scrapy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#reporting-bugs">Reporting bugs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#writing-patches">Writing patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#submitting-patches">Submitting patches</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#coding-style">Coding style</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#scrapy-contrib">Scrapy Contrib</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#documentation-policies">Documentation policies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contributing.html#tests">Tests</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../versioning.html">Versioning and API Stability</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../versioning.html#id1">Versioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../versioning.html#api-stability">API Stability</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../experimental/index.html">试验阶段特性</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../experimental/index.html#id3">使用外部库插入命令</a></li>
</ul>
</li>
</ul>

        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Scrapy</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>Spiders</li>
      <li class="wy-breadcrumbs-aside">
        
          <a href="https://github.com/marchtea/scrapy_doc_chs/blob/stable/topics/spiders.rst" class="fa fa-github"> Edit on GitHub</a>
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
    
  <div class="section" id="spiders">
<span id="topics-spiders"></span><h1>Spiders<a class="headerlink" href="#spiders" title="永久链接至标题">¶</a></h1>
<p>Spider类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页的内容中提取结构化数据(爬取item)。
换句话说，Spider就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。</p>
<p>对spider来说，爬取的循环类似下文:</p>
<ol class="arabic">
<li><p class="first">以初始的URL初始化Request，并设置回调函数。
当该request下载完毕并返回时，将生成response，并作为参数传给该回调函数。</p>
<p>spider中初始的request是通过调用 <a class="reference internal" href="#scrapy.spider.Spider.start_requests" title="scrapy.spider.Spider.start_requests"><tt class="xref py py-meth docutils literal"><span class="pre">start_requests()</span></tt></a> 来获取的。
<a class="reference internal" href="#scrapy.spider.Spider.start_requests" title="scrapy.spider.Spider.start_requests"><tt class="xref py py-meth docutils literal"><span class="pre">start_requests()</span></tt></a> 读取 <a class="reference internal" href="#scrapy.spider.Spider.start_urls" title="scrapy.spider.Spider.start_urls"><tt class="xref py py-attr docutils literal"><span class="pre">start_urls</span></tt></a> 中的URL，
并以 <a class="reference internal" href="#scrapy.spider.Spider.parse" title="scrapy.spider.Spider.parse"><tt class="xref py py-attr docutils literal"><span class="pre">parse</span></tt></a> 为回调函数生成 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 。</p>
</li>
<li><p class="first">在回调函数内分析返回的(网页)内容，返回 <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> 对象或者 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 或者一个包括二者的可迭代容器。
返回的Request对象之后会经过Scrapy处理，下载相应的内容，并调用设置的callback函数(函数可相同)。</p>
</li>
<li><p class="first">在回调函数内，您可以使用 <a class="reference internal" href="selectors.html#topics-selectors"><em>选择器（Selectors）</em></a>
(您也可以使用BeautifulSoup, lxml 或者您想用的任何解析器) 来分析网页内容，并根据分析的数据生成item。</p>
</li>
<li><p class="first">最后，由spider返回的item将被存到数据库(由某些
<a class="reference internal" href="item-pipeline.html#topics-item-pipeline"><em>Item Pipeline</em></a> 处理)或使用
<a class="reference internal" href="feed-exports.html#topics-feed-exports"><em>Feed exports</em></a> 存入到文件中。</p>
</li>
</ol>
<p>虽然该循环对任何类型的spider都(多少)适用，但Scrapy仍然为了不同的需求提供了多种默认spider。
之后将讨论这些spider。</p>
<div class="section" id="spider">
<span id="spiderargs"></span><h2>Spider参数<a class="headerlink" href="#spider" title="永久链接至标题">¶</a></h2>
<p>Spider可以通过接受参数来修改其功能。
spider参数一般用来定义初始URL或者指定限制爬取网站的部分。
您也可以使用其来配置spider的任何功能。</p>
<p>在运行 <a class="reference internal" href="commands.html#std:command-crawl"><tt class="xref std std-command docutils literal"><span class="pre">crawl</span></tt></a> 时添加 <tt class="docutils literal"><span class="pre">-a</span></tt> 可以传递Spider参数:</p>
<div class="highlight-python"><div class="highlight"><pre>scrapy crawl myspider -a category=electronics
</pre></div>
</div>
<p>Spider在构造器(constructor)中获取参数:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;myspider&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MySpider</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/categories/</span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">category</span><span class="p">]</span>
        <span class="c"># ...</span>
</pre></div>
</div>
<p>Spider参数也可以通过Scrapyd的 <tt class="docutils literal"><span class="pre">schedule.json</span></tt> API来传递。
参见 <a class="reference external" href="http://scrapyd.readthedocs.org/">Scrapyd documentation</a>.</p>
</div>
<div class="section" id="topics-spiders-ref">
<span id="id1"></span><h2>内置Spider参考手册<a class="headerlink" href="#topics-spiders-ref" title="永久链接至标题">¶</a></h2>
<p>Scrapy提供多种方便的通用spider供您继承使用。
这些spider为一些常用的爬取情况提供方便的特性，
例如根据某些规则跟进某个网站的所有链接、根据 <a class="reference external" href="http://www.sitemaps.org">Sitemaps</a> 来进行爬取，或者分析XML/CSV源。</p>
<p>下面spider的示例中，我们假定您有个项目在 <tt class="docutils literal"><span class="pre">myproject.items</span></tt> 模块中声明了 <tt class="docutils literal"><span class="pre">TestItem</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.item</span> <span class="kn">import</span> <span class="n">Item</span>

<span class="k">class</span> <span class="nc">TestItem</span><span class="p">(</span><span class="n">Item</span><span class="p">):</span>
    <span class="nb">id</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
    <span class="n">description</span> <span class="o">=</span> <span class="n">Field</span><span class="p">()</span>
</pre></div>
</div>
<span class="target" id="module-scrapy.spider"></span><div class="section" id="id2">
<h3>Spider<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.spider.Spider">
<em class="property">class </em><tt class="descclassname">scrapy.spider.</tt><tt class="descname">Spider</tt><a class="headerlink" href="#scrapy.spider.Spider" title="永久链接至目标">¶</a></dt>
<dd><p>Spider是最简单的spider。每个其他的spider必须继承自该类(包括Scrapy自带的其他spider以及您自己编写的spider)。
Spider并没有提供什么特殊的功能。
其仅仅请求给定的 <tt class="docutils literal"><span class="pre">start_urls</span></tt>/<tt class="docutils literal"><span class="pre">start_requests</span></tt> ，并根据返回的结果(resulting responses)调用spider的 <tt class="docutils literal"><span class="pre">parse</span></tt> 方法。</p>
<dl class="attribute">
<dt id="scrapy.spider.Spider.name">
<tt class="descname">name</tt><a class="headerlink" href="#scrapy.spider.Spider.name" title="永久链接至目标">¶</a></dt>
<dd><p>定义spider名字的字符串(string)。spider的名字定义了Scrapy如何定位(并初始化)spider，所以其必须是唯一的。
不过您可以生成多个相同的spider实例(instance)，这没有任何限制。
name是spider最重要的属性，而且是必须的。</p>
<p>如果该spider爬取单个网站(single domain)，一个常见的做法是以该网站(domain)(加或不加 <a class="reference external" href="http://en.wikipedia.org/wiki/Top-level_domain">后缀</a> )来命名spider。
例如，如果spider爬取 <tt class="docutils literal"><span class="pre">mywebsite.com</span></tt> ，该spider通常会被命名为 <tt class="docutils literal"><span class="pre">mywebsite</span></tt> 。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spider.Spider.allowed_domains">
<tt class="descname">allowed_domains</tt><a class="headerlink" href="#scrapy.spider.Spider.allowed_domains" title="永久链接至目标">¶</a></dt>
<dd><p>可选。包含了spider允许爬取的域名(domain)列表(list)。
当 <a class="reference internal" href="spider-middleware.html#scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware" title="scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware"><tt class="xref py py-class docutils literal"><span class="pre">OffsiteMiddleware</span></tt></a> 启用时，
域名不在列表中的URL不会被跟进。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.spider.Spider.start_urls">
<tt class="descname">start_urls</tt><a class="headerlink" href="#scrapy.spider.Spider.start_urls" title="永久链接至目标">¶</a></dt>
<dd><p>URL列表。当没有制定特定的URL时，spider将从该列表中开始进行爬取。
因此，第一个被获取到的页面的URL将是该列表之一。
后续的URL将会从获取到的数据中提取。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spider.Spider.start_requests">
<tt class="descname">start_requests</tt><big>(</big><big>)</big><a class="headerlink" href="#scrapy.spider.Spider.start_requests" title="永久链接至目标">¶</a></dt>
<dd><p>该方法必须返回一个可迭代对象(iterable)。该对象包含了spider用于爬取的第一个Request。</p>
<p>当spider启动爬取并且未制定URL时，该方法被调用。
当指定了URL时，<a class="reference internal" href="#scrapy.spider.Spider.make_requests_from_url" title="scrapy.spider.Spider.make_requests_from_url"><tt class="xref py py-meth docutils literal"><span class="pre">make_requests_from_url()</span></tt></a> 将被调用来创建Request对象。
该方法仅仅会被Scrapy调用一次，因此您可以将其实现为生成器。</p>
<p>该方法的默认实现是使用 <a class="reference internal" href="#scrapy.spider.Spider.start_urls" title="scrapy.spider.Spider.start_urls"><tt class="xref py py-attr docutils literal"><span class="pre">start_urls</span></tt></a> 的url生成Request。</p>
<p>如果您想要修改最初爬取某个网站的Request对象，您可以重写(override)该方法。
例如，如果您需要在启动时以POST登录某个网站，你可以这么写:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">FormRequest</span><span class="p">(</span><span class="s">&quot;http://www.example.com/login&quot;</span><span class="p">,</span>
                        <span class="n">formdata</span><span class="o">=</span><span class="p">{</span><span class="s">&#39;user&#39;</span><span class="p">:</span> <span class="s">&#39;john&#39;</span><span class="p">,</span> <span class="s">&#39;pass&#39;</span><span class="p">:</span> <span class="s">&#39;secret&#39;</span><span class="p">},</span>
                        <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">logged_in</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">logged_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="c"># here you would extract links to follow and return Requests for</span>
    <span class="c"># each of them, with another callback</span>
    <span class="k">pass</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="scrapy.spider.Spider.make_requests_from_url">
<tt class="descname">make_requests_from_url</tt><big>(</big><em>url</em><big>)</big><a class="headerlink" href="#scrapy.spider.Spider.make_requests_from_url" title="永久链接至目标">¶</a></dt>
<dd><p>该方法接受一个URL并返回用于爬取的 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象。
该方法在初始化request时被 <a class="reference internal" href="#scrapy.spider.Spider.start_requests" title="scrapy.spider.Spider.start_requests"><tt class="xref py py-meth docutils literal"><span class="pre">start_requests()</span></tt></a> 调用，也被用于转化url为request。</p>
<p>默认未被复写(overridden)的情况下，该方法返回的Request对象中，
<a class="reference internal" href="#scrapy.spider.Spider.parse" title="scrapy.spider.Spider.parse"><tt class="xref py py-meth docutils literal"><span class="pre">parse()</span></tt></a> 作为回调函数，dont_filter参数也被设置为开启。
(详情参见 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a>).</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.spider.Spider.parse">
<tt class="descname">parse</tt><big>(</big><em>response</em><big>)</big><a class="headerlink" href="#scrapy.spider.Spider.parse" title="永久链接至目标">¶</a></dt>
<dd><p>当response没有指定回调函数时，该方法是Scrapy处理下载的response的默认方法。</p>
<p><tt class="docutils literal"><span class="pre">parse</span></tt> 负责处理response并返回处理的数据以及(/或)跟进的URL。
<a class="reference internal" href="#scrapy.spider.Spider" title="scrapy.spider.Spider"><tt class="xref py py-class docutils literal"><span class="pre">Spider</span></tt></a> 对其他的Request的回调函数也有相同的要求。</p>
<p>该方法及其他的Request回调函数必须返回一个包含
<a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 及(或) <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a>
的可迭代的对象。</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">参数:</th><td class="field-body"><strong>response</strong> (<a class="reference internal" href="request-response.html#scrapy.http.Response" title="scrapy.http.Response"><tt class="xref py py-class docutils literal"><span class="pre">Response</span></tt></a>) &#8211; 用于分析的response</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="scrapy.spider.Spider.log">
<tt class="descname">log</tt><big>(</big><em>message</em><span class="optional">[</span>, <em>level</em>, <em>component</em><span class="optional">]</span><big>)</big><a class="headerlink" href="#scrapy.spider.Spider.log" title="永久链接至目标">¶</a></dt>
<dd><p>使用 <a class="reference internal" href="logging.html#scrapy.log.msg" title="scrapy.log.msg"><tt class="xref py py-func docutils literal"><span class="pre">scrapy.log.msg()</span></tt></a> 方法记录(log)message。
log中自动带上该spider的 <a class="reference internal" href="#scrapy.spider.Spider.name" title="scrapy.spider.Spider.name"><tt class="xref py py-attr docutils literal"><span class="pre">name</span></tt></a> 属性。
更多数据请参见 <a class="reference internal" href="logging.html#topics-logging"><em>Logging</em></a> 。</p>
</dd></dl>

</dd></dl>

<div class="section" id="id3">
<h4>Spider样例<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h4>
<p>让我们来看一个例子:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy</span> <span class="kn">import</span> <span class="n">log</span> <span class="c"># This module is useful for printing out debug information</span>
<span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">Spider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">&#39;http://www.example.com/1.html&#39;</span><span class="p">,</span>
        <span class="s">&#39;http://www.example.com/2.html&#39;</span><span class="p">,</span>
        <span class="s">&#39;http://www.example.com/3.html&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s">&#39;A response from </span><span class="si">%s</span><span class="s"> just arrived!&#39;</span> <span class="o">%</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
<p>另一个在单个回调函数中返回多个Request以及Item的例子:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">Selector</span>
<span class="kn">from</span> <span class="nn">scrapy.spider</span> <span class="kn">import</span> <span class="n">Spider</span>
<span class="kn">from</span> <span class="nn">scrapy.http</span> <span class="kn">import</span> <span class="n">Request</span>
<span class="kn">from</span> <span class="nn">myproject.items</span> <span class="kn">import</span> <span class="n">MyItem</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s">&#39;http://www.example.com/1.html&#39;</span><span class="p">,</span>
        <span class="s">&#39;http://www.example.com/2.html&#39;</span><span class="p">,</span>
        <span class="s">&#39;http://www.example.com/3.html&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">sel</span> <span class="o">=</span> <span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">h3</span> <span class="ow">in</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//h3&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
            <span class="k">yield</span> <span class="n">MyItem</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">h3</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">():</span>
            <span class="k">yield</span> <span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</pre></div>
</div>
<span class="target" id="module-scrapy.contrib.spiders"></span></div>
</div>
<div class="section" id="crawlspider">
<h3>CrawlSpider<a class="headerlink" href="#crawlspider" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spiders.CrawlSpider">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spiders.</tt><tt class="descname">CrawlSpider</tt><a class="headerlink" href="#scrapy.contrib.spiders.CrawlSpider" title="永久链接至目标">¶</a></dt>
<dd><p>爬取一般网站常用的spider。其定义了一些规则(rule)来提供跟进link的方便的机制。
也许该spider并不是完全适合您的特定网站或项目，但其对很多情况都使用。
因此您可以以其为起点，根据需求修改部分方法。当然您也可以实现自己的spider。</p>
<p>除了从Spider继承过来的(您必须提供的)属性外，其提供了一个新的属性:</p>
<dl class="attribute">
<dt id="scrapy.contrib.spiders.CrawlSpider.rules">
<tt class="descname">rules</tt><a class="headerlink" href="#scrapy.contrib.spiders.CrawlSpider.rules" title="永久链接至目标">¶</a></dt>
<dd><p>一个包含一个(或多个) <a class="reference internal" href="#scrapy.contrib.spiders.Rule" title="scrapy.contrib.spiders.Rule"><tt class="xref py py-class docutils literal"><span class="pre">Rule</span></tt></a> 对象的集合(list)。
每个 <a class="reference internal" href="#scrapy.contrib.spiders.Rule" title="scrapy.contrib.spiders.Rule"><tt class="xref py py-class docutils literal"><span class="pre">Rule</span></tt></a> 对爬取网站的动作定义了特定表现。
Rule对象在下边会介绍。
如果多个rule匹配了相同的链接，则根据他们在本属性中被定义的顺序，第一个会被使用。</p>
</dd></dl>

<p>该spider也提供了一个可复写(overrideable)的方法:</p>
<dl class="method">
<dt id="scrapy.contrib.spiders.CrawlSpider.parse_start_url">
<tt class="descname">parse_start_url</tt><big>(</big><em>response</em><big>)</big><a class="headerlink" href="#scrapy.contrib.spiders.CrawlSpider.parse_start_url" title="永久链接至目标">¶</a></dt>
<dd><p>当start_url的请求返回时，该方法被调用。
该方法分析最初的返回值并必须返回一个
<a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> 对象或者
一个 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象或者
一个可迭代的包含二者对象。</p>
</dd></dl>

</dd></dl>

<div class="section" id="crawling-rules">
<h4>爬取规则(Crawling rules)<a class="headerlink" href="#crawling-rules" title="永久链接至标题">¶</a></h4>
<dl class="class">
<dt id="scrapy.contrib.spiders.Rule">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spiders.</tt><tt class="descname">Rule</tt><big>(</big><em>link_extractor</em>, <em>callback=None</em>, <em>cb_kwargs=None</em>, <em>follow=None</em>, <em>process_links=None</em>, <em>process_request=None</em><big>)</big><a class="headerlink" href="#scrapy.contrib.spiders.Rule" title="永久链接至目标">¶</a></dt>
<dd><p><tt class="docutils literal"><span class="pre">link_extractor</span></tt> 是一个 <a class="reference internal" href="link-extractors.html#topics-link-extractors"><em>Link Extractor</em></a> 对象。
其定义了如何从爬取到的页面提取链接。</p>
<p><tt class="docutils literal"><span class="pre">callback</span></tt> 是一个callable或string(该spider中同名的函数将会被调用)。
从link_extractor中每获取到链接时将会调用该函数。该回调函数接受一个response作为其第一个参数，
并返回一个包含 <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> 以及(或) <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象(或者这两者的子类)的列表(list)。</p>
<div class="admonition warning">
<p class="first admonition-title">警告</p>
<p class="last">当编写爬虫规则时，请避免使用 <tt class="docutils literal"><span class="pre">parse</span></tt> 作为回调函数。
由于 <a class="reference internal" href="#scrapy.contrib.spiders.CrawlSpider" title="scrapy.contrib.spiders.CrawlSpider"><tt class="xref py py-class docutils literal"><span class="pre">CrawlSpider</span></tt></a> 使用 <tt class="docutils literal"><span class="pre">parse</span></tt> 方法来实现其逻辑，如果
您覆盖了 <tt class="docutils literal"><span class="pre">parse</span></tt> 方法，crawl spider 将会运行失败。</p>
</div>
<p><tt class="docutils literal"><span class="pre">cb_kwargs</span></tt> 包含传递给回调函数的参数(keyword argument)的字典。</p>
<p><tt class="docutils literal"><span class="pre">follow</span></tt> 是一个布尔(boolean)值，指定了根据该规则从response提取的链接是否需要跟进。
如果 <tt class="docutils literal"><span class="pre">callback</span></tt> 为None， <tt class="docutils literal"><span class="pre">follow</span></tt> 默认设置为 <tt class="docutils literal"><span class="pre">True</span></tt> ，否则默认为 <tt class="docutils literal"><span class="pre">False</span></tt> 。</p>
<p><tt class="docutils literal"><span class="pre">process_links</span></tt> 是一个callable或string(该spider中同名的函数将会被调用)。
从link_extractor中获取到链接列表时将会调用该函数。该方法主要用来过滤。</p>
<p><tt class="docutils literal"><span class="pre">process_request</span></tt> 是一个callable或string(该spider中同名的函数将会被调用)。
该规则提取到每个request时都会调用该函数。该函数必须返回一个request或者None。
(用来过滤request)</p>
</dd></dl>

</div>
<div class="section" id="id4">
<h4>CrawlSpider样例<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h4>
<p>接下来给出配合rule使用CrawlSpider的例子:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.linkextractors.sgml</span> <span class="kn">import</span> <span class="n">SgmlLinkExtractor</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">Selector</span>
<span class="kn">from</span> <span class="nn">scrapy.item</span> <span class="kn">import</span> <span class="n">Item</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com&#39;</span><span class="p">]</span>

    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
        <span class="c"># 提取匹配 &#39;category.php&#39; (但不匹配 &#39;subsection.php&#39;) 的链接并跟进链接(没有callback意味着follow默认为True)</span>
        <span class="n">Rule</span><span class="p">(</span><span class="n">SgmlLinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="p">(</span><span class="s">&#39;category\.php&#39;</span><span class="p">,</span> <span class="p">),</span> <span class="n">deny</span><span class="o">=</span><span class="p">(</span><span class="s">&#39;subsection\.php&#39;</span><span class="p">,</span> <span class="p">))),</span>

        <span class="c"># 提取匹配 &#39;item.php&#39; 的链接并使用spider的parse_item方法进行分析</span>
        <span class="n">Rule</span><span class="p">(</span><span class="n">SgmlLinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="p">(</span><span class="s">&#39;item\.php&#39;</span><span class="p">,</span> <span class="p">)),</span> <span class="n">callback</span><span class="o">=</span><span class="s">&#39;parse_item&#39;</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s">&#39;Hi, this is an item page! </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>

        <span class="n">sel</span> <span class="o">=</span> <span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">Item</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//td[@id=&quot;item_id&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">re</span><span class="p">(</span><span class="s">r&#39;ID: (\d+)&#39;</span><span class="p">)</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//td[@id=&quot;item_name&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;description&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sel</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//td[@id=&quot;item_description&quot;]/text()&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
<p>该spider将从example.com的首页开始爬取，获取category以及item的链接并对后者使用 <tt class="docutils literal"><span class="pre">parse_item</span></tt> 方法。
当item获得返回(response)时，将使用XPath处理HTML并生成一些数据填入 <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> 中。</p>
</div>
</div>
<div class="section" id="xmlfeedspider">
<h3>XMLFeedSpider<a class="headerlink" href="#xmlfeedspider" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spiders.XMLFeedSpider">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spiders.</tt><tt class="descname">XMLFeedSpider</tt><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider" title="永久链接至目标">¶</a></dt>
<dd><p>XMLFeedSpider被设计用于通过迭代各个节点来分析XML源(XML feed)。
迭代器可以从 <tt class="docutils literal"><span class="pre">iternodes</span></tt> ， <tt class="docutils literal"><span class="pre">xml</span></tt> ， <tt class="docutils literal"><span class="pre">html</span></tt> 选择。
鉴于 <tt class="docutils literal"><span class="pre">xml</span></tt> 以及 <tt class="docutils literal"><span class="pre">html</span></tt> 迭代器需要先读取所有DOM再分析而引起的性能问题，
一般还是推荐使用 <tt class="docutils literal"><span class="pre">iternodes</span></tt> 。
不过使用 <tt class="docutils literal"><span class="pre">html</span></tt> 作为迭代器能有效应对错误的XML。</p>
<p>您必须定义下列类属性来设置迭代器以及标签名(tag name):</p>
<dl class="attribute">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.iterator">
<tt class="descname">iterator</tt><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.iterator" title="永久链接至目标">¶</a></dt>
<dd><p>用于确定使用哪个迭代器的string。可选项有:</p>
<blockquote>
<div><ul class="simple">
<li><tt class="docutils literal"><span class="pre">'iternodes'</span></tt> - 一个高性能的基于正则表达式的迭代器</li>
<li><tt class="docutils literal"><span class="pre">'html'</span></tt> - 使用 <a class="reference internal" href="selectors.html#scrapy.selector.Selector" title="scrapy.selector.Selector"><tt class="xref py py-class docutils literal"><span class="pre">Selector</span></tt></a> 的迭代器。
需要注意的是该迭代器使用DOM进行分析，其需要将所有的DOM载入内存，
当数据量大的时候会产生问题。</li>
<li><tt class="docutils literal"><span class="pre">'xml'</span></tt> - 使用 <a class="reference internal" href="selectors.html#scrapy.selector.Selector" title="scrapy.selector.Selector"><tt class="xref py py-class docutils literal"><span class="pre">Selector</span></tt></a> 的迭代器。
需要注意的是该迭代器使用DOM进行分析，其需要将所有的DOM载入内存，
当数据量大的时候会产生问题。</li>
</ul>
</div></blockquote>
<p>默认值为 <tt class="docutils literal"><span class="pre">iternodes</span></tt> 。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.itertag">
<tt class="descname">itertag</tt><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.itertag" title="永久链接至目标">¶</a></dt>
<dd><p>一个包含开始迭代的节点名的string。例如:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">itertag</span> <span class="o">=</span> <span class="s">&#39;product&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.namespaces">
<tt class="descname">namespaces</tt><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.namespaces" title="永久链接至目标">¶</a></dt>
<dd><p>一个由 <tt class="docutils literal"><span class="pre">(prefix,</span> <span class="pre">url)</span></tt> 元组(tuple)所组成的list。
其定义了在该文档中会被spider处理的可用的namespace。
<tt class="docutils literal"><span class="pre">prefix</span></tt> 及 <tt class="docutils literal"><span class="pre">uri</span></tt> 会被自动调用
<a class="reference internal" href="selectors.html#scrapy.selector.Selector.register_namespace" title="scrapy.selector.Selector.register_namespace"><tt class="xref py py-meth docutils literal"><span class="pre">register_namespace()</span></tt></a> 生成namespace。</p>
<p>您可以通过在 <a class="reference internal" href="#scrapy.contrib.spiders.XMLFeedSpider.itertag" title="scrapy.contrib.spiders.XMLFeedSpider.itertag"><tt class="xref py py-attr docutils literal"><span class="pre">itertag</span></tt></a> 属性中制定节点的namespace。</p>
<p>例如:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">class</span> <span class="nc">YourSpider</span><span class="p">(</span><span class="n">XMLFeedSpider</span><span class="p">):</span>

    <span class="n">namespaces</span> <span class="o">=</span> <span class="p">[(</span><span class="s">&#39;n&#39;</span><span class="p">,</span> <span class="s">&#39;http://www.sitemaps.org/schemas/sitemap/0.9&#39;</span><span class="p">)]</span>
    <span class="n">itertag</span> <span class="o">=</span> <span class="s">&#39;n:url&#39;</span>
    <span class="c"># ...</span>
</pre></div>
</div>
</dd></dl>

<p>除了这些新的属性之外，该spider也有以下可以覆盖(overrideable)的方法:</p>
<dl class="method">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.adapt_response">
<tt class="descname">adapt_response</tt><big>(</big><em>response</em><big>)</big><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.adapt_response" title="永久链接至目标">¶</a></dt>
<dd><p>该方法在spider分析response前被调用。您可以在response被分析之前使用该函数来修改内容(body)。
该方法接受一个response并返回一个response(可以相同也可以不同)。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.parse_node">
<tt class="descname">parse_node</tt><big>(</big><em>response</em>, <em>selector</em><big>)</big><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.parse_node" title="永久链接至目标">¶</a></dt>
<dd><p>当节点符合提供的标签名时(<tt class="docutils literal"><span class="pre">itertag</span></tt>)该方法被调用。
接收到的response以及相应的 <a class="reference internal" href="selectors.html#scrapy.selector.Selector" title="scrapy.selector.Selector"><tt class="xref py py-class docutils literal"><span class="pre">Selector</span></tt></a> 作为参数传递给该方法。
该方法返回一个 <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> 对象或者
<a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><tt class="xref py py-class docutils literal"><span class="pre">Request</span></tt></a> 对象 或者一个包含二者的可迭代对象(iterable)。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.spiders.XMLFeedSpider.process_results">
<tt class="descname">process_results</tt><big>(</big><em>response</em>, <em>results</em><big>)</big><a class="headerlink" href="#scrapy.contrib.spiders.XMLFeedSpider.process_results" title="永久链接至目标">¶</a></dt>
<dd><p>当spider返回结果(item或request)时该方法被调用。
设定该方法的目的是在结果返回给框架核心(framework core)之前做最后的处理，
例如设定item的ID。其接受一个结果的列表(list of results)及对应的response。
其结果必须返回一个结果的列表(list of results)(包含Item或者Request对象)。</p>
</dd></dl>

</dd></dl>

<div class="section" id="id5">
<h4>XMLFeedSpider例子<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h4>
<p>该spider十分易用。下边是其中一个例子:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy</span> <span class="kn">import</span> <span class="n">log</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">XMLFeedSpider</span>
<span class="kn">from</span> <span class="nn">myproject.items</span> <span class="kn">import</span> <span class="n">TestItem</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">XMLFeedSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/feed.xml&#39;</span><span class="p">]</span>
    <span class="n">iterator</span> <span class="o">=</span> <span class="s">&#39;iternodes&#39;</span> <span class="c"># This is actually unnecessary, since it&#39;s the default value</span>
    <span class="n">itertag</span> <span class="o">=</span> <span class="s">&#39;item&#39;</span>

    <span class="k">def</span> <span class="nf">parse_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">node</span><span class="p">):</span>
        <span class="n">log</span><span class="o">.</span><span class="n">msg</span><span class="p">(</span><span class="s">&#39;Hi, this is a &lt;</span><span class="si">%s</span><span class="s">&gt; node!: </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">itertag</span><span class="p">,</span> <span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">extract</span><span class="p">())))</span>

        <span class="n">item</span> <span class="o">=</span> <span class="n">Item</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;@id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;name&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;description&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;description&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
<p>简单来说，我们在这里创建了一个spider，从给定的 <tt class="docutils literal"><span class="pre">start_urls</span></tt> 中下载feed，
并迭代feed中每个 <tt class="docutils literal"><span class="pre">item</span></tt> 标签，输出，并在 <a class="reference internal" href="items.html#scrapy.item.Item" title="scrapy.item.Item"><tt class="xref py py-class docutils literal"><span class="pre">Item</span></tt></a> 中存储有些随机数据。</p>
</div>
</div>
<div class="section" id="csvfeedspider">
<h3>CSVFeedSpider<a class="headerlink" href="#csvfeedspider" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spiders.CSVFeedSpider">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spiders.</tt><tt class="descname">CSVFeedSpider</tt><a class="headerlink" href="#scrapy.contrib.spiders.CSVFeedSpider" title="永久链接至目标">¶</a></dt>
<dd><p>该spider除了其按行遍历而不是节点之外其他和XMLFeedSpider十分类似。
而其在每次迭代时调用的是 <a class="reference internal" href="#scrapy.contrib.spiders.CSVFeedSpider.parse_row" title="scrapy.contrib.spiders.CSVFeedSpider.parse_row"><tt class="xref py py-meth docutils literal"><span class="pre">parse_row()</span></tt></a> 。</p>
<dl class="attribute">
<dt id="scrapy.contrib.spiders.CSVFeedSpider.delimiter">
<tt class="descname">delimiter</tt><a class="headerlink" href="#scrapy.contrib.spiders.CSVFeedSpider.delimiter" title="永久链接至目标">¶</a></dt>
<dd><p>在CSV文件中用于区分字段的分隔符。类型为string。
默认为 <tt class="docutils literal"><span class="pre">','</span></tt> (逗号)。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.CSVFeedSpider.headers">
<tt class="descname">headers</tt><a class="headerlink" href="#scrapy.contrib.spiders.CSVFeedSpider.headers" title="永久链接至目标">¶</a></dt>
<dd><p>在CSV文件中包含的用来提取字段的行的列表。参考下边的例子。</p>
</dd></dl>

<dl class="method">
<dt id="scrapy.contrib.spiders.CSVFeedSpider.parse_row">
<tt class="descname">parse_row</tt><big>(</big><em>response</em>, <em>row</em><big>)</big><a class="headerlink" href="#scrapy.contrib.spiders.CSVFeedSpider.parse_row" title="永久链接至目标">¶</a></dt>
<dd><p>该方法接收一个response对象及一个以提供或检测出来的header为键的字典(代表每行)。
该spider中，您也可以覆盖 <tt class="docutils literal"><span class="pre">adapt_response</span></tt> 及
<tt class="docutils literal"><span class="pre">process_results</span></tt> 方法来进行预处理(pre-processing)及后(post-processing)处理。</p>
</dd></dl>

</dd></dl>

<div class="section" id="id6">
<h4>CSVFeedSpider例子<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h4>
<p>下面的例子和之前的例子很像，但使用了
<a class="reference internal" href="#scrapy.contrib.spiders.CSVFeedSpider" title="scrapy.contrib.spiders.CSVFeedSpider"><tt class="xref py py-class docutils literal"><span class="pre">CSVFeedSpider</span></tt></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy</span> <span class="kn">import</span> <span class="n">log</span>
<span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">CSVFeedSpider</span>
<span class="kn">from</span> <span class="nn">myproject.items</span> <span class="kn">import</span> <span class="n">TestItem</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">CSVFeedSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&#39;example.com&#39;</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;example.com&#39;</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/feed.csv&#39;</span><span class="p">]</span>
    <span class="n">delimiter</span> <span class="o">=</span> <span class="s">&#39;;&#39;</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;name&#39;</span><span class="p">,</span> <span class="s">&#39;description&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse_row</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">row</span><span class="p">):</span>
        <span class="n">log</span><span class="o">.</span><span class="n">msg</span><span class="p">(</span><span class="s">&#39;Hi, this is a row!: </span><span class="si">%r</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">row</span><span class="p">)</span>

        <span class="n">item</span> <span class="o">=</span> <span class="n">TestItem</span><span class="p">()</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">]</span>
        <span class="n">item</span><span class="p">[</span><span class="s">&#39;description&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s">&#39;description&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="sitemapspider">
<h3>SitemapSpider<a class="headerlink" href="#sitemapspider" title="永久链接至标题">¶</a></h3>
<dl class="class">
<dt id="scrapy.contrib.spiders.SitemapSpider">
<em class="property">class </em><tt class="descclassname">scrapy.contrib.spiders.</tt><tt class="descname">SitemapSpider</tt><a class="headerlink" href="#scrapy.contrib.spiders.SitemapSpider" title="永久链接至目标">¶</a></dt>
<dd><p>SitemapSpider使您爬取网站时可以通过 <a class="reference external" href="http://www.sitemaps.org">Sitemaps</a> 来发现爬取的URL。</p>
<p>其支持嵌套的sitemap，并能从 <a class="reference external" href="http://www.robotstxt.org/">robots.txt</a> 中获取sitemap的url。</p>
<dl class="attribute">
<dt id="scrapy.contrib.spiders.SitemapSpider.sitemap_urls">
<tt class="descname">sitemap_urls</tt><a class="headerlink" href="#scrapy.contrib.spiders.SitemapSpider.sitemap_urls" title="永久链接至目标">¶</a></dt>
<dd><p>包含您要爬取的url的sitemap的url列表(list)。
您也可以指定为一个 <a class="reference external" href="http://www.robotstxt.org/">robots.txt</a> ，spider会从中分析并提取url。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.SitemapSpider.sitemap_rules">
<tt class="descname">sitemap_rules</tt><a class="headerlink" href="#scrapy.contrib.spiders.SitemapSpider.sitemap_rules" title="永久链接至目标">¶</a></dt>
<dd><p>一个包含 <tt class="docutils literal"><span class="pre">(regex,</span> <span class="pre">callback)</span></tt> 元组的列表(list):</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">regex</span></tt> 是一个用于匹配从sitemap提供的url的正则表达式。
<tt class="docutils literal"><span class="pre">regex</span></tt> 可以是一个字符串或者编译的正则对象(compiled regex object)。</li>
<li>callback指定了匹配正则表达式的url的处理函数。
<tt class="docutils literal"><span class="pre">callback</span></tt> 可以是一个字符串(spider中方法的名字)或者是callable。</li>
</ul>
<p>例如:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[(</span><span class="s">&#39;/product/&#39;</span><span class="p">,</span> <span class="s">&#39;parse_product&#39;</span><span class="p">)]</span>
</pre></div>
</div>
<p>规则按顺序进行匹配，之后第一个匹配才会被应用。</p>
<p>如果您忽略该属性，sitemap中发现的所有url将会被 <tt class="docutils literal"><span class="pre">parse</span></tt> 函数处理。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.SitemapSpider.sitemap_follow">
<tt class="descname">sitemap_follow</tt><a class="headerlink" href="#scrapy.contrib.spiders.SitemapSpider.sitemap_follow" title="永久链接至目标">¶</a></dt>
<dd><p>一个用于匹配要跟进的sitemap的正则表达式的列表(list)。其仅仅被应用在
使用 <cite>Sitemap index files</cite> 来指向其他sitemap文件的站点。</p>
<p>默认情况下所有的sitemap都会被跟进。</p>
</dd></dl>

<dl class="attribute">
<dt id="scrapy.contrib.spiders.SitemapSpider.sitemap_alternate_links">
<tt class="descname">sitemap_alternate_links</tt><a class="headerlink" href="#scrapy.contrib.spiders.SitemapSpider.sitemap_alternate_links" title="永久链接至目标">¶</a></dt>
<dd><p>指定当一个 <tt class="docutils literal"><span class="pre">url</span></tt> 有可选的链接时，是否跟进。
有些非英文网站会在一个 <tt class="docutils literal"><span class="pre">url</span></tt> 块内提供其他语言的网站链接。</p>
<p>例如:</p>
<div class="highlight-python"><div class="highlight"><pre>&lt;url&gt;
    &lt;loc&gt;http://example.com/&lt;/loc&gt;
    &lt;xhtml:link rel=&quot;alternate&quot; hreflang=&quot;de&quot; href=&quot;http://example.com/de&quot;/&gt;
&lt;/url&gt;
</pre></div>
</div>
<p>当 <tt class="docutils literal"><span class="pre">sitemap_alternate_links</span></tt> 设置时，两个URL都会被获取。
当 <tt class="docutils literal"><span class="pre">sitemap_alternate_links</span></tt> 关闭时，只有 <tt class="docutils literal"><span class="pre">http://example.com/</span></tt> 会被获取。</p>
<p>默认 <tt class="docutils literal"><span class="pre">sitemap_alternate_links</span></tt> 关闭。</p>
</dd></dl>

</dd></dl>

<div class="section" id="id7">
<h4>SitemapSpider样例<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h4>
<p>简单的例子: 使用 <tt class="docutils literal"><span class="pre">parse</span></tt> 处理通过sitemap发现的所有url:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/sitemap.xml&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape item here ...</span>
</pre></div>
</div>
<p>用特定的函数处理某些url，其他的使用另外的callback:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/sitemap.xml&#39;</span><span class="p">]</span>
    <span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s">&#39;/product/&#39;</span><span class="p">,</span> <span class="s">&#39;parse_product&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="s">&#39;/category/&#39;</span><span class="p">,</span> <span class="s">&#39;parse_category&#39;</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse_product</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape product ...</span>

    <span class="k">def</span> <span class="nf">parse_category</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape category ...</span>
</pre></div>
</div>
<p>跟进 <a class="reference external" href="http://www.robotstxt.org/">robots.txt</a> 文件定义的sitemap并只跟进包含有 <tt class="docutils literal"><span class="pre">..sitemap_shop</span></tt> 的url:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/robots.txt&#39;</span><span class="p">]</span>
    <span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s">&#39;/shop/&#39;</span><span class="p">,</span> <span class="s">&#39;parse_shop&#39;</span><span class="p">),</span>
    <span class="p">]</span>
    <span class="n">sitemap_follow</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;/sitemap_shops&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse_shop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape shop here ...</span>
</pre></div>
</div>
<p>在SitemapSpider中使用其他url:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">scrapy.contrib.spiders</span> <span class="kn">import</span> <span class="n">SitemapSpider</span>

<span class="k">class</span> <span class="nc">MySpider</span><span class="p">(</span><span class="n">SitemapSpider</span><span class="p">):</span>
    <span class="n">sitemap_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/robots.txt&#39;</span><span class="p">]</span>
    <span class="n">sitemap_rules</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s">&#39;/shop/&#39;</span><span class="p">,</span> <span class="s">&#39;parse_shop&#39;</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="n">other_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;http://www.example.com/about&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">requests</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">super</span><span class="p">(</span><span class="n">MySpider</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">start_requests</span><span class="p">())</span>
        <span class="n">requests</span> <span class="o">+=</span> <span class="p">[</span><span class="n">Request</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_other</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">other_urls</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">requests</span>

    <span class="k">def</span> <span class="nf">parse_shop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape shop here ...</span>

    <span class="k">def</span> <span class="nf">parse_other</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">pass</span> <span class="c"># ... scrape other here ...</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


    
        <h2>
            讨论
            <a class="headerlink" href="#discuss" title="永久链接至标题">¶</a>
        </h2>

        <div id="disqus_thread"></div>
    

          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="selectors.html" class="btn btn-neutral float-right" title="选择器（Selectors）">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="items.html" class="btn btn-neutral" title="Items"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; 版权所有 2008-2014, written by Scrapy developers, translated by Summer&amp;Friends.
      最后更新于 Feb 03, 2015.
    </p>
  </div>

  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
</footer>
        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: stable
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="/zh_CN/latest/">latest</a></dd>
        
          <dd><a href="/zh_CN/stable/">stable</a></dd>
        
          <dd><a href="/zh_CN/master/">master</a></dd>
        
          <dd><a href="/zh_CN/0.24/">0.24</a></dd>
        
          <dd><a href="/zh_CN/0.22/">0.22</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="//readthedocs.org/projects/scrapy-chs/downloads/htmlzip/stable/">HTML</a></dd>
        
          <dd><a href="//readthedocs.org/projects/scrapy-chs/downloads/epub/stable/">Epub</a></dd>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="//readthedocs.org/projects/scrapy-chs/?fromdocs=scrapy-chs">Project Home</a>
          </dd>
          <dd>
            <a href="//readthedocs.org/builds/scrapy-chs/?fromdocs=scrapy-chs">Builds</a>
          </dd>
      </dl>
      <hr/>
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.

    </div>
  </div>



  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.22.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
      <script type="text/javascript" src="../_static/translations.js"></script>
      <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>

  

  
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
     
    
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'scrapychs'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
     var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
     dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
     (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();

    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
         (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
           m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
             })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-50189694-1', 'readthedocs.org');
      ga('send', 'pageview');

    </script>
    


</body>
</html>